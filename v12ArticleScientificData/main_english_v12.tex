\documentclass[fleqn,10pt]{wlscirep}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lineno}
 \usepackage{multirow}
\usepackage{array}  % Añade esto en el preámbulo
\renewcommand{\arraystretch}{1.3}  % Espaciado vertical entre filas

\usepackage{subcaption}
\linenumbers
\usepackage{float}

% ===== TRACK CHANGES PACKAGE =====
% Use [draft] to show changes with highlighting
% Use [final] to hide all markup for submission
\usepackage[draft]{changes}
\usepackage{xcolor}

% Define authors for tracked changes
\definechangesauthor[name={Revision}, color=yellow]{REV}

% Custom commands for easier tracking
\newcommand{\addtext}[1]{\added[id=REV]{#1}}
\newcommand{\deltext}[1]{\deleted[id=REV]{#1}}
\newcommand{\replacetext}[2]{\replaced[id=REV]{#1}{#2}}
\newcommand{\notetext}[1]{\comment[id=REV]{#1}}
\newcommand{\highlighttext}[1]{\highlight[id=REV]{#1}}
% ===== END TRACK CHANGES ===== 

%\title{CoSiBD: A Versatile Dataset for Benchmarking Signal Processing and Machine Learning Algorithms}
%\title{CoSiBD: A Synthetic Dataset for Super-Resolution Deep Learning Temporal Series Analysis}
%\title{A synthetic dataset for super-resolution of Time Series using Deep Learning}
\title{A synthetic dataset for Time Series Super-Resolution with Deep Learning}
\author[1]{Julio Ibarra-Fiallo}
\author[2]{Juan A. Lara}
\author[1]{D'hamar Agudelo-Moreno}
%\author[2,*]{autor }
\affil[1]{Colegio de Ciencias e Ingenierías, Universidad San Francisco de Quito, Cumbayá, Ecuador}
\affil[2]{Universidad de Córdoba, Córdoba, España}

\affil[*]{corresponding author: Julio Ibarra-Fiallo (jibarra@usfq.edu.ec)}

\begin{abstract}
\deltext{The increasing application of temporal signal analysis in fields like biomedical engineering, telecommunications, and industrial monitoring emphasizes the need for high-quality data to train and evaluate advanced machine learning models.}
\addtext{The increasing application of time-series analysis in fields such as biomedical engineering, telecommunications, and industrial monitoring emphasizes the need for high-quality datasets to develop and evaluate data-driven methods.}

Acquiring real-world temporal data at suitable resolutions is often limited by ethical, economic, or practical constraints. To address this, we introduce CoSiBD (Complex Signal Benchmark Dataset for Super-Resolution), a synthetic dataset of complex temporal signals designed for \deltext{training and assessing AI models, particularly deep learning systems, in tasks like temporal super-resolution and signal processing}
\addtext{supporting reproducible research in multi-resolution time-series analysis, including temporal super-resolution and related signal processing tasks}.

\addtext{CoSiBD comprises 2,500 high-resolution signals ($N=5{,}000$ samples each over a reference domain $\tau\in[0,4\pi]$) with corresponding low-resolution versions at four sampling levels (150, 250, 500, and 1,000 samples).}

\replacetext{Each signal is provided in three formats (NumPy arrays, plain text, and JSON) with comprehensive metadata documenting all generation parameters for reproducibility.}
{Each signal is provided in three formats (NumPy arrays, plain text, and JSON), accompanied by comprehensive per-signal metadata documenting all generation parameters, including random seeds, to enable exact regeneration.}

CoSiBD includes diverse signals with non-uniform frequency modulations, capturing gradual transitions and abrupt high-frequency events
\replacetext{to approximate a range of dynamics observed in practice.}
{to reflect a broad range of non-stationary temporal behaviors.}

\deltext{The dataset provides both clean and noisy high-resolution signals; additionally, multiple subsampled versions are provided to support SR benchmarking.}

\deltext{Subsampling is performed using two approaches: direct re-evaluation at lower time resolutions and uniform decimation.}
\addtext{Low-resolution signals are provided at four target resolutions obtained via simple uniform decimation of the original high-resolution sequences.}

The dataset is generated by combining distinct frequency bands, non-uniform intervals, and probabilistic frequency assignments to create realistic patterns, with smoothing achieved through spline interpolation.

\replacetext{Validated for spectral consistency across sampling rates and noise, CoSiBD supports training and evaluation.}
{Technical validation focuses on the spectral characteristics of the generated signals across sampling resolutions, documenting consistent behavior and controlled variability under the reported settings.}
\end{abstract}


\begin{document}

\flushbottom
\maketitle

\section*{Background \& Summary}
\label{sec:background-summary}

The analysis and simulation of temporal signals are fundamental across science and engineering, 
\deltext{supporting insights into dynamic processes.}
\addtext{providing critical insights into dynamic processes across multiple domains.}
In biomedical research \cite{Karacan2024}, electroencephalography (EEG) and electrocardiography (ECG) analyses reveal brain and heart function \cite{Nayak2023,shaffer2017}. 
Telecommunications rely on signal processing to ensure data fidelity across noisy media \cite{Chen2022}, while finance uses time-series forecasting for risk and trend analysis \cite{Zhang2016}. 
Industrial monitoring detects equipment faults using temporal patterns \cite{Bhatia2021}, and environmental science applies similar techniques to 
\deltext{climate tracking via remote sensing}
\addtext{climate and environmental monitoring using remote-sensor time series} \cite{Mallat1989}. 
Developing robust tools for interpreting time-varying data continues to support both scientific discovery and practical applications,
\addtext{while increasingly relying on the availability of reliable and well-characterized temporal signal datasets.}
\\ \\ 
Recent advances in deep learning have contributed significantly to this field by enabling automatic extraction of complex features from raw signals. 
Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), including Long Short-Term Memory (LSTM) units, and Generative Adversarial Networks (GANs) have demonstrated improved performance over traditional techniques in image, speech, and time-series processing tasks \cite{Lecun2015,Goodfellow2014}. 
These models support fine-grained signal reconstruction and forecasting, allowing researchers to explore temporal dynamics in new ways,
\addtext{but also increasing the demand for well-structured, high-quality temporal signal datasets suitable for training and evaluation.}
\\ \\
Despite this progress, deep learning methods for temporal signal processing often require large quantities of labeled, high-quality data. 
Access to such data is frequently constrained by medical privacy regulations such as the General Data Protection Regulation (GDPR) and the Health Insurance Portability and Accountability Act (HIPAA) \cite{Isasa2024}. 
In other domains, including 
\deltext{remote sensing and industrial monitoring}
\addtext{environmental monitoring using remote sensors and industrial monitoring}, 
data availability is limited by practical and economic barriers to sensor deployment and data collection \cite{Zhang2016}. 
These limitations are particularly relevant in super-resolution (SR) tasks, where models require paired low- and high-resolution signals for effective training,
\addtext{which are rarely available in sufficient quantity and with consistent acquisition conditions.}
\\ \\
Temporal SR, which enhances resolution over time, has broad potential. 
\deltext{In medicine, for instance, it improves magnetic resonance imaging (MRI) and computed tomography (CT) scans, supporting earlier disease detection \cite{Morales2022}.}
\addtext{In biomedical monitoring and sensing, temporal SR can help reconstruct higher-resolution physiological time series, such as ECG and EEG signals.}
For EEG analysis, SR may help recover high-frequency components that aid in the study of neural oscillations \cite{Nayak2023} or detect subtle physiological irregularities \cite{shaffer2017}. 
\deltext{In remote sensing, SR helps refine satellite imagery \cite{Mallat1989},}
\addtext{In domains such as environmental sensing, telecommunications, and industrial monitoring,}
SR \addtext{can increase sensitivity to rapid temporal changes,} 
\deltext{while in telecommunications it contributes to enhanced signal reliability. It also has applications in industrial monitoring by increasing sensitivity to system changes.}
\\ \\
Traditional SR methods such as polynomial interpolation, frequency-domain transforms, and splines each have limitations. Polynomial models are often insufficient for capturing nonlinear dynamics; frequency-domain methods are susceptible to noise \cite{Mallat1989}; and splines, though flexible, may not generalize well to complex signal variability \cite{Schumaker2007,DeBoor2001}. Many of these methods also assume uniform partitioning, which may not align with the multi-scale, irregular structure of natural temporal phenomena.
\\ \\
Deep learning offers adaptive alternatives to these traditional methods. CNNs are capable of modeling spatio-temporal structure, RNNs and LSTMs capture long-range dependencies in time, and GANs can learn high-resolution representations through adversarial training \cite{Lecun2015,Goodfellow2014}. While GANs have achieved strong results in image SR \cite{Brophy2023}, their application to time-series SR remains relatively new. Preliminary work on synthetic time-series generation indicates potential \cite{Brophy2023,IbarraFiallo2024}, but the lack of accessible, high-quality paired datasets remains a significant barrier to progress.
\\ \\
Synthetic datasets offer one solution to this problem, allowing researchers to design reproducible training environments that reflect the structure and variability of real-world signals. Prior studies have used synthetic data in domains such as fluid dynamics \cite{Yasuda2023}, bioimaging \cite{Priessner2024}, and live-cell imaging \cite{Qiao2025}, demonstrating that synthetic approaches can help simulate complexity while avoiding legal and practical restrictions associated with real-world data.
\\ \\
To support research in super-resolution for time-series data, we present the Complex Signal Benchmark Dataset (CoSiBD).
CoSiBD is a synthetic dataset composed of time-series signals with variable resolution, frequency characteristics, and noise levels.
The dataset is intended to provide a resource for training and evaluating SR models under controlled, reproducible conditions.
It includes 
\deltext{non-uniformly sampled signals,}
\addtext{non-stationary, piecewise-structured signals generated via non-uniform interval partitioning with change-points,}
multiple levels of resolution and noise, a technical validation suite, and publicly available Python code to facilitate use.
\deltext{CoSiBD has been used in research presented at the International Conference on Signal Processing and Machine Learning}
\addtext{The dataset has been used as part of previously published work \cite{IbarraFiallo2024}}
and is made available to support further development in deep learning approaches for temporal super-resolution.

\subsection*{Related synthetic time-series resources}

\addtext{Publicly available synthetic resources for temporal signals exist, but they are typically designed for tasks other than time-series super-resolution (SR), or they target a specific domain. In wireless communications, the RadioML family provides large collections of synthetic complex I/Q sequences with varying SNR and channel impairments, mainly to benchmark automatic modulation classification rather than paired SR reconstruction \cite{oshea2016grcon,deepsig_datasets,deepsig_radioml2018}. In biomedical signal processing, physiological simulators such as ECGSYN (ECG) and SEREEGA (EEG) enable controlled generation with tunable morphology, sampling settings, and noise, supporting method development when real data access is constrained \cite{mcsharry2003ecg,ecgsyn_physionet,krol2018sereega}. In power systems, LoadGAN provides multi-resolution generation of load time series across sampling rates and time horizons (from sub-second to long-term scales), but it is not distributed as a standardized paired SR benchmark \cite{pinceti2021loadgan}. Domain-specific paired low-/high-resolution training data can also be produced via physical forward modeling, e.g., low- and high-resolution 1D seismic traces for learning-based resolution enhancement \cite{yuan2024seismic}.}
\\ \\
\noindent
\addtext{Table~\ref{tab:related_synthetic_datasets} summarizes these representative resources and highlights a practical gap: while many tools provide synthetic signals, they usually do not jointly offer (i) multi-factor paired LR--HR signals for time-series SR, (ii) a clearly specified and reproducible protocol for constructing low-resolution observations aligned to a fixed high-resolution target, and (iii) per-signal metadata enabling deterministic regeneration and principled benchmarking. CoSiBD is designed to address this gap by providing multi-resolution paired signals, explicit nuisance modeling (noise and structured interference), and comprehensive metadata for reproducible SR benchmarking across multiple difficulty levels.}


\begin{table*}[t]
\centering
\begingroup
\small
\setlength{\tabcolsep}{3pt}
\renewcommand{\arraystretch}{1.15}
\begin{tabular}{|p{2.7cm}|p{2.3cm}|p{1.6cm}|p{1.9cm}|p{1.7cm}|p{2.2cm}|p{2.4cm}|}
\hline
                                     \csname textbf\endcsname{Resource} & \textbf{Domain} & \textbf{Form} & \textbf{Paired LR--HR SR} & \textbf{Multi-resolution} & \textbf{Noise / artifacts} & \textbf{Reproducibility granularity} \\
\hline
                                     \csname textbf\endcsname{CoSiBD (this work)} &
Generic time series (complex-structured signals) &
Dataset + generator &
Yes (LR $\rightarrow$ HR targets) &
Yes ($150/\allowbreak250/\allowbreak500/\allowbreak1000 \rightarrow 5000$) &
Gaussian + structured interference; primary benchmark uses direct decimation &
Per-signal metadata; deterministic regeneration (seed-controlled) \\
\hline
RadioML 2016.10A \cite{oshea2016grcon,deepsig_datasets} &
Wireless communications (I/Q) &
Dataset &
No (classification benchmark) &
N/A (not SR) &
Variable SNR + channel impairments &
Dataset-level (labels/\allowbreak SNR); not per-sample ``recipe'' \\
\hline
RadioML 2018.01A \cite{deepsig_radioml2018} &
Wireless communications (I/Q) &
Dataset &
No (classification benchmark) &
N/A (not SR) &
Simulated channel effects + SNR variability &
Dataset-level; not SR-paired \\
\hline
ECGSYN \cite{mcsharry2003ecg,ecgsyn_physionet} &
ECG (physiology) &
Simulator/tool &
Configurable\footnotemark[1] &
Configurable (via sampling settings) &
Model-based; supports controlled variability &
Configurable via simulator parameters (user-defined) \\
\hline
SEREEGA \cite{krol2018sereega} &
EEG (physiology) &
Simulator/\allowbreak toolbox &
Configurable\footnotemark[1] &
Configurable (user-defined) &
Supports noise and event-related components &
Configurable via simulator parameters (user-defined) \\
\hline
LoadGAN \cite{pinceti2021loadgan} &
Power systems load time series &
Generator/tool &
No (generation) &
Yes (variable sampling rates) &
Domain-specific variability (load patterns) &
Tool-based; generation is configurable \\
\hline
Synthetic LR--HR seismic traces (example) \cite{yuan2024seismic} &
Seismic traces (geophysics) &
Paper-specific paired data &
Yes (LR--HR pairs) &
Typically limited (study-specific) &
Study-dependent &
Paired data available for the study; limited generality \\
\hline
\end{tabular}
\endgroup
\caption{Representative publicly available synthetic time-series datasets and simulators related to signal processing and learning. ``Form'' indicates whether the resource is distributed primarily as a fixed dataset or as a simulator/generator. ``Reproducibility granularity'' summarizes whether exact per-sample regeneration is supported via documented parameters and seeds.}
\label{tab:related_synthetic_datasets}
\end{table*}

\footnotetext[1]{``Configurable'' indicates that LR--HR pairs can be constructed by running the simulator at different sampling settings and/or applying controlled downsampling, but a standardized paired SR benchmark (multi-factor LR versions aligned to a fixed HR target) is not typically distributed as part of the resource.}

\section*{Methods}
\label{sec:methods}

The methodology used to generate the synthetic temporal signals that constitute the CoSiBD dataset is illustrated in Figure~\ref{fig:generation_process}.
The process was designed to produce signals that reflect general
\deltext{characteristics}
\addtext{structural characteristics}
of real-world temporal data, such as variable frequency content, continuous transitions, and intermittent high-frequency activity.
A key aspect of the procedure is the ability
\deltext{to produce signals at different resolution levels, supporting the generation of paired datasets for evaluating super-resolution (SR) algorithms.}
\addtext{to generate signals at multiple resolution levels, supporting paired datasets for evaluating temporal super-resolution (SR) algorithms under controlled and reproducible conditions.}
\\ \\

\begin{figure}
    \centering
    \deleted{\includegraphics[width=0.35\textwidth]{diagrams/generation_process3.png}}
    \added{\includegraphics[width=0.35\textwidth]{diagrams/generation_process4.png}}
    \caption{Schematic overview of the CoSiBD signal generation process.}
    \label{fig:generation_process}
\end{figure}

\noindent
\addtext{The design of the CoSiBD signal generator is informed by qualitative observations of representative physiological (EEG/ECG) and speech signals. In particular, such signals commonly exhibit (i) non-stationary regime changes, (ii) coexisting low- and high-frequency components with intermittent transients, (iii) smooth amplitude-envelope evolution, and (iv) slow baseline drift and measurement noise. CoSiBD instantiates these properties via non-uniform interval partitioning with change-points, separate low/high-frequency bands, spline-based envelopes and frequency profiles, and explicit offset and noise terms. Figure~\ref{fig:design_rationale_motivations} provides qualitative examples of these motivating properties; the goal is to capture challenging structure for SR benchmarking rather than to match a specific domain distribution.}
\\ \\

\begin{figure}
    \centering
    \includegraphics[width=0.95\textwidth]{graphs/r1_3_design_rationale/r1_3_real_signal_motivations.png}
    \caption{Qualitative real-signal properties motivating the CoSiBD design. The physiological example illustrates non-stationarity in the waveform and structured spectral content; the speech example illustrates amplitude-envelope dynamics and a smoothly varying pitch (F0) trend. These observations motivate CoSiBD mechanisms such as regime partitioning with change-points, low/high-frequency bands, and spline-based envelopes/frequency profiles.}
    \label{fig:design_rationale_motivations}
\end{figure}

\noindent The signal generation pipeline involves the following steps:

\begin{enumerate}
    \item \textbf{Base frequency band definition:}
    A set of distinct frequency bands is defined to represent the underlying spectral content of the signals.
    \addtext{All signals are defined over a reference domain $\tau \in [0,4\pi]$, which is dimensionless and does not correspond to a physical unit of time.}
    These can be adjusted to reflect application-specific characteristics.

    \item \textbf{Non-uniform interval partitioning:}
    The total signal duration is divided into multiple intervals of variable length. The interval lengths are determined probabilistically to introduce variability in the signal structure
    \addtext{and non-stationarity through change-points}.

    \item \textbf{Frequency assignment:}
    Each interval is assigned a dominant frequency band, sampled according to a predefined probability distribution.
    This introduces spectral variation over time
    \addtext{that may be piecewise constant or smoothly interpolated across intervals}.

    \item \textbf{Signal synthesis:}
    A sinusoidal waveform, or a combination of sinusoids within the assigned frequency band, is generated for each interval. Signal parameters such as amplitude and phase are configurable.
    \addtext{This construction yields non-stationary oscillatory patterns with controlled variability driven by the interval structure and frequency assignment.}

    \item \textbf{Transition smoothing:}
    To avoid discontinuities at interval boundaries, a smoothing function is applied to overlapping segments.
    This ensures gradual transitions between intervals with different frequency content.
    \addtext{All smoothing parameters are deterministic and recorded in metadata.}

    \item \textbf{Resolution variation:}
    All signals are initially synthesized at a high temporal resolution.
    \addtext{High-resolution reference signals consist of $N=5{,}000$ samples defined over the domain $\tau \in [0,4\pi]$.}
    Lower-resolution versions are created by applying controlled downsampling to the high-resolution signals, forming paired datasets.
    \addtext{In practice, low-resolution sequences are generated using a fixed and documented uniform subsampling protocol, in which the low-resolution observation is obtained by subsampling the original high-resolution sequence without pre-filtering. Reconstructing low-pass filtered signals or modeling specific acquisition devices is not an objective of CoSiBD.}
    \addtext{For reproducibility, given a high-resolution sequence $x_{\mathrm{HR}}[n]$ of length $N=5000$ and a target low-resolution length $M\in\{1000,500,250,150\}$, the low-resolution sequence is defined as
    \[
    x_{\mathrm{LR}}[i] = x_{\mathrm{HR}}[n_i], \quad
    n_i = \left\lfloor \frac{i\,(N-1)}{M-1} + 0.5 \right\rfloor,
    \]
    for $i=0,\ldots,M-1$, applied identically to the time grid.}

    \item \textbf{Noise injection:}
    Controlled levels of synthetic noise are added to the signals to emulate different data acquisition scenarios.
    Both the type and intensity of the noise can be configured.
    \addtext{In CoSiBD, two noise families are supported: additive Gaussian noise with configurable standard deviation and structured sinusoidal interference components. Noise is applied probabilistically with a fixed probability of 50\% per signal.}
    \addtext{All noise parameters are stored per signal in metadata, enabling exact reconstruction of the applied noise.}

\end{enumerate}

\noindent
\addtext{In addition to broadband Gaussian noise, CoSiBD optionally includes a structured sinusoidal interference component to reflect common narrow-band artifacts observed in real measurement pipelines (e.g., mains hum). Signals are generated over a reference domain $\tau \in [0,4\pi]$; interpreting $\tau$ as physical time (and therefore expressing frequencies in Hz) requires an explicit time scaling. Throughout this manuscript we adopt an illustrative convention that maps the reference domain to a duration $T=4\pi$ seconds, under which the structured component can be interpreted as a 50/60\,Hz-like interference term, while the broadband component represents the measurement noise floor. Figure~\ref{fig:r1_4_powerline_noise} provides a qualitative illustration of this effect. The purpose of this design choice is not to reproduce a specific acquisition device, but to include representative nuisance factors that temporal SR models may encounter in practice.}
\\ \\

\begin{figure}
    \centering
    \includegraphics[width=0.85\textwidth]{figures/powerline_interference_justification.png}
    \caption{Qualitative motivation for the structured interference term used in CoSiBD. An illustrative example shows how adding a narrow-band sinusoidal component (interpretable as 50/60\,Hz under the illustrative convention $T=4\pi$\,s) produces the characteristic periodic contamination observed in real recordings, while broadband noise captures the measurement floor.} % R1-4
    \label{fig:r1_4_powerline_noise}
\end{figure}

\noindent
\addtext{CoSiBD signals are provided as discrete sequences $x[n]$ (e.g., $N=5{,}000$ samples) that are directly used as inputs/targets by SR models. The internal generation domain $\tau\in[0,4\pi]$ is a reference parameterization; interpreting $\tau$ as physical time requires choosing a duration $T$ (in seconds) for the reference interval. Under this convention, the implied sampling rate is $f_s = N/T$ and all frequencies reported in Hz scale linearly with $4\pi/T$. Throughout this manuscript, when reporting example frequencies in Hz we adopt the illustrative convention $T=4\pi$\,s, yielding $f_s \approx 5000/(4\pi) \approx 398\,$Hz; other equally valid mappings exist depending on application. Consequently, any band-specific interpretation in Hz (e.g., ``low/high'' frequency ranges) should be understood under the chosen $T$; changing $T$ rescales all reported Hz values while preserving the underlying discrete sequences, which is a key feature of CoSiBD's reference-domain design. Figure~\ref{fig:r1_5_sampling_units} illustrates that the discrete samples are unchanged under different time scalings and that Hz axes shift with the assumed $f_s$, while the normalized spectrum (cycles/sample) is invariant.}
\\ \\
\begin{figure}
    \centering
    \includegraphics[width=0.95\textwidth]{graphs/r1_5_sampling_units/r1_5_time_scaling.png}
    \vspace{0.25cm}
    \includegraphics[width=0.95\textwidth]{graphs/r1_5_sampling_units/r1_5_spectrum_mapping.png}
    \caption{Sampling/unit convention in CoSiBD. Top: the same discrete sequence $x[n]$ can be plotted against the sample index or under different assumed time scalings. Bottom: the intrinsic frequency axis is normalized (cycles/sample); mapping to ``Hz'' depends on the assumed sampling rate $f_s$ (two example mappings shown).} % R1-5
    \label{fig:r1_5_sampling_units}
\end{figure}

\noindent
The parameters that govern each step of the generation process—such as interval length distributions, frequency band selection
probabilities, smoothing function characteristics, sampling rates, and noise settings—can be configured to produce signal sets
tailored to different domains or experimental conditions.
\deltext{These configurations are included in the dataset’s accompanying code
to support reproducibility and allow users to regenerate the signals under consistent conditions.}
\addtext{All generation parameters, including random seeds, are documented in comprehensive metadata (\texttt{signals\_metadata.json}), enabling exact reproduction of individual signals as well as the complete dataset. These configurations are included in the dataset’s accompanying code and implemented in modular Python routines, supporting reproducibility and allowing users to regenerate the signals under consistent conditions.}

\section*{Data Records}
\label{sec:data-records}

The Complex Signal Benchmark Dataset (CoSiBD) is publicly available
\addtext{on Zenodo}
and consists of synthetic temporal signals created to
support the development and evaluation of temporal super-resolution (SR) algorithms.
\addtext{The dataset is released under an open license to facilitate reuse and reproducibility.}
This section provides an overview of the
dataset structure, content, and storage format.
\\ \\
\noindent
\deltext{The dataset includes a total of 7,800 signal samples divided into two main categories:}
\addtext{The dataset comprises 2,500 high-resolution signals, each with corresponding subsampled versions at four resolution levels, organized into multiple categories:}

\begin{itemize}
    \item \deltext{High-resolution signals, generated at full sampling rate.}
    \addtext{\textbf{High-resolution signals}: 2,500 signals generated at full sampling rate, each consisting of 5,000 samples spanning the reference domain $[0,4\pi]$. Each signal is provided in three formats: NumPy compressed archives (.npz), plain-text files (.txt), and JSON representations (.json). Per-signal generative metadata---including frequency profiles with explicit change-points (\texttt{base\_points}, \texttt{high\_freq\_points}), segment labels (\texttt{variation\_type}), amplitude envelopes, spline parameters, vertical offsets, noise configurations, and random seeds---is stored in a consolidated metadata file (\texttt{signals\_metadata.json}), enabling exact regeneration of individual signals.}

    \item \deltext{\textbf{Low-resolution signals}, obtained through controlled downsampling of the high-resolution versions, available at three distinct resolution levels.}
    \addtext{\textbf{Simple subsampled signals}: low-resolution versions obtained via uniform decimation of the high-resolution signals at four target resolutions (150, 250, 500, and 1,000 samples). These paired low-resolution sequences are intended as inputs for temporal super-resolution benchmarking against the original 5,000-sample targets and are provided in .npz, .txt, and .json formats.}
\end{itemize}

\deltext{Noise is applied to both high- and low-resolution signals at different signal-to-noise ratio (SNR) levels (20 dB, 10 dB, and 5 dB), integrated directly into the signal files.}
\addtext{Reproducibility is ensured through documented random seeds: each high-resolution signal is generated using a unique seed (ranging from 10,000 to 12,499), enabling exact regeneration of individual signals or the entire dataset. All generation parameters are stored in metadata JSON files, allowing users to reproduce signals deterministically without relying on a fixed global seed.}
\\ \\
\noindent
\deltext{A summary table describes the dataset subsets, indicating sample counts and resolution. Naming conventions follow a consistent pattern: `Sub\_Super\_Sample` prefixes denote high-resolution subsets, while `Sub\_Sample` denotes low-resolution ones. Resolution pairings are indicated in the names (e.g., `500\_5000`), and validation subsets are labeled with the suffix `Val`.}
\addtext{The dataset is provided as consolidated files organized by resolution level and processing method. High-resolution signals are stored as \texttt{signals\_\allowbreak high\_\allowbreak resolution\_\allowbreak 5000.[npz|txt|json]}. Simple subsampled (uniformly decimated) signals are stored as \texttt{signals\_\allowbreak subsampled\_\allowbreak simple\_\allowbreak \{150,250,500,1000\}.[npz|txt|json]}. Dataset-level metadata and configuration files are provided separately, including \texttt{signals\_\allowbreak metadata.json} and \texttt{dataset\_\allowbreak summary.json}.}
\\ \\
\noindent
\deltext{Signals are stored in plain text `.txt` files containing NumPy-formatted arrays. Each file represents a single temporal signal as a one-dimensional sequence of numerical values. The dataset folder structure mirrors the subset naming scheme.}
\addtext{Each signal is provided in three formats: (1) NumPy compressed format (.npz) containing the signal array, the corresponding time grid, and (for high-resolution records only) the clean signal without noise; (2) plain-text format (.txt), where signals are stored as numerical arrays with samples separated by whitespace, for maximum portability; and (3) JSON format (.json) containing both time and signal arrays to support web-based applications and interoperability. Per-signal generative metadata is stored separately in \texttt{signals\_metadata.json} (one entry per signal), while dataset-level configuration and summary information is provided in \texttt{dataset\_summary.json}.}

\subsection*{Metadata schema and example}

\addtext{CoSiBD provides per-signal metadata to support (i) deterministic regeneration, (ii) principled partitioning (e.g., by noise type/level or segment labels), and (iii) analysis of the piecewise structure induced by change-points. Table~\ref{tab:metadata_schema} summarizes representative fields contained in \texttt{signals\_metadata.json}. A minimal example entry is shown below (one signal; values truncated for brevity).}

\begin{table}[H]
\centering
\small
\begin{tabular}{|p{3.2cm}|p{3.2cm}|p{7.2cm}|}
\hline
\textbf{Field} & \textbf{Type / example} & \textbf{Meaning} \\ \hline
\texttt{signal\_id}, \texttt{index} & \texttt{"signal\_0000"}, 0 & Unique identifier and row index used to align LR--HR pairs across consolidated files. \\ \hline
\texttt{seed} & 10000--12499 & Per-signal random seed enabling deterministic regeneration. \\ \hline
\texttt{t\_start}, \texttt{t\_end} & 0.0, 12.566... & Reference-domain interval (\(\tau\in[0,4\pi]\)) used by the generator. \\ \hline
\texttt{fs\_high} & 397.887... & Illustrative sampling rate under the manuscript convention \(T=4\pi\) s (see Sampling units and frequency interpretation). \\ \hline
\texttt{tau\_frequency} & 1.15 & Frequency-profile spline tension parameter. \\ \hline
\texttt{amplitude\_\allowbreak spline\_\allowbreak type}, \texttt{tau\_\allowbreak amplitude} &
\texttt{"zero\_\allowbreak order"}, \texttt{"N/A"} &
Envelope model type and, when applicable, its tension parameter. \\ \hline
\texttt{base\_points} & \(K\times 2\) array & Change-points and base-band frequencies defining the piecewise frequency profile. \\ \hline
\texttt{high\_freq\_points} & \(K\times 2\) array & Change-points and high-frequency component levels (intermittent transients). \\ \hline
\texttt{variation\_type} & \texttt{["low", ...]} & Segment labels aligned to change-points (e.g., low/high/no-change regime). \\ \hline
\texttt{amp\_knots}, \texttt{amp\_values} & arrays & Envelope control knots and values. \\ \hline
\texttt{vertical\_offset} & 0.069... & Additive baseline drift term. \\ \hline
\texttt{noise\_profile} & JSON object & Noise flags and parameters (e.g., Gaussian vs structured interference; probabilities; amplitudes). \\ \hline
\end{tabular}
\caption{Representative per-signal metadata fields in \texttt{signals\_metadata.json}. The file contains one entry per signal, supporting deterministic regeneration and analysis/partitioning based on the signal's piecewise structure and nuisance settings.}
\label{tab:metadata_schema}
\end{table}

\begin{verbatim}
{
    "t_start": 0.0,
    "t_end": 12.566370614359172,
    "fs_high": 397.88735772973837,
    "tau_frequency": 1.15,
    "amplitude_spline_type": "zero_order",
    "vertical_offset": 0.06905161748158965,
    "base_points": [[0.0, 2.076409156965817], [1.9229451245119575, 2.076409156965817], ...],
    "high_freq_points": [[0.0, 0.0], [1.9229451245119575, 0.0], ...],
    "variation_type": ["low", "low", "low", "low"],
    "amp_knots": [0.0, 6.28192867011815, 12.5638573402363],
    "amp_values": [0.7237770021649202, 1.2266792057266251, 0.9661294815645534],
    "noise_profile": {"has_noise": true, "noise_type": "gaussian", "p_has_noise": 0.5, ...},
    "seed": 10000,
    "signal_id": "signal_0000",
    "index": 0
}
\end{verbatim}

\noindent The following resolution levels are available:

\begin{itemize}
    \item \textbf{High-resolution:} 5000 \deltext{points}\addtext{samples} per signal,
    \addtext{sampled over the reference domain $\tau\in[0,4\pi]$}.
    \addtext{An illustrative mapping to physical time is discussed in the Methods section.}

    \item \deltext{\textbf{Low-resolution:} Created via downsampling from the high-resolution version:}
    \addtext{\textbf{Subsampled resolutions:} Available as simple decimated versions of the high-resolution signals:}
    \begin{itemize}
        \item \deltext{1000 points}\addtext{1000 samples}
        \item \deltext{500 points}\addtext{500 samples}
        \item \deltext{250 points}\addtext{250 samples}
        \item \addtext{150 samples}
    \end{itemize}
\end{itemize}

\noindent Table~\ref{tab:Parameter} outlines the main parameters used in signal generation.
\deltext{Each signal was generated with randomly sampled values within the defined ranges.}
\addtext{Each high-resolution signal was generated using a unique random seed (ranging from 10{,}000 to 12{,}499), with parameter values randomly sampled within the defined ranges. This design supports dataset diversity while enabling exact regeneration of individual signals through the accompanying metadata.}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|m{6cm}|}
\hline
\textbf{Parameter} & \textbf{Range} & \textbf{Description} \\ \hline
Low Frequency & \replacetext{1--5 Hz}{1--5 (illustrative Hz for $T=4\pi$\,s)} & Low-frequency component present in signals \\ \hline
High Frequency & \replacetext{20--100 Hz}{20--100 (illustrative Hz for $T=4\pi$\,s)} & Higher-frequency variations for transitions \\ \hline
Change Points & 2--11 & Number of frequency transitions per signal \\ \hline
Change Locations & Random & Time locations where transitions occur \\ \hline
Variation Type & Categorical & Defines nature of frequency change ("low", "high", "no\_change") \\ \hline
Amplitude Range & \replacetext{1--8}{3--16} & \replacetext{Range for amplitude-envelope magnitude values (controlled to avoid extreme peaks)}{Range for amplitude envelope values} \\ \hline
\addtext{Vertical Offset} & \addtext{N(0, 3.0)} & \addtext{Normally distributed offset added to signals} \\ \hline
Spline Type & Mixed & \replacetext{50\% zero-order (step), 50\% tension spline}{70\% zero-order (step), 30\% tension spline} \\ \hline
\addtext{Tension Parameter (freq)} & \addtext{[1, 2]} & \addtext{Tau values for frequency spline interpolation} \\ \hline
Tension Parameter (amp) & \replacetext{[0.5, 2.5]}{\{1,3,5,8,10,12,15,20\}} & \replacetext{Tau values for amplitude tension spline (uniform; used when spline type is tension)}{Tau values for amplitude spline (when tension type)} \\ \hline
Noise Probability & \replacetext{80\%}{50\%} & Probability of adding noise to each signal \\ \hline
Random Seed & \replacetext{42}{10000--12499} & \replacetext{Global seed used to deterministically reproduce the official dataset release}{Unique seed per signal for reproducibility} \\ \hline
\end{tabular}
\caption{Signal generation parameters used to create diverse temporal patterns within the CoSiBD dataset. \replacetext{All parameters are documented in metadata files, enabling deterministic regeneration of the official dataset release.}{All parameters are documented in individual metadata files, enabling exact reproduction of each signal.} These parameters control the frequency composition and temporal structure.}
\label{tab:Parameter}
\end{table}

\noindent
\addtext{To explicitly characterize dataset diversity and complexity, CoSiBD spans multiple controlled axes of variation (Table~\ref{tab:Parameter}), including the number and location of change points, categorical transition types, low- and high-frequency bands, and amplitude-envelope configurations. This variability is visible in representative realizations (Figures~\ref{fig:amplitud} and~\ref{fig:simples}) and is further quantified in the Technical Validation section through the distribution of dominant frequencies (Figure~\ref{fig:dominant_frequency_distribution} and Table~\ref{tab:density_label}) and PSD behavior under different resolutions and noise settings (Figures~\ref{fig:average_psd} and~\ref{fig:noise_psd}). While the dataset is synthetic and not fitted to match a single domain-specific distribution, these controlled variations provide reproducible coverage of common real-world time-series phenomena, including non-stationarity, transient high-frequency events, and additive noise.}
\\ \\

\noindent Figure~\ref{fig:amplitud} shows a representative signal from the dataset sampled at different resolution levels. This illustrates the multi-resolution structure of CoSiBD and the alignment between high- and low-resolution representations.


\begin{figure}
\centering

% --- Row 1 ---
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/amplitud_high.png}
    \label{fig:amp1}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/amplitud_medium.png}
    \label{fig:amp2}
\end{minipage}

\vspace{0.15cm}

% --- Row 2 (centered single panel) ---
\begin{minipage}{0.6\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/amplitud_low.png}
    \label{fig:amp3}
\end{minipage}

\caption{A synthetic signal sampled at different resolutions: (a) high (5000 points), (b) medium (500 points), and (c) low (250 points). These examples reflect the multi-resolution and noise conditions present in the dataset.}
\label{fig:amplitud}
\end{figure}

\vspace{0.3cm}

\noindent Figure~\ref{fig:simples} displays four additional synthetic signals generated using different configuration parameters. These examples demonstrate the variability in temporal structure across instances in the dataset.
\\ \\
\begin{figure}
\centering
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/simples_high_low.png}
    \label{fig:simp1}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/simples_localized.png}
    \label{fig:simp2}
\end{minipage}

\vspace{0.15cm}

\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/simples_smooth.png}
    \label{fig:simp3}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/simples_irregular.png}
    \label{fig:simp4}
\end{minipage}

\caption{Examples of synthetic signals in the dataset generated with different parameter configurations. Each signal presents a distinct temporal profile.}
\label{fig:simples}
\end{figure}
\noindent The full dataset is publicly available on Zenodo \cite{cosibd_zenodo_2025} and includes the signal files and associated metadata organized in structured folders.


\section*{Technical Validation}
\label{sec:technical-validation}

\replacetext{This section validates the proposed signal generation method by analyzing its spectral properties under different conditions, including the distribution of dominant frequencies, spectral stability across sampling rates, and the effect of noise. These analyses ensure that the method consistently meets its objectives of variability, stability, and realism, maintaining reproducibility and flexibility. Below, the methodologies and results are described in detail.}
{This section evaluates the signal generation procedure by analyzing spectral properties under different conditions, including the distribution of dominant frequencies, spectral stability across sampling rates, and the effect of noise. These analyses aim to assess variability and stability under the reported settings and to document the dataset's behavior for reproducible use. Below, the methodologies and results are described in detail.}

\subsection*{Validation Context}
\deltext{Experimental parameters were carefully selected to ensure reproducibility and
relevance. The number of signals (n=50) was chosen to provide statistically significant
information about the variability and consistency of the generated signals. Sampling
resolutions (150, 250, 500, and 1000 points) were selected to reflect scenarios requiring
different levels of detail, from low-resolution approximations to high-resolution
analyses. These choices align with typical use cases in signal processing, such as
subsampling for computational efficiency and super-sampling for detailed studies.
\\ \\
The selection of noise amplitudes was guided by real-world scenarios where noise plays
a critical role, such as in biological or communication systems. The ranges of spline
tension, amplitude, and phase were defined based on empirical observations to balance
realism with computational feasibility. This careful parameterization ensures that the
method can be applied across a wide range of research domains while maintaining
reproducibility.}\addtext{Experimental parameters were selected to support reproducibility and to illustrate representative behaviors of the generator under the reported settings. The number of signals (n=50) provides a compact but informative sample to summarize variability in spectral characteristics. Sampling resolutions (150, 250, 500, and 1000 samples) reflect scenarios requiring different levels of detail, aligning with typical signal processing use cases. Noise amplitudes and other parameter ranges were motivated by common acquisition artifacts and exploratory checks, with the goal of providing a controllable benchmark rather than an exhaustive model of any specific measurement pipeline.}

\subsection*{Analysis of Dominant Frequency Distribution}

To assess the stability and variability of the primary spectral components, we analyzed the distribution of dominant frequencies across multiple generated signals. A total of fifty independent signals were synthesized using identical input parameters. To examine their spectral characteristics, we computed the power spectral density (PSD) of each signal, which quantifies how signal power is distributed across different frequencies.
\\ \\
The PSD was estimated using Welch’s method, selected for its ability to reduce noise and provide a smoother spectral representation \cite{Welch1967}. \replacetext{This method achieves better spectral estimation by dividing the signal into overlapping segments, computing their individual spectra, and averaging them. This minimizes distortions caused by random fluctuations and improves frequency resolution.}{This method stabilizes spectral estimation by dividing the signal into overlapping segments, computing their individual spectra, and averaging them. This reduces variance from random fluctuations and yields a smoother estimate.} For each signal, the dominant frequency was identified as the frequency at which the PSD reaches its maximum value. This corresponds to the most prominent spectral component, indicating where the signal concentrates most of its energy.
\\ \\
\replacetext{By analyzing the distribution of dominant frequencies across the dataset, we evaluate whether the generated signals exhibit consistent spectral patterns or if there is significant variation. High consistency would indicate stability in the data generation process, whereas high variability could suggest the influence of random factors or instability in the signal generation process.}
{By analyzing the distribution of dominant frequencies across the dataset, we characterize the range and spread of the primary spectral components produced by the generator. This analysis documents how dominant frequencies are distributed under fixed generation settings, capturing both repeated structural patterns and the controlled variability introduced by randomized parameters, without implying optimality or domain-specific realism.}
\\ 

\begin{figure}
    \centering
    \includegraphics[width=0.56\textwidth]{graphs/analysis_densidad.png}
    \caption{Distribution of dominant frequencies in 50 independently generated signals (reported in Hz under the illustrative convention $T=4\pi$\,s; for other choices of $T$, the Hz axis rescales by $4\pi/T$).}
    \label{fig:dominant_frequency_distribution}
\end{figure}

\begin{table}
\centering
\small
\begin{tabular}{|l|l|}
\hline
Statistic  & Value (Hz; illustrative $T=4\pi$\,s) \\
\hline
Average Dominant Frequency  & 0.508 \\
Standard Deviation  & 0.195 \\
Minimum Dominant Frequency  & 0.390 \\
Maximum Dominant Frequency  & 1.171 \\
\hline
\end{tabular}
\caption{\label{tab:density_label}Summary statistics of dominant frequencies, including average, standard deviation, and extreme values.}
\end{table}

\noindent
\deltext{The results, shown in Figure 4 and Table 3, demonstrate that the dominant frequencies are predominantly concentrated in
the low-frequency range (0.4 to 0.8 Hz), with sporadic occurrences of higher frequencies (1.1 to 1.2 Hz). This reflects the
method’s ability to generate signals with consistent primary structures while introducing controlled variability. Such flexibility is beneficial for applications requiring limited spectral variability while maintaining the predominance of low frequencies.}
\addtext{\noindent The results, shown in Figure~\ref{fig:dominant_frequency_distribution} and Table~\ref{tab:density_label}, show that the dominant frequency values (reported in Hz under the illustrative convention $T=4\pi$\,s) are concentrated in a low-frequency range, with occasional higher-frequency occurrences under the same convention. For other choices of $T$, these values rescale linearly by $4\pi/T$. This behavior reflects the method's ability to generate signals with consistent primary structures while introducing controlled variability.}

\noindent Figure \ref{fig:noise_ruido} presents examples of signals from the CoSiBD dataset with increasing levels of added noise, illustrating how amplitude fluctuations progressively obscure the underlying temporal structure.

\begin{figure}[H] \centering \begin{minipage}{0.47\textwidth} \centering \includegraphics[width=\textwidth]{graphs/ruido1.png} \subcaption{Low-noise signal, where amplitude variations are present but minimally distorted.} \label{fig:noise1} \end{minipage} \hspace{0.02\textwidth} \begin{minipage}{0.47\textwidth} \centering \includegraphics[width=\textwidth]{graphs/ruido2.png} \subcaption{Moderate-noise signal, with irregular peaks and troughs beginning to distort the oscillatory pattern.} \label{fig:noise2} \end{minipage}

\vspace{0.15cm}

\begin{minipage}{0.47\textwidth} \centering \includegraphics[width=\textwidth]{graphs/ruido3.png} \subcaption{High-noise signal, where significant distortion leads to unpredictable fluctuations.} \label{fig:noise3} \end{minipage} \hspace{0.02\textwidth} \begin{minipage}{0.47\textwidth} \centering \includegraphics[width=\textwidth]{graphs/ruido4.png} \subcaption{Extreme-noise signal, where the original oscillatory structure is almost entirely masked by chaotic interference.} \label{fig:noise4} \end{minipage}

\caption{Visualization of signals under increasing noise conditions, showing how added noise progressively masks the original temporal patterns. From low (a) to extreme noise levels (d), this degradation highlights reconstruction challenges for super-resolution models.} \label{fig:noise_ruido} \end{figure}

\subsection*{Spectral Stability Across Sampling Resolutions}
\deltext{This analysis aims to investigate the influence of sampling resolution on the robustness of spectral estimates under varying
frequency content. At lower resolutions, aliasing can obscure critical frequency peaks, compromising the ability to distinguish
closely spaced spectral components \cite{Rabiner1975}. Conversely, higher resolutions improve the granularity of the frequency axis, allowing
for better separation of spectral features and reducing the risk of misrepresenting the signal’s underlying structure \cite{Marple1987}.}
\addtext{This analysis aims to investigate the influence of sampling resolution (number of samples) on the robustness of spectral estimates under varying frequency content. When frequency axes are reported in Hz, they follow the illustrative convention $T=4\pi$\,s; for other choices of $T$, the Hz axis rescales by $4\pi/T$. At lower resolutions, reduced sampling density and coarser frequency grids can obscure or merge spectral peaks, compromising the ability to distinguish closely spaced spectral components \cite{Rabiner1975}. Conversely, higher resolutions improve the granularity of the frequency axis, allowing for better separation of spectral features and reducing the risk of misrepresenting the signal’s underlying structure \cite{Marple1987}.}
\\ \\
\deltext{Ultimately, this evaluation seeks to determine the sampling resolution that optimizes both spectral fidelity and practical utility. By quantifying the relationship between resolution and spectral stability, this approach provides a framework for selecting appropriate sampling rates in real-world applications, ensuring accurate frequency-domain analysis while managing computational resources efficiently.}
\addtext{This evaluation documents how spectral summaries vary with sampling resolution under the reported settings. The intent is to provide descriptive context for using CoSiBD at different resolutions (and computational budgets) in benchmark protocols, rather than to prescribe a universal sampling rate.}
\\ 
\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{graphs/psd.png}
    \caption{\replacetext{Average power spectral density (PSD) for different sampling resolutions based on 50 independent runs.}{Average power spectral density (PSD) for different sampling resolutions based on 50 independent runs (Hz axis under the illustrative convention $T=4\pi$\,s).}}
    \label{fig:average_psd}
\end{figure}

\noindent
\replacetext{As shown in Figure~\ref{fig:average_psd}, lower sampling resolutions, specifically the blue curve (150 samples) and the orange curve (250 samples), exhibit a noticeable reduction in detail within the higher-frequency range (reported in Hz under the illustrative convention $T=4\pi$\,s). These lower-resolution curves display greater fluctuations, particularly at higher frequencies under this convention, which is consistent with the theoretical effects of subsampling. The blue curve (150 samples) is especially affected, showing significant variability and a less stable spectral representation in the higher frequencies.}
{As shown in Figure 6, lower sampling resolutions, specifically the blue curve (150 points) and the orange curve (250 points), exhibit a noticeable reduction in detail within the high-frequency range. These lower-resolution curves display greater fluctuations and noise, particularly beyond 20 Hz, which is consistent with the theoretical effects of subsampling. The blue curve (150 points) is especially affected, showing significant variability and a less stable spectral representation in the higher frequencies.}
\\ \\ 
\noindent
In contrast, the higher sampling \deltext{demonstrate}\addtext{resolutions demonstrate} a smoother and more stable spectral profile across all frequencies. The red curve (1000 \deltext{points}\addtext{samples}), in particular, captures finer details and exhibits minimal high-frequency noise, \replacetext{making it the most reliable for precise spectral analysis.}{making it the smoothest estimate among the reported settings.}

\subsection*{Impact of Noise on Frequency Characteristics}
\deltext{Analyzing the impact of noise on frequency characteristics is a critical step in validating the robustness and reliability of spectral analysis methods. Understanding how noise influences the Power Spectral Density (PSD) allows for the assessment of a method’s sensitivity and its ability to preserve essential signal features despite the presence of interference.}
\addtext{The effect of varying noise amplitude on the power spectral density (PSD) is analyzed, with particular attention to differences between low- and high-frequency regions.}
\\ 
\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{graphs/noise.png}
    \caption{Power spectral density (PSD) of signals generated with different noise amplitudes (Hz axis under the illustrative convention $T=4\pi$\,s).}
    \label{fig:noise_psd}
\end{figure}

\noindent \replacetext{Figure~\ref{fig:noise_psd} illustrates the impact of different noise amplitudes on the Power Spectral Density (PSD). As the noise amplitude increases—from 0.0 (blue curve) to 0.2 (red curve)—there is a noticeable rise in variability at higher frequencies, particularly beyond 10 Hz, while the low-frequency region remains comparatively stable.}{Figure~\ref{fig:noise_psd} illustrates the impact of different noise amplitudes on the Power Spectral Density (PSD) under the reported settings (Hz axis under the illustrative convention $T=4\pi$\,s). As the noise amplitude increases—from 0.0 (blue curve) to 0.2 (red curve)—the estimated PSD exhibits increased variability at higher frequencies, while the low-frequency region remains comparatively stable in these plots.}
\\ \\
\noindent
Across these settings, the low-frequency region changes less than the higher-frequency region in these estimates. This observation provides context for the subsequent super-resolution benchmark, where both time-domain and frequency-domain metrics are reported.

\subsection*{Multi-Scale Super-Resolution Benchmark}
\label{sec:multiscale-super-resolution-benchmark}

To illustrate a representative baseline use case of CoSiBD and to document expected behavior across different upsampling regimes, reference results are reported for temporal super-resolution at multiple scaling factors. Four upsampling factors are considered: 5$\times$, 10$\times$, 20$\times$, and 33$\times$, corresponding to low-resolution inputs of 1000, 500, 250, and 150 samples reconstructed to the 5,000-sample high-resolution target.
\\ \\
\noindent
The 2,500 high-resolution signals are partitioned into an experiment-specific split of 2,000 paired signals for training and 500 signals for validation. This split is used solely for the reported benchmark and is not distributed as a predefined dataset partition. The purpose of this benchmark is not to optimize model performance or establish state-of-the-art results, but to provide a reproducible reference illustrating how reconstruction difficulty scales with increasing upsampling factor when using CoSiBD.
\\ \\
\noindent
Table~\ref{tab:multiscale_benchmark} summarizes validation performance across the considered scaling factors. Validation loss increases systematically with upsampling factor, reflecting the inherent difficulty of reconstructing fine temporal details from severely undersampled inputs.
\\ \\
\begin{table}[h]
\centering
\small
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Input Size} & \textbf{Factor} & \textbf{Val. Loss (MSE)} & \textbf{LSD} & \textbf{SCORR} \\
\hline
1000 samples & 5$\times$  & 0.0845 & 0.51$\pm$0.63 & 0.98$\pm$0.10 \\
500 samples  & 10$\times$ & 0.1524 & 0.64$\pm$0.63 & 0.98$\pm$0.10 \\
250 samples  & 20$\times$ & 0.4376 & 0.95$\pm$0.67 & 0.98$\pm$0.10 \\
150 samples  & 33$\times$ & 1.0326 & 1.21$\pm$0.67 & 0.98$\pm$0.11 \\
\hline
\end{tabular}
\caption{Reference multi-scale super-resolution results on CoSiBD. Validation loss is reported as mean squared error (MSE) over 500 validation signals. Log Spectral Distance (LSD; lower is better) and Spectral Correlation (SCORR; higher is better) quantify spectral fidelity of reconstructed signals. Results are provided as illustrative baselines rather than optimized performance targets.}
\label{tab:multiscale_benchmark}
\end{table}

\noindent Spectral fidelity metrics show a systematic increase in reconstruction difficulty with upsampling factor: Log Spectral Distance (LSD) increases from 0.51 at 5$\times$ to 1.21 at 33$\times$, while Spectral Correlation (SCORR) remains consistently high across all factors. This indicates that, although fine-scale details become harder to recover at extreme upsampling ratios, the dominant spectral structure is largely preserved.
\\ \\
\noindent
Overall, these results provide a compact, reproducible reference for the expected behavior of CoSiBD under increasingly challenging super-resolution settings, supporting its use as a benchmark dataset rather than as a platform for model comparison.

\section*{Usage Notes}
\label{sec:usage-notes}

\replacetext{
The CoSiBD dataset contains paired low- and high-resolution temporal signals in plain text format. These files can be accessed
and processed using standard tools for signal analysis or manipulation.
}{
The CoSiBD dataset contains high-resolution signals and corresponding subsampled versions at multiple resolutions. Signals are provided in consolidated \texttt{.txt}, \texttt{.npz}, and \texttt{.json} formats. Pairing between low- and high-resolution versions is performed by row index: row $i$ in a subsampled file corresponds to row $i$ in the high-resolution file, with per-signal parameters available in \texttt{signals\_metadata.json}.
}
\addtext{
The dataset is distributed as a single, unified collection without a predefined train/validation/test split. Users can create partitions appropriate to their objectives (e.g., random splits, stratified splits by noise type or signal characteristics, cross-validation, or scenario-specific test sets), using the provided metadata to support principled partitioning.
}

\subsection*{Reading the Data}

CoSiBD is distributed as consolidated plain-text (\texttt{.txt}) files in which each row corresponds to a single temporal signal (samples separated by whitespace). Low- and high-resolution signals are aligned by row index: row $i$ in a subsampled file corresponds to row $i$ in the high-resolution file. Per-signal generation parameters are provided in the accompanying metadata file (\texttt{signals\_metadata.json}) using the same indexing scheme.

The following example illustrates how to load paired low- and high-resolution signals using standard Python tools:

\begin{verbatim}
import numpy as np

# Load subsampled (simple decimation) and high-resolution signals
# Each .txt file is consolidated: one signal per row
x_lr = np.loadtxt('SignalBuilderC/data/signals_subsampled_simple_250.txt')
x_hr = np.loadtxt('SignalBuilderC/data/signals_high_resolution_5000.txt')

# Access a paired signal by row index
i = 0
low_res_signal  = x_lr[i]
high_res_signal = x_hr[i]
\end{verbatim}

These commands return NumPy arrays where each row corresponds to one signal. Users may optionally convert the arrays to other formats or frameworks depending on their analysis pipeline.

\subsection*{Visualizing Paired Signals}

To inspect the alignment between low- and high-resolution versions, users can visualize paired signals indexed by the same row:

\begin{verbatim}
import matplotlib.pyplot as plt
import numpy as np

# Visualize a paired low- and high-resolution signal
i = 0
plt.figure(figsize=(10, 4))

# High-resolution signal
plt.plot(high_res_signal, label='High-resolution (5000 samples)', alpha=0.8)

# Low-resolution signal (aligned to HR index range for visualization)
lr_x = np.linspace(0, len(high_res_signal), len(low_res_signal))
plt.scatter(lr_x, low_res_signal, color='red', s=12,
            label='Low-resolution (250 samples)')

plt.xlabel('Sample index')
plt.ylabel('Amplitude')
plt.title('Paired Low- and High-Resolution Signal')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
\end{verbatim}

This visualization highlights how the same underlying temporal structure is represented at different resolutions while preserving alignment between paired signals. Additional signal characteristics (e.g., change-points, frequency profiles, or noise configuration) can be retrieved from \texttt{signals\_metadata.json} using the same row index.

\section*{Code availability}
\label{sec:code-availability}

\noindent
The full signal generation pipeline used to create the CoSiBD dataset is openly available in a public GitHub repository:  
\href{https://github.com/DhamarAM/SignalBuilder/tree/main}{SignalBuilderC (CoSiBD scripts)}.
\\ \\
\noindent
The repository provides a modular Python package (\texttt{SignalBuilderC}) implementing all stages of the dataset construction process, including: (i) generation of high-resolution synthetic temporal signals with configurable frequency profiles and amplitude envelopes; (ii) deterministic creation of paired low-resolution signals via uniform subsampling; (iii) optional noise injection; and (iv) export of signals and associated metadata in NumPy (\texttt{.npz}), plain-text (\texttt{.txt}), and JSON (\texttt{.json}) formats. The codebase is documented and includes example scripts and notebooks illustrating dataset generation, regeneration from metadata, and basic data access.
\\ \\
\noindent
All source code is released under the MIT License, allowing reuse and extension of the generation framework for research and benchmarking purposes.

\vspace{0.3cm}
\noindent
The CoSiBD dataset itself is published separately on Zenodo and is cited in the Data Records section~\cite{cosibd_zenodo_2025}.  
The Zenodo record distributes the dataset under the Creative Commons Attribution 4.0 International (CC BY 4.0) license.


% ===== BIBLIOGRAPHY =====
% Using BibTeX with naturemag-doi style for Nature Scientific Data
% References stored in referencias.bib
% Note: \bibliographystyle{naturemag-doi} is defined in wlscirep.cls
\bibliography{referencias}



\section*{Acknowledgments}
This research was supported by Dean's Office of the Polytechnic College of the San Francisco de Quito University  and partially by ProyExcel-0069 project of the Andalusian University, Research and Innovation Department.

\section*{Author Contributions}
J. I. F. handled the methodological design for artificial data creation, probabilistic analysis, spline-based variations, noise distributions, and random node selection. J. A. L. was responsible for the time series methodological design. D. A. M. performed data processing and validation analysis. All of the authors have contributed to writing the manuscript.

\section*{Competing Interests}
The authors declare no competing interests.

\end{document}