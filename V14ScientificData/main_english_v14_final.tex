\documentclass[fleqn,10pt]{wlscirep}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lineno}
 %\usepackage{multirow}
\usepackage{array}  % Añade esto en el preámbulo
\renewcommand{\arraystretch}{1.3}  % Espaciado vertical entre filas

\usepackage{subcaption}
\captionsetup[subfigure]{font=footnotesize}
% Consistent panel labels: bold literal + short descriptor
\newcommand{\panelcap}[2]{\subcaption*{\textbf{(#1)}~#2}}
\linenumbers
\usepackage{float}
\usepackage{enumitem}
\usepackage{tabularx}
\usepackage{booktabs}

% ===== CLEAN VERSION (NO TRACK CHANGES) =====
\usepackage{xcolor}
\usepackage{parskip}
% \setlength{\parindent}{0pt}
% \setlength{\parskip}{0.6\baselineskip}   % espacio entre párrafos ≈ 0.6 líneas
% ===== END TRACK CHANGES =====  

%\title{CoSiBD: A Versatile Dataset for Benchmarking Signal Processing and Machine Learning Algorithms}
%\title{CoSiBD: A Synthetic Dataset for Super-Resolution Deep Learning Temporal Series Analysis}
%\title{A synthetic dataset for super-resolution of Time Series using Deep Learning}
\title{A synthetic dataset for Time Series Super-Resolution with Deep Learning}
\author[1]{Julio Ibarra-Fiallo}
\author[1]{D'hamar Agudelo-Moreno}
\author[2]{Juan A. Lara}
%\author[2,*]{autor }
\affil[1]{Colegio de Ciencias e Ingenierías, Universidad San Francisco de Quito, Cumbayá, Ecuador}
\affil[2]{Universidad de Córdoba, Córdoba, España}

\affil[*]{corresponding author: Julio Ibarra-Fiallo (jibarra@usfq.edu.ec)}


\begin{abstract}
The increasing application of time-series analysis in fields like biomedical engineering or telecommunications emphasizes the need for high-quality data to train and evaluate advanced machine learning models. Acquiring real-world temporal data at suitable resolutions is often limited by ethical, economic, or practical constraints. We introduce CoSiBD (Complex Signal Benchmark Dataset for Super-Resolution), a synthetic dataset designed for reproducible time-series super-resolution research. CoSiBD provides 2,500 high-resolution signals ($N=5{,}000$ samples each over a reference domain $\tau\in[0,4\pi]$) with aligned low-resolution versions at four levels (150, 250, 500, and 1,000 samples) obtained via uniform decimation. Signals are generated with diverse non-stationary behaviors through piecewise frequency modulation and spline-based amplitude envelopes, and provides both clean and noisy variants. Signals are distributed as NumPy arrays, plain text, and JSON, with comprehensive metadata describing segment structure, generation parameters, and seeds for full reproducibility. Technical validation of the dataset analyzes spectral properties and reports baseline SR benchmarking and transfer experiments on EEG and speech to illustrate utility on real-world signals super-resolution.
\end{abstract}


\begin{document}

\flushbottom
\maketitle

\section*{Background \& Summary}
\label{sec:background-summary}

The analysis and simulation of temporal signals are fundamental across science and engineering. These techniques provide critical insights into dynamic processes in multiple domains. For instance, in biomedical research, physiological time series such as electroencephalography (EEG) and electrocardiography (ECG) support the study of neural and cardiac function \cite{Luciw2014,Nayak2023,shaffer2017}. Another example is telecommunications, which rely on signal processing to ensure data fidelity across noisy media \cite{Chen2022}. Developing robust tools for interpreting time-varying data continues to support both scientific discovery and practical applications.

Recent advances in deep learning have contributed significantly to this field by enabling automatic extraction of complex features from raw signals. Deep learning approaches, such as Convolutional Neural Networks (CNNs) or Generative Adversarial Networks (GANs) have demonstrated improved performance over traditional techniques in image, speech, and time-series processing tasks \cite{Lecun2015,Goodfellow2014}. These models support fine-grained signal reconstruction, allowing researchers to explore temporal dynamics in new ways.

Despite this progress, deep learning methods for temporal signal processing often require large quantities of labeled, high-quality data. Access to such data is frequently constrained. For instance, in medicine, data access is constrained by medical privacy regulations such as the General Data Protection Regulation (GDPR) and the Health Insurance Portability and Accountability Act (HIPAA) \cite{Isasa2024}. In other domains, including telecommunications, data availability is limited by proprietary protocols and the high cost of acquiring large-scale channel sounding datasets for diverse environments \cite{Zhang2016}. These limitations are particularly relevant in super-resolution (SR) tasks, where models require paired low- and high-resolution signals for effective training. Here, temporal SR refers to reconstructing a higher-sample-count (higher temporal resolution) discrete sequence from a uniformly decimated low-resolution version.

This task has broad potential. In biomedical monitoring and sensing, for instance, SR can help reconstruct higher-resolution physiological time series (e.g., EEG), potentially improving the analysis of subtle physiological irregularities \cite{shaffer2017}. SR also applies to audio/speech enhancement and telecommunications (e.g., neural audio upsampling and bandwidth extension, relevant to telephony and compression) \cite{Kuleshov2017,IbarraFiallo2024}.

Deep learning offers adaptive alternatives to these traditional methods. For instance, CNNs are capable of modeling spatio-temporal structure present in real datasets across these domains. Preliminary work on synthetic time-series generation indicates potential for SR \cite{Brophy2023,IbarraFiallo2024}, but the lack of accessible, high-quality paired datasets remains a significant barrier to progress.

Synthetic datasets offer one solution to this problem, allowing researchers to design reproducible training environments that reflect the characteristics of real-world signals. Prior studies have used synthetic data in domains such as biomedical signal analysis \cite{mcsharry2003ecg} and wireless communications \cite{oshea2016grcon}, demonstrating that synthetic approaches can help simulate complexity while avoiding legal and practical restrictions associated with real-world data.

To support research in super-resolution for time-series data, we present the Complex Signal Benchmark Dataset (CoSiBD). CoSiBD is a synthetic dataset composed of time-series signals with variable resolution, frequency characteristics, and noise levels. As it is designed to resemble real-world signals, our dataset is intended with a double purpose: a) to provide a resource for training and evaluating deep learning SR models under controlled, reproducible conditions, which can constitute a sort of benchmark for this problem; and b) a resource for training deep learning models to be used for SR of real-world signals (either directly or finetuning them with the real data), particularly in scenarios where real signals are scarce and not enough for a complete training of those models. It includes non-stationary, piecewise-structured signals (via non-uniform interval partitioning with change-points), multiple levels of resolution and noise, a technical validation suite, and publicly available Python code to facilitate use. CoSiBD has been previously used in research presented at the International Conference on Signal Processing and Machine Learning~\cite{IbarraFiallo2024}, with good prelimary results for signal reconstruction using deep learning. CoSiBD is made available to support further development in deep learning approaches for temporal super-resolution.

To further position CoSiBD with respect to existing public synthetic time-series resources, we summarize in the next subsection representative datasets and simulators and highlight the practical gap addressed by our approach.

\subsection*{Related synthetic time-series resources}

Publicly available synthetic resources for temporal signals exist, but they are typically designed for tasks other than time-series SR, or they target a specific domain. In wireless communications, the RadioML family provides large collections of synthetic complex I/Q sequences with varying SNR (Signal-to-noise ratio) and channel impairments, mainly to benchmark automatic modulation classification rather than paired SR reconstruction \cite{oshea2016grcon,deepsig_datasets,deepsig_radioml2018}. In biomedical signal processing, physiological simulators such as ECGSYN (electrocardiography) and SEREEGA (EEG) enable controlled generation with tunable morphology, sampling settings, and noise, supporting method development when real data access is constrained \cite{mcsharry2003ecg,ecgsyn_physionet,krol2018sereega}. In power systems, LoadGAN provides multi-resolution generation of load time series across sampling rates and time horizons (from sub-second to long-term scales), but it is not distributed as a standardized paired SR benchmark \cite{pinceti2021loadgan}. Domain-specific paired low-/high-resolution training data can also be produced via physical forward modeling, e.g., low- and high-resolution 1D seismic traces for learning-based resolution enhancement \cite{yuan2024seismic}.

Table~\ref{tab:related_synthetic_datasets} provides a concise view of representative public synthetic resources for temporal signals and clarifies how they relate to the specific needs of time-series super-resolution (SR). We summarize each resource by its target \textit{Domain} and \textit{Form} (fixed dataset vs.\ simulator/generator), and we highlight practical properties that determine whether a resource can be used as an SR benchmark: whether it provides \textit{paired LR--HR data}, whether it supports \textit{multi-resolution} generation, what \textit{noise/artifact} mechanisms are available, and the \textit{reproducibility granularity} (dataset-level variability vs.\ per-signal deterministic regeneration).

Overall, existing resources offer important strengths but also exhibit limitations when viewed through an SR-benchmark lens. Domain-specific datasets such as RadioML provide large-scale controlled variability (e.g., SNR and channel impairments) and are highly valuable for tasks like modulation classification, but they are not distributed as paired LR--HR SR targets. On the other hand, physiological simulators (e.g., ECGSYN and SEREEGA) enable flexible generation with tunable morphology, sampling settings, and noise, which in principle can be used to create LR--HR pairs; however, they typically do not provide a standardized, fixed paired benchmark designed explicitly for SR evaluation across multiple difficulty levels. Similarly, multi-resolution generators in other domains may capture realistic structure at multiple sampling rates, but often lack an aligned, reproducible LR--HR pairing protocol and a unified dataset release that facilitates direct, comparable benchmarking across methods.

These observations motivate the need for a public resource that combines: (i) fixed, aligned LR--HR pairs for SR, (ii) controllable nuisance modeling (noise and structured interference), and (iii) strong reproducibility at the per-signal level, while remaining broad enough to support benchmarking and transfer across domains.

CoSiBD is designed to close the gap by providing a fixed, standardized set of LR--HR pairs with explicit nuisance modeling (noise and structured interference) and comprehensive metadata, enabling reproducible benchmarking across multiple difficulty levels (defined by varying downsampling factors and noise intensities).

\begin{table*}[t]
\centering
\begingroup
\scriptsize
\setlength{\tabcolsep}{3pt}
\renewcommand{\arraystretch}{1.2}
\begin{tabularx}{\textwidth}{|>{\raggedright\arraybackslash}p{2.2cm}|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}p{1.4cm}|>{\raggedright\arraybackslash}p{1.6cm}|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|}
\hline
\textbf{Resource} & \textbf{Domain} & \textbf{Form} & \textbf{Paired LR--HR SR} & \textbf{Multi-resolution} & \textbf{Noise / artifacts} & \textbf{Reproducibility granularity} \\
\hline
\textbf{CoSiBD (this work)} &
Generic time series (complex-structured signals) &
Dataset + generator &
Yes (LR $\rightarrow$ HR targets) &
Yes ($150/\allowbreak250/\allowbreak500/\allowbreak1000 \rightarrow 5000$) &
Gaussian + structured interference; primary benchmark uses direct decimation &
Per-signal metadata; deterministic regeneration (seed-controlled) \\
\hline
RadioML 2016.10A \cite{oshea2016grcon,deepsig_datasets} &
Wireless communications (I/Q) &
Dataset &
No (classification benchmark) &
N/A (not SR) &
Variable SNR + channel impairments &
Dataset-level (labels/\allowbreak SNR); not per-sample ``recipe'' \\
\hline
RadioML 2018.01A \cite{deepsig_radioml2018} &
Wireless communications (I/Q) &
Dataset &
No (classification benchmark) &
N/A (not SR) &
Simulated channel effects + SNR variability &
Dataset-level; not SR-paired \\
\hline
ECGSYN \cite{mcsharry2003ecg,ecgsyn_physionet} &
ECG (physiology) &
Simulator/tool &
Configurable &
Configurable (via sampling settings) &
Model-based; supports controlled variability &
Configurable via simulator parameters (user-defined) \\
\hline
SEREEGA \cite{krol2018sereega} &
EEG (physiology) &
Simulator/\allowbreak toolbox &
Configurable &
Configurable (user-defined) &
Supports noise and event-related components &
Configurable via simulator parameters (user-defined) \\
\hline
LoadGAN \cite{pinceti2021loadgan} &
Power systems load time series &
Generator/tool &
No (generation) &
Yes (variable sampling rates) &
Domain-specific variability (load patterns) &
Tool-based; generation is configurable \\
\hline
Synthetic LR--HR seismic traces (example) \cite{yuan2024seismic} &
Seismic traces (geophysics) &
Paper-specific paired data &
Yes (LR--HR pairs) &
Typically limited (study-specific) &
Study-dependent &
Paired data available for the study; limited generality \\
\hline
\end{tabularx}
\endgroup
\caption{Representative publicly available synthetic time-series datasets and simulators related to signal processing and learning.}
\label{tab:related_synthetic_datasets}
\end{table*}

\section*{Methods}
\label{sec:methods}

The methodology used to generate the synthetic temporal signals that constitute the CoSiBD dataset is illustrated in Figure~\ref{fig:generation_process}, and will be explained later. The signal generation process is designed to produce time series exhibiting structural properties commonly observed in real-world temporal data, including variable frequency content, smooth transitions, and intermittent high-frequency activity. A key aspect of the procedure is the generation of signals at multiple temporal resolutions, enabling the construction of paired datasets for super-resolution (SR) benchmarking.

\begin{figure}
    \centering
    \includegraphics[width=0.35\textwidth]{diagrams/generation_process4.png}
    \caption{Schematic overview of the CoSiBD signal generation process.}
    \label{fig:generation_process}
\end{figure}

\textbf{Design rationale inspired by real signals.} It is important to note that one of the main applications of the proposed dataset will be the training of deep learning models to be used for SR purposes in other real-world datasets, like, for instance, physiological or speech signals. Therefore, there is a need for our dataset to resemble real-world data. In particular, real signals exhibit (i) non-stationary regime changes, (ii) coexisting low- and high-frequency components with intermittent transients, (iii) smooth amplitude-envelope evolution, and (iv) slow baseline drift and measurement noise. CoSiBD instantiates these properties via non-uniform interval partitioning with change-points, separate low/high-frequency bands, spline-based envelopes and frequency profiles, and explicit offset/noise terms. Figure~\ref {fig:design_rationale_motivations} provides qualitative examples of these motivating properties found in real-world time series; the main goal of our dataset is to be able to capture challenging structure for SR benchmarking rather than match a specific domain distribution.

 The design of CoSiBD is informed by the inherent limitations of standard synthetic datasets in capturing the irregular morphologies of real-world signals. As shown in Figure~\ref{fig:design_rationale_motivations}, physiological signals such as ECG or EEG (\textbf{\subref{fig:motivations_physio_time}--\subref{fig:motivations_physio_psd}}) are rarely stationary, often exhibiting abrupt regime shifts and highly structured spectral components that pose significant challenges for temporal reconstruction. By implementing explicit change-points and multi-band frequency partitioning, CoSiBD attempts to approximate these localized dynamics, providing a more demanding benchmark than globally stationary models.

 Similarly, the inclusion of spline-based modulation seeks to address the continuous but non-linear fluctuations observed in acoustic data (\textbf{\subref{fig:motivations_speech_time}--\subref{fig:motivations_speech_f0}}). The amplitude envelopes and F0 trajectories in speech represent a level of temporal complexity that rigid parametric approaches often oversimplify. Using smooth spline profiles allows the framework to emulate these high-order dependencies without assuming a fixed functional form. This ensures that the resulting dataset, while still synthetic, exposes super-resolution models to the morphological variability—such as pitch drifting and dynamic scaling—required for generalization to authentic signals.

\begin{figure}

    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{graphs/r1_3_design_rationale/r1_3_real_signal_motivations01.jpg}
        \subcaption{Physiological example: ECG/EEG like waveform}
        \label{fig:motivations_physio_time}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{graphs/r1_3_design_rationale/r1_3_real_signal_motivations02.jpg}
        \subcaption{Physiological PSD (Welch, qualitative).}
        \label{fig:motivations_physio_psd}
    \end{minipage}



    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{graphs/r1_3_design_rationale/r1_3_real_signal_motivations03.jpg}
        \subcaption{Speech example: waveform + amplitude envelope}
        \label{fig:motivations_speech_time}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{graphs/r1_3_design_rationale/r1_3_real_signal_motivations04.jpg}
        \subcaption{Speech example: pitch trend (F0)}
        \label{fig:motivations_speech_f0}
    \end{minipage}

    \caption{Qualitative real-signal properties motivating the CoSiBD design, specifically non-stationarity and spectral structure in physiological data, and envelope-pitch dynamics in speech.}
    \label{fig:design_rationale_motivations}
\end{figure}


 The signal generation pipeline involves the following steps:

\begin{enumerate}
    \item \textbf{Base frequency band definition:} A set of distinct frequency bands is defined to represent the underlying spectral content of the signals. These can be adjusted to reflect application-specific characteristics.

    \item \textbf{Non-uniform interval partitioning:} The total signal duration is divided into multiple intervals of variable length. The interval lengths are determined probabilistically to introduce variability in the signal structure.

    \item \textbf{Frequency assignment:} Each interval is assigned a dominant frequency band, sampled according to a predefined probability distribution. This introduces spectral variation over time.

    \item \textbf{Signal synthesis:} A sinusoidal waveform, or a combination of sinusoids within the assigned frequency band, is generated for each interval. Signal parameters such as amplitude and phase are configurable.

    \item \textbf{Transition smoothing:} To avoid discontinuities at interval boundaries, a smoothing function is applied to overlapping segments. This ensures gradual transitions between intervals with different frequency content.

    \item \textbf{Resolution variation:} All signals are initially synthesized at a high temporal resolution (5,000 samples over the domain [0, 4$\pi$]). Lower-resolution versions are created using simple decimation (uniform subsampling). This keeps the SR task aligned with reconstructing the original high-resolution target; the low-resolution observation is obtained by subsampling the original sequence without pre-filtering. Reconstructing low-pass filtered signals is not an objective of CoSiBD. For reproducibility, given a high-resolution sequence $x_{\mathrm{HR}}[n]$ of length $N=5000$ and a target low-resolution length $M\in\{1000,500,250,150\}$, we form $x_{\mathrm{LR}}[i]=x_{\mathrm{HR}}[n_i]$ using the fixed index set $n_i=\left\lfloor \frac{i\,(N-1)}{M-1}+0.5\right\rfloor$ for $i=0,\ldots,M-1$ (applied identically to the time array). This reduces to standard stride decimation when $M$ divides $N$.

    \item \textbf{Noise injection:} Controlled levels of synthetic noise are added to the signals to emulate different data acquisition scenarios. Two noise types are implemented: (1) Additive white Gaussian noise (AWGN) with configurable standard deviation (relative to signal RMS amplitude), representing broadband sensor thermal noise; and (2) structured sinusoidal noise bursts (deterministic sinusoidal components), representing narrow-band interference such as powerline hum (50/60\,Hz). Noise is applied probabilistically (in the released dataset, \texttt{noise\_profile} records \texttt{p\_has\_noise}=0.5 per signal, and the realized subset with noise is approximately half). When noise is present, the specific parameters (type, amplitude, frequency for structured noise) are recorded in the metadata, allowing users to benchmark denoising or super-resolution under specific degradation conditions.
\end{enumerate}

\textbf{Rationale for structured 50/60\,Hz interference and noise.} Real measurement pipelines frequently contain narrow-band interference (e.g., mains hum) superimposed on broadband sensor noise. To reflect this common acquisition artifact, CoSiBD includes an optional structured sinusoidal component in addition to Gaussian noise. CoSiBD signals are generated over a reference domain (by default $\tau\in[0,4\pi]$); interpreting $\tau$ as physical time (and therefore reporting frequencies in Hz) requires an explicit time scaling. Throughout this manuscript we adopt an illustrative convention that maps the reference domain to a duration $T=4\pi$ seconds, under which the structured component can be interpreted as a 50/60\,Hz-like powerline interference term, while the broadband term represents the measurement noise floor.


Figure~\ref{fig:r1_4_powerline_noise} illustrates this qualitative motivation. Subfigure (a) displays a clean synthetic ECG signal, serving as a baseline. Subfigure (b) shows the same signal contaminated with a 50\,Hz sinusoidal component (mimicking powerline interference in Europe/Asia), while (c) illustrates the effect of a 60\,Hz component (typical of the Americas). Subfigure (d) presents the frequency spectrum comparison, clearly showing the narrow-band interference spikes associated with these powerline artifacts. This explicitly models the periodic contamination observed in real recordings~\cite{SornmoLaguna2005}; the intent is not to reproduce a specific device transfer function but to include realistic nuisance factors that SR models must handle.

\begin{figure}
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/powerline_interference_justification01.jpg}
        \subcaption{Clean ECG Signal}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/powerline_interference_justification02.jpg}
        \subcaption{ECG + 50 Hz Powerline (Europe/Asia)}
    \end{minipage}



    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/powerline_interference_justification03.jpg}
        \subcaption{ECG + 60Hz Powerline (Americas)}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/powerline_interference_justification04.jpg}
        \subcaption{Frequency Spectrum Comparison}
    \end{minipage}
    \caption{Qualitative motivation for the structured interference term used in CoSiBD.}
    \label{fig:r1_4_powerline_noise}
\end{figure}

\textbf{Sampling units and frequency interpretation.} CoSiBD signals are provided as discrete sequences $x[n]$ (e.g., $N=5{,}000$ samples) that are directly used as inputs/targets by SR models. The internal generation domain $\tau\in[0,4\pi]$ is a reference parameterization; interpreting it as physical time requires choosing a duration $T$ (in seconds) for the reference interval. Under this convention, the implied sampling rate is $f_s = N/T$ and all frequencies reported in Hz scale linearly with $4\pi/T$. Throughout this manuscript, when reporting example frequencies in Hz we adopt the illustrative convention $T=4\pi$\,s, yielding $f_s \approx 5000/(4\pi) \approx 398\,$Hz; other equally valid mappings exist depending on application. Consequently, any band-specific interpretation in Hz (e.g., ``low/high'' frequency ranges) should be understood under the chosen $T$; changing $T$ rescales all reported Hz values while preserving the underlying discrete sequences, which is a key feature of CoSiBD's design.


Figure~\ref{fig:r1_5_sampling_units} clarifies this convention using three panels (a--c). Panel (a) shows the normalized frequency spectrum (cycles/sample), which is intrinsic to the discrete sequence. Panels (b) and (c) illustrate how this same spectrum maps to physical units (Hz) under different assumed sampling rates: (b) assumes $f_s \approx 397.9$\,Hz (corresponding to $T=4\pi$\,s), while (c) assumes $f_s \approx 1000$\,Hz. This demonstrates that while the discrete data remains identical, the physical interpretation scales with the user-defined duration. % R1-5

\begin{figure}
    \centering
    \begin{minipage}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{graphs/r1_5_sampling_units/r1_5_time_scaling01.png}
        \subcaption{Spectrum vs. normalized frequency}
    \end{minipage}
    \hfill
    \begin{minipage}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{graphs/r1_5_sampling_units/r1_5_time_scaling02.png}
        \subcaption{Mapped to Hz ($f_s \approx 397.9$\,Hz)}
    \end{minipage}
    \hfill
    \begin{minipage}{0.32\textwidth}
        \centering
        \includegraphics[width=\textwidth]{graphs/r1_5_sampling_units/r1_5_time_scaling03.png}
        \subcaption{Mapped to Hz ($f_s \approx 1000$\,Hz)}
    \end{minipage}
    \caption{Frequency domain mapping under different sampling rate assumptions.} % R1-5
    \label{fig:r1_5_sampling_units}
\end{figure}

\clearpage
\section*{Data Records}
\label{sec:data-records}

The Complex Signal Benchmark Dataset (CoSiBD) is publicly available on Zenodo\cite{cosibd_zenodo_2025} and consists of synthetic temporal signals, mainly created to support the development and evaluation of temporal super-resolution (SR) algorithms, and also to train deep learning models that can be used for SR in real-world signals. This section provides an overview of the dataset structure, content, and storage format, as well as the parameters that rule the generation of data and the metadata that enrich our dataset.

The dataset comprises 2,500 high-resolution signals, each with corresponding subsampled versions at four resolution levels, organized into three main categories:

\begin{itemize}[itemsep=8pt,topsep=6pt,partopsep=0pt,parsep=0pt]
    \item \textbf{High-resolution signals}: 2,500 signals with 5,000 samples each, spanning the domain $T=[0, 4\pi]$ (s), which, under the illustrative convention used, corresponds to $f_s = 5000/(4\pi) \approx 398$\,Hz. Each signal is stored in three formats: NumPy compressed format (.npz), plain text (.txt), and JSON (.json). Per-signal metadata (frequency profiles with explicit change-points (\texttt{base\_points} and \texttt{high\_freq\_points}) and segment labels (\texttt{variation\_type}), amplitude envelopes, spline parameters, vertical offsets, noise configurations, and seeds) is provided in a consolidated JSON file (\texttt{signals\_metadata.json}) with one entry per signal, enabling exact regeneration.

    \item \textbf{Simple subsampled signals}: Uniform decimation (uniform subsampling) of each signal to four target resolutions: 150 (illustrative $f_s \approx 11.9$\,Hz for $T=4\pi$\,s), 250 (illustrative $f_s \approx 19.9$\,Hz for $T=4\pi$\,s), 500 (illustrative $f_s \approx 39.8$\,Hz for $T=4\pi$\,s), and 1,000 samples (illustrative $f_s \approx 79.6$\,Hz for $T=4\pi$\,s). These low-resolution versions serve as inputs for SR benchmarking against the original 5,000-sample target. Stored in .npz, .txt, and .json formats.
\end{itemize}

The dataset is provided as consolidated files under \texttt{SignalBuilderC/data/}. High-resolution signals are stored as \texttt{signals\_\allowbreak high\_\allowbreak resolution\_\allowbreak 5000.[npz|txt|json]}. Simple subsampled (decimated) signals are stored as \texttt{signals\_\allowbreak subsampled\_\allowbreak simple\_\allowbreak \{150,250,500,1000\}.[npz|txt|json]}. Dataset-level metadata (described later in detail) and configuration are stored in \texttt{signals\_\allowbreak metadata.json} (per-signal metadata, one entry per signal), \texttt{signals\_\allowbreak metadata\_\allowbreak consolidated\_\allowbreak 2500.json}, and \texttt{dataset\_\allowbreak summary.json}.

Regarding the three formats used for both high-resolution and subsampled signals, we provide here some additional information for each format: (1) NumPy compressed format (.npz) containing the signal array, time array, and (for high-resolution only) clean signal without noise; (2) consolidated plain text format (.txt) with one signal per row (samples separated by whitespace) for maximum portability; and (3) JSON format (.json) with both time and signal arrays for web-based applications and interoperability.

Reproducibility is ensured through documented seeds: each high-resolution signal is generated using a unique seed (ranging from 10,000 to 12,499), enabling exact regeneration of individual signals or the entire dataset. All generation parameters (described later in detail) are stored in metadata JSON files, including: (1) frequency profile parameters---tau\_frequency values from uniform distribution [1, 2] with 0.05 step; (2) amplitude envelope parameters---\texttt{amplitude\_spline\_type} is predominantly \texttt{zero\_order} (approximately 70\%), otherwise \texttt{tension} with tau\_amplitude drawn from \{1, 3, 5, 8, 10, 12, 15, 20\}; (3) vertical offsets---normally distributed (mean=0, SD=3.0); and (4) noise configurations---per-signal \texttt{noise\_profile} with \texttt{p\_has\_noise}=0.5 (and \texttt{p\_gaussian}=0.5 when noise is present).

\subsection*{Metadata schema and example}


CoSiBD provides per-signal metadata to support (i) deterministic regeneration, (ii) principled partitioning (e.g., by noise type/level or segment labels), and (iii) analysis of the piecewise structure induced by change-points. Table~\ref{tab:metadata_schema} summarizes representative fields contained in \texttt{signals\_metadata.json}. A minimal example entry is shown below (one signal; values truncated for brevity).

Table~\ref{tab:metadata_schema} details the key fields describing each signal, specifically the \texttt{variation\_type} list which provides categorical labels aligned with the \texttt{base\_points} anchors (e.g., ``low'', ``high'', or ``no\_change''), enabling users to filter for signals containing specific dynamic behaviors. The following JSON snippet shows a simplified illustrative metadata record (Example 1; values truncated for readability). Figure~\ref{fig:metadata_visualization} provides a visual counterpart of the same record: it highlights how consecutive \texttt{base\_points} (and, when present, \texttt{high\_freq\_points}) define temporal intervals and frequency targets, while \texttt{variation\_type} provides the corresponding per-anchor labels (here, yielding two intervals: ``low'' then ``high''), and \texttt{amp\_knots}/\texttt{amp\_values} define the amplitude envelope.

\begin{verbatim}
{
    "t_start": 0.0,
    "t_end": 12.566370614359172,
    "fs_high": 397.88735772973837,
    "tau_frequency": 1.15,
    "amplitude_spline_type": "zero_order",
    "tau_amplitude": "N/A",
    "vertical_offset": 0.06905161748158965,
    "base_points": [[0.0, 1.0], [6.28, 3.0], [12.56, 3.0]],
    "high_freq_points": [[0.0, 0.0], [6.28, 0.0], [12.56, 0.0]],
    "variation_type": ["low", "high", "high"],
    "amp_knots": [0.0, 6.28, 12.56],
    "amp_values": [0.72, 1.22, 0.96],
    "noise_profile": {"has_noise": true, "noise_type": "gaussian", "p_has_noise": 0.5, ...},
    "seed": 10000,
    "signal_id": "signal_0000",
    "index": 0
}
\end{verbatim}

\begin{table}[htbp]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{|l|l|l|X|}
\hline
\textbf{Field} & \textbf{Type} & \textbf{Example} & \textbf{Meaning} \\ \hline
\texttt{signal\_id} & String & "signal\_0000" & Unique identifier for the generated signal. \\ \hline
\texttt{index} & Integer & 0 & Numeric index of the signal (0 to N-1). \\ \hline
\texttt{seed} & Integer & 10000 & Seed used for deterministic generation of this specific signal. \\ \hline
\texttt{t\_start, t\_end} & Float & 0.0, 12.56 & Start and end time of the signal domain. \\ \hline
\texttt{base\_points} & Array & [[0.0, 2.07]...] & Control points ($t$, $f$) for the frequency spline. \\ \hline
\texttt{high\_freq\_points} & Array & [[0.0, 0.0]...] & Control points ($t$, $f$) for an optional high-frequency component. \\ \hline
\texttt{variation\_type} & List[Str] & ["low", "high", "high"] & Categorical labels aligned with \texttt{base\_points} anchors (same length), describing the intended band at each change-point (e.g., "low", "high", "no\_change"); interval labels are derived between successive anchors. \\ \hline
\texttt{tau\_frequency} & Float & 1.15 & Tension parameter for the frequency spline. \\ \hline
\texttt{amplitude\_spline\_type} & String & "zero\_order" & Interpolation family for the amplitude envelope (e.g., step-wise or tension spline). \\ \hline
\texttt{tau\_amplitude} & Float / String & 10.0 & Tension parameter for the amplitude spline (or \texttt{"N/A"} for zero-order). \\ \hline
\texttt{amp\_knots} & Array & [0.0, 6.28, 12.56] & Knot times defining the amplitude envelope segments. \\ \hline
\texttt{amp\_values} & Array & [0.72, 1.22, 0.96] & Amplitude values at knots (piecewise-constant or spline-interpolated). \\ \hline
\texttt{noise\_profile} & Dict & \{...\} & Parameters for added noise (if any). \\ \hline
\end{tabularx}
\caption{Metadata schema describing the JSON structure for each signal. Key fields define the frequency trajectory (\texttt{base\_points}, \texttt{variation\_type}) and amplitude envelope, allowing precise reconstruction or filtering.}
\label{tab:metadata_schema}
\end{table}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{graphs/metadata_vis.png}
    \caption{Visual representation of an illustrative metadata record for signal\_0000 (Example 1). The plot illustrates how \texttt{base\_points} define temporal intervals and frequency targets, while \texttt{amp\_values} control the amplitude envelope segments, corresponding directly to the JSON structure.}
    \label{fig:metadata_visualization}
\end{figure}

\subsection*{Parameters for signal generation}

 As we anticipated before, our dataset is generated from a set of configuration parameters summarized in Table~\ref{tab:Parameter}. Each high-resolution signal was generated with a unique seed (10,000--12,499) and sampled parameter values within the defined ranges, supporting diversity while maintaining reproducibility. Parameters marked as \emph{Sampled (seed-controlled)} are drawn per-signal using the recorded seed, while fixed defaults are held constant across the dataset. Unless otherwise stated, these defaults correspond to the settings used in the Zenodo release, and the CLI follows the same behavior unless a user explicitly overrides a parameter.

 Concretely, generation proceeds as a deterministic pipeline conditioned on the seed: (i) the seed initializes all pseudo-random draws; (ii) a set of frequency-trajectory and envelope parameters is sampled within the reported ranges; (iii) a continuous-time signal is synthesized over the fixed domain ($T=4\pi$\,s convention) by combining a time-varying frequency trajectory with an amplitude envelope; and (iv) optional nuisance terms (offset and additive noise) are applied. Therefore, fixing the seed fully determines the sampled parameters and the resulting signal instance, which supports exact reproduction and controlled ablations.

\textbf{Frequency trajectory.} The overall (instantaneous) frequency evolution is controlled by the sampled low/high frequency bands (``Low Frequency'' and ``High Frequency''), the number of transitions (``Change Points''), and their temporal placement (``Change Locations''). The categorical ``Variation Type'' (\{low, high, no\_change\}) provides labels aligned with the \texttt{base\_points} anchors, indicating whether the trajectory targets the low band, the high band, or remains stable around each change-point; this supports controlled balancing and downstream filtering via metadata. The smoothness/shape of the resulting trajectory is governed by the spline settings, including \texttt{tau\_frequency} (``Tension (freq)'').

\textbf{Amplitude envelope.} Independently of the frequency trajectory, the signal amplitude is modulated by an envelope whose overall scale is constrained by ``Amplitude Range''. The envelope shape is generated via the specified interpolation scheme (``Spline Type'') and, when applicable, by the sampled ``Tension (amp)'' parameter. This yields signals with comparable frequency content but different amplitude dynamics.

\textbf{Offsets and noise.} To emulate common acquisition artifacts without tying the generator to a specific instrument, we add a per-signal ``Vertical Offset'' and inject additive noise stochastically according to ``Noise Prob.''. When noise is enabled for a given signal, its parameters are recorded in metadata to preserve reproducibility.

\textbf{Resolution and sampling.} Each instance is first generated at the target high-resolution length (e.g., 5,000 samples in the released dataset), and lower-resolution views are derived by subsampling, enabling consistent multi-scale analysis and SR benchmarking (Figure~\ref{fig:amplitud}).

\textbf{Mathematical formulation.} Let $t\in[t_\mathrm{start},t_\mathrm{end}]$ with the paper's convention $T=t_\mathrm{end}-t_\mathrm{start}=4\pi$\,s. A generated signal can be written as
\begin{equation}
x(t)=v + a(t)\,\sin\!\big(\phi(t)\big) + \varepsilon(t),
\end{equation}
where $v$ is a vertical offset, $a(t)\ge 0$ is the amplitude envelope, and $\varepsilon(t)$ is an optional additive noise term. The instantaneous frequency trajectory is encoded through the phase derivative
\begin{equation}
f(t)=\frac{1}{2\pi}\,\frac{d\phi(t)}{dt},
\end{equation}
and is constructed from a spline defined by a set of control points and a tension parameter (Table~\ref{tab:Parameter}). This separation (frequency trajectory vs. amplitude envelope) allows generating signals that share the same transition structure but differ in amplitude dynamics, or vice versa.

\textbf{Mapping Table~\ref{tab:Parameter} to metadata fields.} The parameters in Table~\ref{tab:Parameter} correspond to concrete entries in each per-signal metadata record (Figure~\ref{fig:metadata_visualization} shows an illustrative example):
\begin{itemize}
    \item \emph{Seed} $\rightarrow$ \texttt{seed} (and derived identifiers \texttt{signal\_id}, \texttt{index}). Fixing \texttt{seed} reproduces all sampled values.
    \item \emph{Domain} $T=4\pi$ convention $\rightarrow$ \texttt{t\_start}, \texttt{t\_end}.
    \item \emph{Change points / locations / variation type} $\rightarrow$ \texttt{base\_points} (frequency control points), \texttt{variation\_type} (interval labels), and auxiliary arrays such as \texttt{high\_freq\_points} used to represent high-frequency targets during transitions.
    \item \emph{Frequency tension} $\rightarrow$ \texttt{tau\_frequency}.
    \item \emph{Amplitude range / spline settings} $\rightarrow$ \texttt{amplitude\_spline\_type}, \texttt{tau\_amplitude}, and the envelope knot representation \texttt{amp\_knots} and \texttt{amp\_values}.
    \item \emph{Vertical offset} $\rightarrow$ \texttt{vertical\_offset}.
    \item \emph{Noise probability and settings} $\rightarrow$ \texttt{noise\_profile} (including whether noise was applied and the sampled noise parameters for that signal).
\end{itemize}
 Some fields (e.g., \texttt{fs\_high}) are reported as part of the complete record to make downstream processing explicit; they are derived from the chosen resolution and the domain convention.

\begin{table}[htbp]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{|l|l|l|X|}
\hline
\textbf{Parameter} & \textbf{Range / Options} & \textbf{Default} & \textbf{Description} \\ \hline
Low Frequency & 1--5 Hz & Sampled (seed-controlled) & Low-frequency component ($T=4\pi$\,s convention). \\ \hline
High Frequency & 20--100 Hz & Sampled (seed-controlled) & High-frequency variations for transitions. \\ \hline
Change Points & 2--11 & Sampled (seed-controlled) & Number of frequency transitions per signal. \\ \hline
Change Locations & Continuous & Sampled (seed-controlled) & Time locations where transitions occur. \\ \hline
Variation Type & \{low, high, no\_change\} & Balanced & Category of frequency change per segment. \\ \hline
Amplitude Range & 3--16 & Sampled (seed-controlled) & Bounds for amplitude envelope generation. \\ \hline
Vertical Offset & $N(0, 3.0)$ & 0.0 & Normally distributed offset added to signals. \\ \hline
Spline Type & Zero-Order (70\%), Tension (30\%) & - & Interpolation method for envelopes. \\ \hline
Tension (freq) & [1, 2] & 1.5 & Tension parameter for frequency splines. \\ \hline
Tension (amp) & \{1, 3, 5, 8, 10, 12, 15, 20\} & Sampled (seed-controlled) & Tension parameter for amplitude splines (\texttt{"N/A"} for zero-order). \\ \hline
Noise Prob. & 0.0--1.0 & 0.5 & Probability of adding noise to a signal. \\ \hline
Seed & Integer & - & Unique initialization seed per signal. \\ \hline
\end{tabularx}
\caption{Configuration parameters used to generate the dataset. Ranges define the sampling space for the 2,500 signals, ensuring diversity. When not explicitly set by the user, parameters are either sampled per signal (seed-controlled) or take fixed defaults as listed (defaults used for the Zenodo release).}
\label{tab:Parameter}
\end{table}

To explicitly characterize dataset diversity and complexity, CoSiBD spans multiple controlled axes of variation (Table~\ref{tab:Parameter}), including the number and location of change points, categorical transition types, low/high frequency bands, and amplitude-envelope configurations.While the dataset is synthetic and not fitted to match a single domain-specific distribution, these controlled variations provide reproducible coverage of common real-world time-series phenomena such as non-stationarity, transient high-frequency events, and additive noise.

 Figure~\ref{fig:amplitud} shows a representative signal from the dataset sampled at different resolution levels, as well as a version with added noise. This illustrates the variety of sampling and noise conditions included in CoSiBD. Figure~\ref{fig:simples} displays four additional synthetic signals generated using different configuration parameters. These examples demonstrate the variability in temporal structure across instances in the dataset.

\begin{figure}[htbp]
\centering
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/amplitud1.png}
    \subcaption{High-resolution signal (5000 samples).}
    \label{fig:amp1}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/amplitud2.png}
    \subcaption{Medium-resolution signal (500 samples).}
    \label{fig:amp2}
\end{minipage}



\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/amplitud3.png}
    \subcaption{Low-resolution signal (250 samples).}
    \label{fig:amp3}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/amplitud4.png}
    \subcaption{Signal with added noise.}
    \label{fig:amp4}
\end{minipage}

\caption{A synthetic signal sampled at different resolutions: (a) high (5000 samples), (b) medium (500 samples), (c) low (250 samples), and (d) with added noise. These examples reflect the multi-resolution and noise conditions present in the dataset.}
\label{fig:amplitud}
\end{figure}



\begin{figure}[htbp]
\centering
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/simples1.png}
    \subcaption{Signal with increasing frequency over time.}
    \label{fig:simp1}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/simples2.png}
    \subcaption{Signal with localized frequency variation.}
    \label{fig:simp2}
\end{minipage}



\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/simples3.png}
    \subcaption{Signal with smooth oscillations and broad amplitude cycles.}
    \label{fig:simp3}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/simples4.png}
    \subcaption{Signal with irregular peak spacing.}
    \label{fig:simp4}
\end{minipage}

\caption{Examples of synthetic signals in the dataset generated with different parameter configurations. Each signal presents a distinct temporal profile.}
\label{fig:simples}
\end{figure}

\subsection*{Custom Dataset Generation}

In addition to the pre-generated dataset, the CoSiBD package includes a command-line interface (CLI) that allows users to generate custom datasets with their own parameter distributions. Figure~\ref{fig:cli_tool} demonstrates the usage of this tool. The command specifies the number of signals (\texttt{--n\_signals}), the target high-resolution length in samples (\texttt{--resolution}, e.g., \texttt{5000}), and the probability of applying noise to each signal (\texttt{--noise\_prob}, e.g., \texttt{0.5}, meaning noise is injected into roughly half of the signals). The output log confirms the resolved configuration (signal count, domain, and output directory), reports progress during generation, and summarizes the created artifacts (per-signal files and the consolidated \texttt{signals\_metadata.json}).

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{graphs/cli_tool_demo.png}
    \caption{Demonstration of the CoSiBD Command Line Interface (CLI). Users can generate new dataset instances by specifying parameters such as signal count, sampling resolution, and noise probability directly from the terminal.}
    \label{fig:cli_tool}
\end{figure}



\section*{Technical Validation}
\label{sec:technical-validation}

This section evaluates the signal generation procedure by analyzing spectral properties under different conditions, including the distribution of dominant frequencies, spectral stability across sampling rates, and the effect of noise. Additionally, we provide a multi-scale super-resolution benchmark to demonstrate the dataset's utility in training deep learning models, and illustrative transfer learning experiments using real-world EEG and speech data. These analyses aim to assess variability and stability under the reported settings, and to document the dataset's behavior for reproducible use. Below, the methodologies and results are described in detail.

\subsection*{Validation Context}
Experimental parameters were selected to support reproducibility and to illustrate representative behaviors of the generator under the reported settings. The number of signals ($n=50$ for spectral analysis, $n=2500$ for benchmarks) provides a compact but informative sample to summarize variability. Sampling resolutions (ranging from 150 to 5000 samples) reflect scenarios requiring different levels of detail, aligning with typical signal processing use cases. Noise amplitudes (Gaussian noise with $\sigma \in [0.0, 0.2]$) were motivated by common acquisition artifacts, with the goal of providing a controllable benchmark rather than an exhaustive model of any specific measurement pipeline. Unless otherwise stated, signal-generation settings follow the configuration in Table~\ref{tab:Parameter}.

\subsection*{Analysis of Dominant Frequency Distribution}

To assess the stability and variability of the primary spectral components, we analyzed the distribution of dominant frequencies across multiple generated signals. A total of fifty independent signals were synthesized using identical input parameters. To examine their spectral characteristics, we computed the power spectral density (PSD) of each signal, which quantifies how signal power is distributed across different frequencies.

The PSD was estimated using Welch’s method, selected for its ability to reduce noise and provide a smoother spectral representation \cite{Welch1967}. This method stabilizes spectral estimation by dividing the signal into overlapping segments, computing their individual spectra, and averaging them. This reduces variance from random fluctuations and yields a smoother estimate. For each signal, the dominant frequency was identified as the frequency at which the PSD reaches its maximum value. This corresponds to the most prominent spectral component, indicating where the signal concentrates most of its energy.

By analyzing the distribution of dominant frequencies across the dataset, we evaluate whether the generated signals exhibit consistent spectral patterns or if there is significant variation. High consistency would indicate stability in the data generation process, whereas high variability could suggest the influence of stochastic sampling effects (seed-controlled).


\begin{figure}
    \centering
    \includegraphics[width=0.56\textwidth]{graphs/analysis_densidad.png}
    \caption{Distribution of dominant frequencies in 50 independently generated signals (reported in Hz, assuming the illustrative convention $T=4\pi$\,s; for other time domains, the axis rescales by $4\pi/T$).}
    \label{fig:dominant_frequency_distribution}
\end{figure}

\begin{table}
\centering
\small
\begin{tabular}{|l|l|}
\hline
Statistic  & Value (Hz; illustrative $T=4\pi$\,s) \\
\hline
Average Dominant Frequency  & 0.508 \\
Standard Deviation  & 0.195 \\
Minimum Dominant Frequency  & 0.390 \\
Maximum Dominant Frequency  & 1.171 \\
\hline
\end{tabular}
\caption{\label{tab:density_label}Summary statistics of dominant frequencies, including average, standard deviation, and extreme values.}
\end{table}

 The results, shown in Figure~\ref{fig:dominant_frequency_distribution} and Table~\ref{tab:density_label}, indicate that the dominant frequency (reported in Hz under the illustrative convention $T=4\pi$\,s) is predominantly low under the reported settings. Quantitatively, the mean dominant frequency is 0.508\,Hz with a standard deviation of 0.195\,Hz, while the observed range spans 0.390--1.171\,Hz (Table~\ref{tab:density_label}). Figure~\ref{fig:dominant_frequency_distribution} shows a strong concentration in the low-frequency region, with a thinner tail toward higher values, corresponding to a smaller subset of realizations where the strongest spectral peak shifts upward. This pattern is consistent with the stochastic sampling of frequency profiles (e.g., random control points and segment-wise variations): signals share the same parameter ranges, but some draws produce higher instantaneous-frequency segments that become dominant in the PSD. Overall, the concentration around low frequencies combined with controlled spread supports the goal of stable primary structure with deliberate diversity, which is desirable for training models that must generalize across plausible spectral configurations~\cite{Bengio2013}.

 Figure \ref{fig:noise_ruido} presents examples of signals from the CoSiBD dataset with increasing levels of added noise, illustrating how amplitude fluctuations progressively obscure the underlying temporal structure.

\begin{figure}[htbp] \centering \begin{minipage}{0.47\textwidth} \centering \includegraphics[width=\textwidth]{graphs/ruido1.png} \subcaption{Low-noise signal, where amplitude variations are present but minimally distorted.} \label{fig:noise1} \end{minipage} \hspace{0.02\textwidth} \begin{minipage}{0.47\textwidth} \centering \includegraphics[width=\textwidth]{graphs/ruido2.png} \subcaption{Moderate-noise signal, with irregular peaks and troughs beginning to distort the oscillatory pattern.} \label{fig:noise2} \end{minipage}



\begin{minipage}{0.47\textwidth} \centering \includegraphics[width=\textwidth]{graphs/ruido3.png} \subcaption{High-noise signal, where significant distortion leads to unpredictable fluctuations.} \label{fig:noise3} \end{minipage} \hspace{0.02\textwidth} \begin{minipage}{0.47\textwidth} \centering \includegraphics[width=\textwidth]{graphs/ruido4.png} \subcaption{Extreme-noise signal, where the original oscillatory structure is almost entirely masked by chaotic interference.} \label{fig:noise4} \end{minipage}

\caption{Visualization of signals under increasing noise conditions, showing how added noise progressively masks the original temporal patterns. From low (a) to extreme noise levels (d), this degradation highlights reconstruction challenges for super-resolution models.} \label{fig:noise_ruido} \end{figure}


\subsection*{Spectral Stability Across Sampling Resolutions}

This analysis aims to investigate the influence of sampling resolution (number of samples) on the robustness of spectral estimates under varying frequency content. When frequency axes are reported in Hz, they follow the illustrative convention $T=4\pi$\,s; for other choices of $T$, the Hz axis rescales by $4\pi/T$. At lower resolutions, reduced sampling density and coarser frequency grids can obscure or merge spectral peaks, compromising the ability to distinguish closely spaced spectral components \cite{Rabiner1975}. Conversely, higher resolutions improve the granularity of the frequency axis, allowing for better separation of spectral features and reducing the risk of misrepresenting the signal’s underlying structure \cite{Marple1987}.

 This evaluation documents how spectral summaries vary with sampling resolution under the reported settings. The intent is to provide descriptive context for using CoSiBD at different resolutions (and computational budgets) in benchmark protocols, rather than to prescribe a universal sampling rate.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{graphs/psd.png}
    \caption{Average power spectral density (PSD) for different sampling resolutions based on 50 independent runs (Hz axis under the illustrative convention $T=4\pi$\,s).}
    \label{fig:average_psd}
\end{figure}

As shown in Figure~\ref{fig:average_psd}, lower sampling resolutions, specifically the blue curve (150 samples) and the orange curve (250 samples), exhibit a noticeable reduction in detail within the higher-frequency range. These lower-resolution curves display greater fluctuations, consistent with the theoretical effects of subsampling and aliasing~\cite{Shannon1949}. In contrast, the higher sampling resolutions (500, 1000 samples) demonstrate a smoother and more stable spectral profile. This analysis confirms that while lower sampling rates introduce aliasing artifacts, the dataset provides spectral fidelity comparable to theoretical expectations when sufficient resolution is employed.

\subsection*{Impact of Noise on Frequency Characteristics}

We analyze how varying the noise amplitude affects the power spectral density (PSD), with particular attention to differences between low- and high-frequency regions. Figure~\ref{fig:noise_psd} illustrates this effect under the reported settings.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\textwidth]{graphs/noise.png}
    \caption{Power spectral density (PSD) of signals generated with different noise amplitudes (Hz axis under the illustrative convention $T=4\pi$\,s).}
    \label{fig:noise_psd}
\end{figure}

Across these settings, as the noise amplitude increases—from 0.0 (blue curve) to 0.2 (green curve)—the estimated PSD exhibits increased variability at higher frequencies, while the low-frequency region remains comparatively stable. This stability suggests that CoSiBD signals retain their primary structural characteristics even under significant noise, a critical property for robust representation learning~\cite{Bishop2006}.

\subsection*{Multi-Scale Super-Resolution Benchmark}
\label{sec:multiscale-super-resolution-benchmark}

To illustrate a baseline use case of CoSiBD, we trained a series of convolutional neural network (CNN) models for time series super-resolution at four different scaling factors: 5$\times$ (1000$\to$5000), 10$\times$ (500$\to$5000), 20$\times$ (250$\to$5000), and 33$\times$ (150$\to$5000). All models employed the TimeSeriesSRNet architecture—a five-layer encoder-decoder network with 1D convolutional layers and bilinear upsampling, inspired by deep residual architectures for audio generation~\cite{Kuleshov2017}. For this benchmark, the 2,500 high-resolution signals were partitioned into an experiment-specific split of 2,000 paired signals for training and 500 held-out signals for validation.

We selected this architecture as a simple 1D convolutional encoder--decoder baseline: it captures local temporal structure while providing a deterministic upsampling mechanism, enabling consistent comparisons across scaling factors. Each model was trained using mean squared error (MSE) loss, a standard objective for regression tasks requiring broad mode coverage~\cite{Goodfellow2016}, using the Adam optimizer (learning rate 0.001) and early stopping. A batch size of 16 was used as a practical compromise between optimization stability and MPS memory constraints. Training was conducted on Apple Silicon GPU (MPS backend) to accelerate convergence.

Table~\ref{tab:multiscale_benchmark} summarizes the validation performance. In these runs, validation loss increased systematically with upsampling factor, reflecting the inherent difficulty of reconstructing fine temporal details from severely undersampled inputs (Table~\ref{tab:multiscale_benchmark}, Figure~\ref{fig:multifactor_loss_curves}). Figure~\ref{fig:multifactor_loss_curves} shows the training/validation loss trajectories separately for each scaling factor: (a) 5$\times$ (1000$\to$5000), (b) 10$\times$ (500$\to$5000), (c) 20$\times$ (250$\to$5000), and (d) 33$\times$ (150$\to$5000). In all four cases, training and validation curves follow similar trends without pronounced divergence, indicating stable optimization under the fixed protocol.

Across panels (a--d), the final validation loss increases as the factor grows, consistent with the expected increase in ill-posedness as fewer LR samples constrain the HR target. The 5$\times$ and 10$\times$ settings (a--b) exhibit faster convergence and lower final error, while the 20$\times$ and especially the 33$\times$ setting (c--d) show higher residual error, reflecting the greater difficulty of reconstructing fine-scale temporal detail from extreme undersampling.

\begin{figure}[htbp]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{graphs/multifactor_loss_curves01.jpg}
        \subcaption{5x upsampling}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{graphs/multifactor_loss_curves02.jpg}
        \subcaption{10x upsampling}
    \end{minipage}



    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{graphs/multifactor_loss_curves03.jpg}
        \subcaption{20x upsampling}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{graphs/multifactor_loss_curves04.jpg}
        \subcaption{33x upsampling}
    \end{minipage}

    \caption{Training/validation loss curves for each upsampling factor in the multi-scale benchmark.}
    \label{fig:multifactor_loss_curves}
\end{figure}

\begin{table}[htbp]
\centering
\setlength{\tabcolsep}{3pt}
\footnotesize
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\textbf{Input Size} & \textbf{Factor} & \textbf{Val Loss} & \textbf{Epochs} & \textbf{Early Stop} & \textbf{LSD} & \textbf{SCORR} \\
\hline
1000 samples & 5$\times$ & 0.0845 & 50 & No & 0.51$\pm$0.63 & 0.98$\pm$0.10 \\
500 samples & 10$\times$ & 0.1524 & 50 & No & 0.64$\pm$0.63 & 0.98$\pm$0.10 \\
250 samples & 20$\times$ & 0.4376 & 50 & No & 0.95$\pm$0.67 & 0.98$\pm$0.10 \\
150 samples & 33$\times$ & 1.0326 & 50 & No & 1.21$\pm$0.67 & 0.98$\pm$0.11 \\
\hline
\end{tabular}
\caption{Multi-scale super-resolution benchmark results. Validation loss measured as mean squared error on 500 independent validation signals. LSD (Log Spectral Distance) quantifies spectral content deviation, while SCORR (Spectral Correlation) measures frequency-domain similarity. All models completed the full 50-epoch training without early termination, showing stable convergence.}
\label{tab:multiscale_benchmark}
\end{table}

To complement amplitude-based validation, we computed spectral fidelity metrics. Log Spectral Distance (LSD) increased from 0.51 (5$\times$) to 1.21 (33$\times$), indicating progressively larger deviations in spectral magnitude as reconstruction becomes more challenging, while Spectral Correlation (SCORR) remained consistently high (Table~\ref{tab:multiscale_benchmark}, Figure~\ref{fig:spectral_metrics}), suggesting that broad spectral structure is still largely preserved across factors \cite{Marple1987}. Figure~\ref{fig:spectral_analysis} provides representative spectrogram comparisons across all upsampling factors; the rightmost column (spectral difference) highlights where reconstruction introduces localized discrepancies (warm colors) that become more pronounced at higher factors, typically around rapid transitions and high-frequency content.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.85\textwidth]{graphs/spectral_metric_trends.png}
    \caption{Spectral quality metrics vs upsampling factor. Left: Log Spectral Distance (LSD) increases systematically with upsampling factor, from 0.51 (5$\times$) to 1.21 (33$\times$). Right: Spectral Correlation (SCORR) maintains consistently high values (>0.97) across all factors. Error bars represent standard deviation over 500 validation signals per factor.}
    \label{fig:spectral_metrics}
\end{figure}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\textwidth]{graphs/spectral_analysis_grid.png}
    \caption{Spectrogram comparison across all upsampling factors. Each row represents a different upsampling factor (5$\times$, 10$\times$, 20$\times$, 33$\times$), showing original signal (left), CNN-reconstructed signal (center), and spectral difference (right). Reconstruction artifacts become more visible at higher upsampling rates. Representative signals selected based on median Log Spectral Distance (LSD) for each factor.}
    \label{fig:spectral_analysis}
\end{figure}

Representative prediction examples (Figure~\ref{fig:multifactor_predictions}) provide qualitative comparisons of reconstructed outputs against ground truth across scaling factors. Panels (a--b) correspond to 5$\times$ upsampling (1000$\to$5000), (c--d) to 10$\times$ (500$\to$5000), (e--f) to 20$\times$ (250$\to$5000), and (g--h) to 33$\times$ (150$\to$5000). Across all factors, the CNN recovers the main waveform structure and overall trend, indicating that the learned mapping is able to exploit consistent LR--HR correlations in the synthetic pairs.

As the upsampling factor increases, the reconstruction problem becomes increasingly ill-posed: fewer observed samples constrain the HR target, and fine temporal details are progressively harder to recover. This is most apparent at 33$\times$, where predictions tend to be smoother and may miss rapid oscillations; correspondingly, a net loss of information at higher frequencies is observed, consistent with the stronger low-pass effect induced by extreme undersampling.

\begin{figure}[htbp]
    \centering
    % Using subcaption package settings for spacing
    \captionsetup[subfigure]{font=scriptsize, skip=3pt, margin=0pt} 
    % Removed undefined subfigbottomskip
    
    % Enforcing height limit to fit on page, but ensuring no overlap
    % Images are ~2.1cm high. 
    
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth, height=2.1cm, keepaspectratio]{graphs/multifactor_predictions01.jpg}
        \subcaption{5x upsampling}
    \end{subfigure}
    
    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth, height=2.1cm, keepaspectratio]{graphs/multifactor_predictions02.jpg}
        \subcaption{5x upsampling}
    \end{subfigure}

    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth, height=2.1cm, keepaspectratio]{graphs/multifactor_predictions03.jpg}
        \subcaption{10x upsampling}
    \end{subfigure}

    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth, height=2.1cm, keepaspectratio]{graphs/multifactor_predictions04.jpg}
        \subcaption{10x upsampling}
    \end{subfigure}

    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth, height=2.1cm, keepaspectratio]{graphs/multifactor_predictions05.jpg}
        \subcaption{20x upsampling}
    \end{subfigure}

    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth, height=2.1cm, keepaspectratio]{graphs/multifactor_predictions06.jpg}
        \subcaption{20x upsampling}
    \end{subfigure}

    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth, height=2.1cm, keepaspectratio]{graphs/multifactor_predictions07.jpg}
        \subcaption{33x upsampling}
    \end{subfigure}

    \begin{subfigure}{\textwidth}
        \centering
        \includegraphics[width=\textwidth, height=2.1cm, keepaspectratio]{graphs/multifactor_predictions08.jpg}
        \subcaption{33x upsampling}
    \end{subfigure}
    
    \captionsetup{skip=5pt}
    \caption{\footnotesize Representative qualitative prediction examples, comparing LR inputs, HR ground truth, and CNN-reconstructed outputs across the multi-scale benchmark. Each panel shows a full-width example.}
    \label{fig:multifactor_predictions}
\end{figure}

These multi-scale experiments provide quantitative baseline results for future benchmarking studies. In addition to providing a reproducible baseline under a fixed architecture and protocol, the systematic increase in task difficulty—from moderate 5$\times$ upsampling to extreme 33$\times$ reconstruction—can serve as a practical reference for comparing architectures, loss functions, and training strategies in the time series super-resolution domain. More broadly, CoSiBD enables controlled benchmarking where methods can be compared on identical LR--HR pairs and nuisance settings, supporting fair ablation studies and future community protocols.


\subsection*{Illustrative Transfer Learning Experiments}
\label{sec:preliminary-application-results}

To demonstrate the practical utility of CoSiBD for training deep learning models, we conducted transfer learning experiments using convolutional neural networks (CNNs) for time-series super-resolution~\cite{Kuleshov2017,Kaniraja2024}. A TimeSeriesSRNet model (encoder-decoder architecture with 1D convolutions: 1$\to$64$\to$128$\to$256, bilinear upsampling, decoder 256$\to$128$\to$64$\to$1) was evaluated on two distinct real-world domains: EEG clinical signals~\cite{Luciw2014} (500 training, 690 validation samples) and VCTK speech recordings~\cite{Yamagishi2019} (44 hours from 109 speakers).
\\ \\
Four training strategies were systematically evaluated: (1) \textbf{Real-only}: trained exclusively on domain-specific real data (baseline); (2) \textbf{Synth-only}: trained exclusively on CoSiBD synthetic signals; (3) \textbf{Mixed}: trained on a combined dataset of synthetic and real data; and (4) \textbf{Tuned}: pre-trained on CoSiBD synthetic data, then fine-tuned on the real-world training set. Performance was measured using Mean Absolute Error (MAE) between predicted and ground-truth high-resolution signals.

The results (Table~\ref{tab:cnn_results}, Figure~\ref{fig:model_comparisons}) demonstrate that integrating CoSiBD improves model performance compared to using limited real data alone. While models trained only on synthetic data (Synth-only) yielded higher errors due to domain shift, the \textbf{Mixed} and \textbf{Tuned} strategies consistently outperformed the Real-only baseline. In particular, the best EEG result is an MAE of \textbf{9.73} achieved by the \textbf{Mixed} strategy, while the best VCTK result is an MAE of \textbf{4.41} achieved by \textbf{Tuned} (Table~\ref{tab:cnn_results}). Specifically, fine-tuning a CoSiBD-pretrained model reduced error significantly on the VCTK dataset, suggesting that the synthetic dataset effectively captures universal temporal structures relevant to super-resolution tasks.

Beyond the aggregate MAE values, Figure~\ref{fig:model_comparisons} provides a qualitative interpretation of these results. In the EEG example, Mixed/Tuned reconstructions better follow fast transients and reduce amplitude under/overshoot compared to the baseline. In the speech example, CoSiBD-enhanced strategies recover sharper oscillatory detail and reduce residual smoothing, visually aligning with the lower MAE reported in Table~\ref{tab:cnn_results}.

\begin{table}[htbp]
\centering
\small
\begin{tabular}{|l|c|c|}
\hline
\textbf{Training Strategy} & \textbf{EEG MAE ($\times 10^{-2}$)} & \textbf{VCTK MAE ($\times 10^{-3}$)} \\
\hline
Real-only (baseline) & 10.77 & 5.92 \\
Synth-only & 12.11 & 8.79 \\
Mixed (synth + real) & \textbf{9.73} & 5.59 \\
Tuned (pretrain + finetune) & 10.68 & \textbf{4.41} \\
\hline
\end{tabular}
\caption{Mean Absolute Error (MAE) for CNN-based super-resolution models. Embedding CoSiBD data (Mixed and Tuned strategies) improves reconstruction accuracy compared to training on limited real data alone.}
\label{tab:cnn_results}
\end{table}

 All those findings suggests that synthetic signals can complement domain-specific realdata. These results are provided as an example of how CoSiBD can be used and depend on the chosen datasets, splits, and training details; they should not be interpreted as definitive claims about general performance but at least in two use cases they prove that our dataset contributes to obtain better results than those obtained using only the real data. This constitutes one of the main contributions of our dataset, although experiments on additional domains are suggested as future research. Detailed experimentalmethodology and additional comparisons are available in the accompanying repository (see Section of Code availability a the end of the manuscript).

 As a further validation of structural transferability, with the purpose that the reader can interact with real reconstructed signals, we applied the TimeSeriesSRNet trained solely on CoSiBD (5$\times$ upsampling) to reconstruct full 2-second audio clips from the VCTK corpus without any fine-tuning. Despite the domain gap, the model successfully recovered intelligible speech with preserved harmonic structure (mean Pearson correlation $r=0.928$). This indicates that CoSiBD's diverse frequency and envelope parameters generalize well to complex, non-stationary signals like human speech. Reconstructed examples (degraded vs. reconstructed signals under different strategies) are provided in the accompanying repository under \texttt{AudioModels/results/audio\_samples/}.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}{0.8\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/eeg_model_comparison_1.pdf}
        \subcaption{EEG clinical signal reconstruction.(x =samples, y=Amplitude)}
        \label{fig:eeg_comparison}
    \end{subfigure}
    
    \vspace{0.3cm} % Space between subfigures

    \begin{subfigure}{0.8\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/vctk_model_comparison_5.pdf}
        \subcaption{VCTK speech signal reconstruction. (x =samples, y=Amplitude)}
        \label{fig:vctk_comparison}
    \end{subfigure}
    \caption{Visual comparison of super-resolution predictions. CoSiBD-enhanced models (Mixed/Tuned) recover finer details in both (a) EEG transients and (b) speech waveforms compared to the baseline.}
    \label{fig:model_comparisons}
\end{figure}

\section*{Usage Notes}
\label{sec:usage-notes}

The CoSiBD dataset contains high-resolution signals and corresponding subsampled versions at multiple resolutions. Signals are provided in consolidated \texttt{.txt}, \texttt{.npz}, and \texttt{.json} formats. Pairing between low- and high-resolution versions is performed by row index: row $i$ in a subsampled file corresponds to row $i$ in the high-resolution file, with per-signal parameters available in \texttt{signals\_metadata.json}.
The dataset is distributed as a single, unified collection without a predefined train/validation/test split. Users should create partitions appropriate to their objectives (e.g., random splits, stratified splits by noise type/level or signal characteristics, cross-validation, or scenario-specific test sets), using the provided metadata to support principled partitioning.

\subsection*{Reading the Data}

In this subsection we show how to read signals stored as consolidated plain text (\texttt{.txt}) files, with one signal per row (samples separated by whitespace). Each file contains multiple time series stacked vertically, where each row corresponds to a single signal. The dataset can be accessed using standard Python tools:

\begin{verbatim}
import numpy as np

# Load subsampled (simple decimation) and high-resolution signals
# Each .txt file is consolidated: one signal per row
x_valid = np.loadtxt('SignalBuilderC/data/signals_subsampled_simple_250.txt')
y_valid = np.loadtxt('SignalBuilderC/data/signals_high_resolution_5000.txt')

# Optional: convert to PyTorch tensors
# import torch
# x_valid = torch.tensor(x_valid, dtype=torch.float32)
# y_valid = torch.tensor(y_valid, dtype=torch.float32)
\end{verbatim}

These commands return NumPy arrays (each row corresponds to one signal). Users can optionally convert them to PyTorch tensors.

\subsection*{Visualizing Signal Pairs}

To explore the resolution differences,users can visualize aligned pairs of signals, as indicated in the following example, where well-known functions provided in the Python matplotlib.pyplot interface have been used for that purpose.

\begin{verbatim}
import matplotlib.pyplot as plt
import numpy as np

# Load subsampled (simple decimation) and high-resolution signals
# Each .txt file is consolidated: one signal per row
x_lr = np.loadtxt('SignalBuilderC/data/signals_subsampled_simple_250.txt')
x_hr = np.loadtxt('SignalBuilderC/data/signals_high_resolution_5000.txt')

# Access a paired signal by row index
i = 0
low_res_signal  = x_lr[i]
high_res_signal = x_hr[i]

# Visualize a paired low- and high-resolution signal
plt.figure(figsize=(10, 4))

# High-resolution signal
plt.plot(high_res_signal, label='High-resolution (5000 samples)', alpha=0.8)

# Low-resolution signal (aligned to HR index range for visualization)
lr_x = np.linspace(0, len(high_res_signal), len(low_res_signal))
plt.scatter(lr_x, low_res_signal, color='red', s=12,
            label='Low-resolution (250 samples)')

plt.xlabel('Sample index')
plt.ylabel('Amplitude')
plt.title('Paired Low- and High-Resolution Signal')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
\end{verbatim}

This visualization highlights how the same underlying temporal structure is represented at different resolutions while preserving alignment between paired signals. Additional signal characteristics (e.g., change-points, frequency profiles, or noise configuration) can be retrieved from \texttt{signals\_metadata.json} using the same row index.

\subsection*{Training a baseline model (synthetic-only)}


The following example illustrates a minimal synthetic-only training loop for time-series super-resolution using CoSiBD pairs (LR input from simple uniform decimation, HR target). The intent is to provide a compact, reproducible starting point; full training scripts and additional configurations are available in the accompanying repository.

\begin{verbatim}
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset

# Load paired signals (rows align by index)
x = np.loadtxt('SignalBuilderC/data/signals_subsampled_simple_250.txt')   # (2500, 250)
y = np.loadtxt('SignalBuilderC/data/signals_high_resolution_5000.txt')   # (2500, 5000)

# Train/val split (example protocol)
x_train, y_train = x[:2000], y[:2000]
x_val,   y_val   = x[2000:2500], y[2000:2500]

device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')

def to_tensor(a):
    # Convert NumPy array (B, L) into torch tensor (B, 1, L)
    # The extra channel dimension matches Conv1d input format
    return torch.tensor(a, dtype=torch.float32).unsqueeze(1)  # (B, 1, L)

# Create dataloaders for batched training
train_loader = DataLoader(TensorDataset(to_tensor(x_train), to_tensor(y_train)),
                          batch_size=16, shuffle=True)
val_loader   = DataLoader(TensorDataset(to_tensor(x_val), to_tensor(y_val)),
                          batch_size=16, shuffle=False)

class TinySRNet(nn.Module):
    def __init__(self, out_len=5000):
        super().__init__()
        # Encoder: extract local features in the LR domain
        self.enc = nn.Sequential(
            nn.Conv1d(1, 64, kernel_size=5, padding=2), nn.ReLU(),
            nn.Conv1d(64, 128, kernel_size=5, padding=2), nn.ReLU(),
            nn.Conv1d(128, 256, kernel_size=5, padding=2), nn.ReLU(),
        )
        # Upsampling: map LR features to the HR length
        self.up = nn.Upsample(size=out_len, mode='linear', align_corners=False)
        # Decoder: project features back to a 1-channel HR signal
        self.dec = nn.Sequential(
            nn.Conv1d(256, 128, kernel_size=5, padding=2), nn.ReLU(),
            nn.Conv1d(128, 64, kernel_size=5, padding=2), nn.ReLU(),
            nn.Conv1d(64, 1, kernel_size=5, padding=2),
        )

    def forward(self, x):
        z = self.enc(x)
        z = self.up(z)
        return self.dec(z)

model = TinySRNet(out_len=5000).to(device)
# Optimizer and loss (MSE is a standard regression objective)
opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)
loss_fn = nn.MSELoss()

for epoch in range(1, 11):
    model.train()
    for xb, yb in train_loader:
        xb, yb = xb.to(device), yb.to(device)
        # Forward + loss + backward + update
        opt.zero_grad()
        pred = model(xb)
        loss = loss_fn(pred, yb)
        loss.backward()
        opt.step()

    model.eval()
    with torch.no_grad():
        # Validation loop: average loss over batches
        val_loss = 0.0
        for xb, yb in val_loader:
            xb, yb = xb.to(device), yb.to(device)
            val_loss += loss_fn(model(xb), yb).item()
    val_loss /= len(val_loader)
    print(f"epoch={epoch:02d} val_mse={val_loss:.4f}")
\end{verbatim}


\section*{Code availability}
\label{sec:code-availability}



The complete signal generation pipeline, including modules for frequency profile generation, amplitude envelope construction, spline interpolation, noise application, and data export in multiple formats, is available at:  
\href{https://github.com/DhamarAM/SignalBuilder/tree/main}{CoSiBD scripts on GitHub}.

The repository includes SignalBuilderC, a modular Python package with documented functions for: (1) generating high-resolution signals with configurable parameters, (2) creating subsampled versions via simple decimation (uniform subsampling), (3) exporting signals in NumPy, text, and JSON formats, and (4) comprehensive metadata generation. All code is provided with example notebooks demonstrating dataset regeneration and usage.
These scripts are distributed under the MIT License.

The dataset itself is published separately at:  
Zenodo\cite{cosibd_zenodo_2025} (DOI: \href{https://doi.org/10.5281/zenodo.15138853}{10.5281/zenodo.15138853}).
The Zenodo record distributes the dataset under the Creative Commons Attribution 4.0 International (CC BY 4.0) license.

% ===== BIBLIOGRAPHY =====
% Using BibTeX with naturemag-doi style for Nature Scientific Data
% References stored in referencias.bib
% Note: \bibliographystyle{naturemag-doi} is defined in wlscirep.cls
\bibliography{referencias}


\section*{Acknowledgments}
This research was supported by Dean's Office of the Polytechnic College of the San Francisco de Quito University  and partially by ProyExcel-0069 project of the Andalusian University, Research and Innovation Department.

\section*{Author Contributions}
J. I. F. handled the methodological design for artificial data creation, probabilistic analysis, spline-based variations, noise distributions, and node selection. J. A. L. was responsible for methodology (time series design) and supervision. D. A. M. performed data processing and validation analysis. All of the authors have contributed to writing the manuscript.

\section*{Competing Interests}
The authors declare no competing interests

\end{document}