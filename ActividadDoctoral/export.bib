@article{bengioDeepArch2009,
   abstract = {Theoretical results suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g., in vision, language, and other AI-level tasks), one may need deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in complicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the stateof-the-art in certain areas. This monograph discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks. © 2009 Y. Bengio.},
   author = {Yoshua Bengio},
   doi = {10.1561/2200000006},
   issn = {19358237},
   issue = {1},
   journal = {Foundations and Trends in Machine Learning},
   pages = {1-27},
   title = {Learning deep architectures for AI},
   volume = {2},
   year = {2009},
}
@article{LecunbengioHinton2015,
   abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech},
   author = {Yann LeCun and Yoshua Bengio and Geoffrey Hinton},
   journal = {Nature},
   pages = {436-444},
   title = {Deeplearning},
   volume = {521},
   url = {https://www.nature.com/articles/nature14539},
   year = {2015},
}
@misc{GoodfellowBengioCourville2016,
   author = {Ian Goodfellow and Yoshua Bengio and Aaron Courville},
   title = {Deeplearning},
   year = {2016},
}
@article{MocaBarzanNagy2021,
   abstract = {Due to the Heisenberg–Gabor uncertainty principle, finite oscillation transients are difficult to localize simultaneously in both time and frequency. Classical estimators, like the short-time Fourier transform or the continuous-wavelet transform optimize either temporal or frequency resolution, or find a suboptimal tradeoff. Here, we introduce a spectral estimator enabling time-frequency super-resolution, called superlet, that uses sets of wavelets with increasingly constrained bandwidth. These are combined geometrically in order to maintain the good temporal resolution of single wavelets and gain frequency resolution in upper bands. The normalization of wavelets in the set facilitates exploration of data with scale-free, fractal nature, containing oscillation packets that are self-similar across frequencies. Superlets perform well on synthetic data and brain signals recorded in humans and rodents, resolving high frequency bursts with excellent precision. Importantly, they can reveal fast transient oscillation events in single trials that may be hidden in the averaged time-frequency spectrum by other methods.},
   author = {Vasile V. Moca and Harald B\^arzan and Adriana Nagy-D\u{a}b\^acan and Raul C. Muresan},
   doi = {10.1038/s41467-020-20539-9},
   issn = {20411723},
   issue = {1},
   journal = {Nature Communications},
   month = {12},
   pmid = {33436585},
   publisher = {Nature Research},
   title = {Time-frequency super-resolution with superlets},
   volume = {12},
   year = {2021},
}
@article{LiuQianYang2022,
   abstract = {High spatial-temporal resolution plays a vital role in the application of geoscience dynamic observance and prediction. However, thanks to the constraints of technology and budget, it is troublesome for one satellite detector to get high spatial-temporal resolution remote sensing images. Individuals have developed spatiotemporal image fusion technology to resolve this downside, and deep remote sensing images with spatiotemporal resolution have become a possible and efficient answer. Due to the fixed size of the receptive field of convolutional neural networks, the features extracted by convolution operations cannot capture long-range features, so the correlation of global features cannot be modeled in the deep learning process. We propose a spatiotemporal fusion model of remote sensing images to solve these problems based on a dual branch feedback mechanism and texture transformer. The model separates the network from the coarse-fine images with similar structures through the idea of double branches and reduces the dependence of images on time series. It principally merges the benefits of transformer and convolution network and employs feedback mechanism and texture transformer to extract additional spatial and temporal distinction features. The primary function of the transformer module is to learn global temporal correlations and fuse temporal features with spatial features. To completely extract additional elaborated features in several stages, we have a tendency to design a feedback mechanism module. This module chiefly refines the low-level representation through high-level info and obtains additional elaborated features when considering the temporal and spacial characteristics. We have a tendency to receive good results by comparison with four typical spatiotemporal fusion algorithms, proving our model’s superiority and robustness.},
   author = {Hui Liu and Yurong Qian and Guangqi Yang and Hao Jiang},
   doi = {10.3390/electronics11162497},
   issn = {20799292},
   issue = {16},
   journal = {Electronics (Switzerland)},
   keywords = {detailed features,feedback mechanism,remote sensing images,spatiotemporal image fusion,texture tran-sformer},
   month = {8},
   publisher = {MDPI},
   title = {Super-Resolution Reconstruction Model of Spatiotemporal Fusion Remote Sensing Image Based on Double Branch Texture Transformers and Feedback Mechanism},
   volume = {11},
   year = {2022},
}
@article{Balestriero2020,
   abstract = {We develop an interpretable and learnable Wigner-Ville distribution that produces a super-resolved quadratic signal representation for time-series analysis. Our approach has two main hallmarks. First, it interpolates between known time-frequency representations (TFRs) in that it can reach super-resolution with increased time and frequency resolution beyond what the Heisenberg uncertainty principle prescribes and thus beyond commonly employed TFRs, Second, it is interpretable thanks to an explicit low-dimensional and physical parameterization of the Wigner-Ville distribution. We demonstrate that our approach is able to learn highly adapted TFRs and is ready and able to tackle various large-scale classification tasks, where we reach state-of-the-art performance compared to baseline and learned TFRs.},
   author = {Randall Balestriero and Herve Glotin and Richard G. Baraniuk},
   month = {6},
   title = {Interpretable Super-Resolution via a Learned Time-Series Representation},
   url = {http://arxiv.org/abs/2006.07713},
   year = {2020},
}
@article{ChengWangLuo2022,
   abstract = {With the development of convolutional neural networks, impressive success has been achieved in remote sensing image super-resolution. However, the performance of super-resolution reconstruction is unsatisfactory due to the lack of details in remote sensing images when compared to natural images. Therefore, this paper presents a novel multiscale convolutional sparse coding network (MCSCN) to carry out the remote sensing images SR reconstruction with rich details. The MCSCN, which consists of a multiscale convolutional sparse coding module (MCSCM) with dictionary convolution units, can improve the extraction of high frequency features. We can obtain more plentiful feature information by combining multiple sizes of sparse features. Finally, a layer based on sub-pixel convolution that combines global and local features takes as the reconstruction block. The experimental results show that the MCSCN gains an advantage over several existing state-of-the-art methods in terms of peak signal-to-noise ratio and structural similarity.},
   author = {Ruihong Cheng and Huajun Wang and Ping Luo},
   doi = {10.1371/journal.pone.0276648},
   issn = {19326203},
   issue = {10 October},
   journal = {PLoS ONE},
   month = {10},
   pmid = {36288378},
   publisher = {Public Library of Science},
   title = {Remote sensing image super-resolution using multi-scale convolutional sparse coding network},
   volume = {17},
   year = {2022},
}
