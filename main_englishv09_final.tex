\documentclass[fleqn,10pt]{wlscirep}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lineno}
 \usepackage{multirow}
\usepackage{array}  % Añade esto en el preámbulo
\renewcommand{\arraystretch}{1.3}  % Espaciado vertical entre filas

\usepackage{subcaption}
\linenumbers
\usepackage{float}

% ===== TRACK CHANGES PACKAGE =====
% Use [draft] to show changes with highlighting
% Use [final] to hide all markup for submission
\usepackage[final]{changes}
\usepackage{xcolor}

% Define authors for tracked changes
\definechangesauthor[name={Revision}, color=yellow]{REV}

% Custom commands for easier tracking
\newcommand{\addtext}[1]{\added[id=REV]{#1}}
\newcommand{\deltext}[1]{\deleted[id=REV]{#1}}
\newcommand{\replacetext}[2]{\replaced[id=REV]{#1}{#2}}
\newcommand{\notetext}[1]{\comment[id=REV]{#1}}
\newcommand{\highlighttext}[1]{\highlight[id=REV]{#1}}
% ===== END TRACK CHANGES =====  

%\title{CoSiBD: A Versatile Dataset for Benchmarking Signal Processing and Machine Learning Algorithms}
%\title{CoSiBD: A Synthetic Dataset for Super-Resolution Deep Learning Temporal Series Analysis}
%\title{A synthetic dataset for super-resolution of Time Series using Deep Learning}
\title{A synthetic dataset for Time Series Super-Resolution with Deep Learning}
\author[1]{Julio Ibarra-Fiallo}
\author[2]{Juan A. Lara}
\author[1]{D'hamar Agudelo-Moreno}
%\author[2,*]{autor }
\affil[1]{Colegio de Ciencias e Ingenierías, Universidad San Francisco de Quito, Cumbayá, Ecuador}
\affil[2]{Universidad de Córdoba, Córdoba, España}

\affil[*]{corresponding author: Julio Ibarra-Fiallo (jibarra@usfq.edu.ec)}


\begin{abstract}
\deltext{The increasing application of temporal signal analysis in fields like biomedical engineering, telecommunications, and industrial monitoring emphasizes the need for high-quality data to train and evaluate advanced machine learning models.}\addtext{The increasing application of time-series analysis in fields like biomedical engineering, telecommunications, and industrial monitoring emphasizes the need for high-quality data to train and evaluate advanced machine learning models.} Acquiring real-world temporal data at suitable resolutions is often limited by ethical, economic, or practical constraints. To address this, we introduce CoSiBD (Complex Signal Benchmark Dataset for Super-Resolution), a synthetic dataset of complex temporal signals designed for training and assessing AI models, particularly deep learning systems, in tasks like temporal super-resolution and signal processing. \addtext{CoSiBD comprises 2,500 high-resolution signals (5,000 samples each over the domain [0, 4$\pi$]) with corresponding subsampled versions at four resolution levels (150, 250, 500, and 1,000 samples).} \addtext{Each signal is provided in three formats (NumPy arrays, plain text, and JSON) with comprehensive metadata documenting all generation parameters, including random seeds for full reproducibility.} CoSiBD includes diverse signals with non-uniform frequency modulations, capturing gradual transitions and abrupt high-frequency events to mirror real-world dynamics. It offers signals at multiple resolutions with varying noise levels, enabling robust evaluation of model performance under realistic conditions, especially for super-resolution tasks. \addtext{Subsampling is performed using two approaches: direct re-evaluation at lower time resolutions and anti-aliasing filtered downsampling to prevent frequency aliasing.} The dataset is generated by combining distinct frequency bands, non-uniform intervals, and probabilistic frequency assignments to create realistic patterns, with smoothing achieved through spline interpolation. Validated for spectral consistency across sampling rates and noise, CoSiBD supports training and evaluation.
\end{abstract}
\begin{document}

\flushbottom
\maketitle

\section*{Background \& Summary}

\deltext{The analysis and simulation of temporal signals are fundamental across science and engineering, supporting insights into dynamic processes.}\addtext{The analysis and simulation of temporal signals are fundamental across science and engineering. These techniques provide critical insights into dynamic processes in multiple domains.} In biomedical research \cite{Karacan2024}, electroencephalography (EEG) and electrocardiography (ECG) analyses reveal brain and heart function \cite{Nayak2023,shaffer2017}. Telecommunications rely on signal processing to ensure data fidelity across noisy media \cite{Chen2022}, while finance uses time-series forecasting for risk and trend analysis \cite{Zhang2016}. Industrial monitoring detects equipment faults using temporal patterns \cite{Bhatia2021}, and environmental science applies similar techniques to climate tracking via remote sensing \cite{Mallat1989}. Developing robust tools for interpreting time-varying data continues to support both scientific discovery and practical applications.
\\ \\
Recent advances in deep learning have contributed significantly to this field by enabling automatic extraction of complex features from raw signals. Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), including Long Short-Term Memory (LSTM) units, and Generative Adversarial Networks (GANs) have demonstrated improved performance over traditional techniques in image, speech, and time-series processing tasks \cite{Lecun2015,Goodfellow2014}. These models support fine-grained signal reconstruction and forecasting, allowing researchers to explore temporal dynamics in new ways.
\\ \\
Despite this progress, deep learning methods for temporal signal processing often require large quantities of labeled, high-quality data. Access to such data is frequently constrained by medical privacy regulations such as the General Data Protection Regulation (GDPR) and the Health Insurance Portability and Accountability Act (HIPAA) \cite{Isasa2024}. In other domains, including remote sensing and industrial monitoring, data availability is limited by practical and economic barriers to sensor deployment and data collection \cite{Zhang2016}. These limitations are particularly relevant in super-resolution (SR) tasks, where models require paired low- and high-resolution signals for effective training.
\\ \\
Temporal SR, which enhances resolution over time, has broad potential. In medicine, for instance, it improves magnetic resonance imaging (MRI) and computed tomography (CT) scans, supporting earlier disease detection \cite{Morales2022}. For EEG analysis, SR may help recover high-frequency components that aid in the study of neural oscillations \cite{Nayak2023} or detect subtle physiological irregularities \cite{shaffer2017}. In remote sensing, SR helps refine satellite imagery \cite{Mallat1989}, while in telecommunications it contributes to enhanced signal reliability. It also has applications in industrial monitoring by increasing sensitivity to system changes.
\\ \\
Traditional SR methods such as polynomial interpolation, frequency-domain transforms, and splines each have limitations. Polynomial models are often insufficient for capturing nonlinear dynamics; frequency-domain methods are susceptible to noise \cite{Mallat1989}; and splines, though flexible, may not generalize well to complex signal variability \cite{Schumaker2007,DeBoor2001}. Many of these methods also assume uniform partitioning, which may not align with the multi-scale, irregular structure of natural temporal phenomena.
\\ \\
Deep learning offers adaptive alternatives to these traditional methods. CNNs are capable of modeling spatio-temporal structure, RNNs and LSTMs capture long-range dependencies in time, and GANs can learn high-resolution representations through adversarial training \cite{Lecun2015,Goodfellow2014}. While GANs have achieved strong results in image SR \cite{Brophy2023}, their application to time-series SR remains relatively new. Preliminary work on synthetic time-series generation indicates potential \cite{Brophy2023,IbarraFiallo2024}, but the lack of accessible, high-quality paired datasets remains a significant barrier to progress.
\\ \\
Synthetic datasets offer one solution to this problem, allowing researchers to design reproducible training environments that reflect the structure and variability of real-world signals. Prior studies have used synthetic data in domains such as fluid dynamics \cite{Yasuda2023}, bioimaging \cite{Priessner2024}, and live-cell imaging \cite{Qiao2025}, demonstrating that synthetic approaches can help simulate complexity while avoiding legal and practical restrictions associated with real-world data.
\\ \\
To support research in super-resolution for time-series data, we present the Complex Signal Benchmark Dataset (CoSiBD). CoSiBD is a synthetic dataset composed of time-series signals with variable resolution, frequency characteristics, and noise levels. The dataset is intended to provide a resource for training and evaluating SR models under controlled, reproducible conditions. It includes non-uniformly sampled signals, multiple levels of resolution and noise, a technical validation suite, and publicly available Python code to facilitate use. CoSiBD has been used in research presented at the International Conference on Signal Processing and Machine Learning~\cite{IbarraFiallo2024} and is made available to support further development in deep learning approaches for temporal super-resolution.


\section*{Methods}

The methodology used to generate the synthetic temporal signals that constitute the CoSiBD dataset is illustrated in Figure~\ref{fig:generation_process}. The process was designed to produce signals that reflect general characteristics of real-world temporal data, such as variable frequency content, continuous transitions, and intermittent high-frequency activity. A key aspect of the procedure is the ability to produce signals at different resolution levels, supporting the generation of paired datasets for evaluating super-resolution (SR) algorithms.

\begin{figure}
    \centering
    \includegraphics[width=0.35\textwidth]{diagrams/generation_process4.png}
    \caption{Schematic overview of the CoSiBD signal generation process.}
    \label{fig:generation_process}
\end{figure}

\noindent The signal generation pipeline involves the following steps:

\begin{enumerate}
    \item \textbf{Base frequency band definition:} A set of distinct frequency bands is defined to represent the underlying spectral content of the signals. These can be adjusted to reflect application-specific characteristics.

    \item \textbf{Non-uniform interval partitioning:} The total signal duration is divided into multiple intervals of variable length. The interval lengths are determined probabilistically to introduce variability in the signal structure.

    \item \textbf{Frequency assignment:} Each interval is assigned a dominant frequency band, sampled according to a predefined probability distribution. This introduces spectral variation over time.

    \item \textbf{Signal synthesis:} A sinusoidal waveform, or a combination of sinusoids within the assigned frequency band, is generated for each interval. Signal parameters such as amplitude and phase are configurable.

    \item \textbf{Transition smoothing:} To avoid discontinuities at interval boundaries, a smoothing function is applied to overlapping segments. This ensures gradual transitions between intervals with different frequency content.

    \item \textbf{Resolution variation:} All signals are initially synthesized at a high temporal resolution \addtext{(5,000 samples over the domain [0, 4$\pi$])}. Lower-resolution versions are created \addtext{using two distinct approaches: (1) direct re-evaluation by computing the signal at fewer time points using the original generation parameters, and (2) anti-aliasing filtered downsampling, where a Butterworth low-pass filter (order 8) is applied before resampling to prevent frequency aliasing. The filter cutoff is set at 90\% of the target Nyquist frequency for each resolution level.} \notetext{Addresses reviewer requirement for anti-aliasing filter documentation.}

    \item \textbf{Noise injection:} Controlled levels of synthetic noise are added to the signals to emulate different data acquisition scenarios. \addtext{Two noise types are implemented: Gaussian noise with configurable standard deviation (relative to signal amplitude) and structured sinusoidal noise bursts. Noise is applied probabilistically with 50\% probability per signal.} Both the type and intensity of the noise can be configured.
\end{enumerate}

\noindent The parameters that govern each step of the generation process—such as interval length distributions, frequency band selection probabilities, smoothing function characteristics, sampling rates, and noise settings—can be configured to produce signal sets tailored to different domains or experimental conditions. \addtext{All generation parameters, including random seeds, are documented in comprehensive metadata files stored alongside each signal, enabling exact reproduction of individual signals or the complete dataset. The generation pipeline is implemented in modular Python code available in the SignalBuilderC package, with clear interfaces for customization and extension.} These configurations are included in the dataset's accompanying code to support reproducibility and allow users to regenerate the signals under consistent conditions.
\notetext{Addresses reviewer requirement for better documentation of generation parameters and reproducibility.}

\section*{Data Records}

The Complex Signal Benchmark Dataset (CoSiBD) is publicly available and consists of synthetic temporal signals created to support the development and evaluation of temporal super-resolution (SR) algorithms. This section provides an overview of the dataset structure, content, and storage format.
\\ \\
\deltext{The dataset includes a total of 7,800 signal samples divided into two main categories:}
\addtext{The dataset comprises 2,500 high-resolution signals, each with corresponding subsampled versions at four resolution levels, organized into three main categories:}

\begin{itemize}
    \item \textbf{High-resolution signals}\addtext{: 2,500 signals with 5,000 samples each, spanning the domain [0, 4$\pi$]. Each signal is stored in three formats: NumPy compressed format (.npz), plain text (.txt), and JSON (.json). Comprehensive metadata is provided in separate JSON files documenting all generation parameters including frequency profiles, amplitude envelopes, spline parameters, vertical offsets, noise configurations, and random seeds for reproducibility.}
    \item \deltext{\textbf{Low-resolution signals}, obtained through controlled downsampling of the high-resolution versions, available at three distinct resolution levels.}\addtext{\textbf{Simple subsampled signals}: Re-evaluation of each high-resolution signal at four target resolutions (150, 250, 500, and 1,000 samples). Stored in .npz, .txt, and .json formats.}
    \item \addtext{\textbf{Anti-aliasing filtered signals}: Downsampled versions at the same four resolutions after applying Butterworth low-pass filtering to prevent frequency aliasing. Filter parameters documented in filtering\_info.json. Stored in .npz, .txt, and .json formats.}
\end{itemize}
\notetext{Addresses reviewer requirements for proper data format documentation and metadata.}

\noindent \deltext{Noise is applied to both high- and low-resolution signals at different signal-to-noise ratio (SNR) levels (20 dB, 10 dB, and 5 dB), integrated directly into the signal files.}
\addtext{Reproducibility is ensured through documented random seeds: each high-resolution signal is generated using a unique seed (ranging from 10,000 to 12,499), enabling exact regeneration of individual signals or the entire dataset. All generation parameters are stored in metadata JSON files, including: (1) frequency profile parameters---tau\_frequency values from uniform distribution [1, 2] with 0.05 step; (2) amplitude envelope parameters---tau\_amplitude from \{1, 3, 5, 8, 10, 12, 15, 20\} for tension splines, or zero-order step functions (70\% probability); (3) vertical offsets---normally distributed (mean=0, SD=3.0); and (4) noise configurations---50\% probability of Gaussian or structured noise.}
\notetext{Addresses reviewer concerns about reproducibility and metadata documentation.}
\\ \\
\deltext{Table~\ref{tab:signal_dimensions} summarizes the dataset subsets, indicating sample counts and resolution. Naming conventions follow a consistent pattern: `Sub\_Super\_Sample` prefixes denote high-resolution subsets, while `Sub\_Sample` denotes low-resolution ones. Resolution pairings are indicated in the names (e.g., `500\_5000`), and validation subsets are labeled with the suffix `Val`.}
\addtext{The dataset is organized into three main directories: \texttt{signals\_high\_resolution/} containing the 2,500 original signals, \texttt{signals\_subsampled\_simple/} containing re-evaluated versions at each resolution level, and \texttt{signals\_subsampled\_filtered/} containing anti-aliasing filtered versions. A comprehensive \texttt{metadata/} directory includes individual signal metadata files and a dataset\_summary.json index file.}

\noindent \deltext{Signals are stored in plain text `.txt` files containing NumPy-formatted arrays. Each file represents a single temporal signal as a one-dimensional sequence of numerical values. The dataset folder structure mirrors the subset names presented in Table~\ref{tab:signal_dimensions}.}
\addtext{Each signal is stored in three formats: (1) NumPy compressed format (.npz) containing the signal array, time array, and (for high-resolution only) clean signal without noise; (2) plain text format (.txt) with one sample value per line for maximum portability; and (3) JSON format (.json) with both time and signal arrays for web-based applications and interoperability. High-resolution signals additionally include metadata in separate JSON files (signal\_XXXX\_metadata.json) documenting all generation parameters.}
\notetext{Addresses reviewer requirement for standard data formats.}
\\
\noindent The following resolution levels are available:

\begin{itemize}
    \item \textbf{High-resolution:} 5000 \deltext{points}\addtext{samples (or points)} per signal\addtext{, sampled over the domain [0, 4$\pi$] at frequency fs = 5000/(4$\pi$) $\approx$ 398 Hz}.
    \item \deltext{\textbf{Low-resolution:} Created via downsampling from the high-resolution version:}\addtext{\textbf{Subsampled resolutions:} Available in both simple (re-evaluated) and filtered (anti-aliasing) versions:}
    \begin{itemize}
        \item \deltext{1000 points}\addtext{1000 samples (fs $\approx$ 79.6 Hz)}
        \item \deltext{500 points}\addtext{500 samples (fs $\approx$ 39.8 Hz)}
        \item \deltext{250 points}\addtext{250 samples (fs $\approx$ 19.9 Hz)}
        \item \addtext{150 samples (fs $\approx$ 11.9 Hz)}
    \end{itemize}
\end{itemize}
\notetext{Clarifies terminology and adds sampling frequencies as requested by reviewers.}

\noindent Table~\ref{tab:Parameter} outlines the main parameters used in signal generation. \addtext{Each high-resolution signal was generated with a unique random seed (10,000--12,499) and randomly sampled parameter values within the defined ranges, ensuring diversity while maintaining reproducibility.}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|m{6cm}|}
\hline
\textbf{Parameter} & \textbf{Range} & \textbf{Description} \\ \hline
Low Frequency & 1--5 Hz & Low-frequency component present in signals \\ \hline
High Frequency & 20--100 Hz & Higher-frequency variations for transitions \\ \hline
Change Points & 2--11 & Number of frequency transitions per signal \\ \hline
Change Locations & Random & Time locations where transitions occur \\ \hline
Variation Type & Categorical & Defines nature of frequency change ("low", "high", "no\_change") \\ \hline
\addtext{Amplitude Range} & \addtext{3--16} & \addtext{Range for amplitude envelope values} \\ \hline
\addtext{Vertical Offset} & \addtext{N(0, 3.0)} & \addtext{Normally distributed offset added to signals} \\ \hline
\addtext{Spline Type} & \addtext{Mixed} & \addtext{70\% zero-order (step), 30\% tension spline} \\ \hline
\addtext{Tension Parameter (freq)} & \addtext{[1, 2]} & \addtext{Tau values for frequency spline interpolation} \\ \hline
\addtext{Tension Parameter (amp)} & \addtext{\{1,3,5,8,10,12,15,20\}} & \addtext{Tau values for amplitude spline (when tension type)} \\ \hline
\addtext{Noise Probability} & \addtext{50\%} & \addtext{Probability of adding noise to each signal} \\ \hline
\addtext{Random Seed} & \addtext{10000--12499} & \addtext{Unique seed per signal for reproducibility} \\ \hline
\end{tabular}
\caption{Signal generation parameters used to create diverse temporal patterns within the CoSiBD dataset. \addtext{All parameters are documented in individual metadata files, enabling exact reproduction of each signal.} These parameters control the frequency composition and temporal structure.}
\label{tab:Parameter}
\end{table}
\notetext{Expanded parameter documentation addressing reviewer concerns about missing parameter specifications.}

\noindent Figure~\ref{fig:amplitud} shows a representative signal from the dataset sampled at different resolution levels, as well as a version with added noise. This illustrates the variety of sampling and noise conditions included in CoSiBD.

\begin{figure}
\centering
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/amplitud1.png}
    \subcaption{High-resolution signal (5000 points).}
    \label{fig:amp1}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/amplitud2.png}
    \subcaption{Medium-resolution signal (500 points).}
    \label{fig:amp2}
\end{minipage}

\vspace{0.15cm}

\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/amplitud3.png}
    \subcaption{Low-resolution signal (250 points).}
    \label{fig:amp3}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/amplitud4.png}
    \subcaption{Signal with added noise.}
    \label{fig:amp4}
\end{minipage}

\caption{A synthetic signal sampled at different resolutions: (a) high (5000 points), (b) medium (500 points), (c) low (250 points), and (d) with added noise. These examples reflect the multi-resolution and noise conditions present in the dataset.}
\label{fig:amplitud}
\end{figure}

\vspace{0.3cm}

\noindent Figure~\ref{fig:simples} displays four additional synthetic signals generated using different configuration parameters. These examples demonstrate the variability in temporal structure across instances in the dataset.

\begin{figure}
\centering
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/simples1.png}
    \subcaption{Signal with increasing frequency over time.}
    \label{fig:simp1}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/simples2.png}
    \subcaption{Signal with localized frequency variation.}
    \label{fig:simp2}
\end{minipage}

\vspace{0.15cm}

\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/simples3.png}
    \subcaption{Signal with smooth oscillations and broad amplitude cycles.}
    \label{fig:simp3}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/simples4.png}
    \subcaption{Signal with irregular peak spacing.}
    \label{fig:simp4}
\end{minipage}

\caption{Examples of synthetic signals in the dataset generated with different parameter configurations. Each signal presents a distinct temporal profile.}
\label{fig:simples}
\end{figure}

\noindent The full dataset is hosted in \href{https://zenodo.org/records/15138853}{CoSiBD dataset on Zenodo}, and includes all `.txt` signal files and associated metadata in structured folders.


\section*{Technical Validation}

This section validates the proposed signal generation method by analyzing its spectral properties under different conditions, including the distribution of dominant frequencies, spectral stability across sampling rates, and the effect of noise. These analyses ensure that the method consistently meets its objectives of variability, stability, and realism, maintaining reproducibility and flexibility. Below, the methodologies and results are described in detail.

\subsection*{Validation Context}
\deltext{Experimental parameters were carefully selected to ensure reproducibility and
relevance. The number of signals (n=50) was chosen to provide statistically significant
information about the variability and consistency of the generated signals. Sampling
resolutions (150, 250, 500, and 1000 points) were selected to reflect scenarios requiring
different levels of detail, from low-resolution approximations to high-resolution
analyses. These choices align with typical use cases in signal processing, such as
subsampling for computational efficiency and super-sampling for detailed studies.
\\ \\
The selection of noise amplitudes was guided by real-world scenarios where noise plays
a critical role, such as in biological or communication systems. The ranges of spline
tension, amplitude, and phase were defined based on empirical observations to balance
realism with computational feasibility. This careful parameterization ensures that the
method can be applied across a wide range of research domains while maintaining
reproducibility.}\addtext{Experimental parameters were carefully selected to ensure reproducibility and relevance. The number of signals (n=50) provides statistically significant information about variability and consistency. Sampling resolutions (150, 250, 500, and 1000 points) reflect scenarios requiring different levels of detail, aligning with typical signal processing use cases. Noise amplitudes, spline tension ranges, and amplitude/phase parameters were defined based on real-world scenarios and empirical observations, balancing realism with computational feasibility across diverse research domains.}

\subsection*{Analysis of Dominant Frequency Distribution}

To assess the stability and variability of the primary spectral components, we analyzed the distribution of dominant frequencies across multiple generated signals. A total of fifty independent signals were synthesized using identical input parameters. To examine their spectral characteristics, we computed the power spectral density (PSD) of each signal, which quantifies how signal power is distributed across different frequencies.
\\ \\
The PSD was estimated using Welch’s method, selected for its ability to reduce noise and provide a smoother spectral representation \cite{Welch1967}. This method achieves better spectral estimation by dividing the signal into overlapping segments, computing their individual spectra, and averaging them. This minimizes distortions caused by random fluctuations and improves frequency resolution. For each signal, the dominant frequency was identified as the frequency at which the PSD reaches its maximum value. This corresponds to the most prominent spectral component, indicating where the signal concentrates most of its energy.
\\ \\
By analyzing the distribution of dominant frequencies across the dataset, we evaluate whether the generated signals exhibit consistent spectral patterns or if there is significant variation. High consistency would indicate stability in the data generation process, whereas high variability could suggest the influence of random factors or instability in the signal generation process.

\begin{figure}
    \centering
    \includegraphics[width=0.56\textwidth]{graphs/analysis_densidad.png}
    \caption{Distribution of dominant frequencies in 50 independently generated signals.}
    \label{fig:dominant_frequency_distribution}
\end{figure}

\begin{table}
\centering
\small
\begin{tabular}{|l|l|}
\hline
Statistic  & Value (Hz) \\
\hline
Average Dominant Frequency  & 0.508 \\
Standard Deviation  & 0.195 \\
Minimum Dominant Frequency  & 0.390 \\
Maximum Dominant Frequency  & 1.171 \\
\hline
\end{tabular}
\caption{\label{tab:density_label}Summary statistics of dominant frequencies, including average, standard deviation, and extreme values.}
\end{table}

\noindent The results, shown in Figure~\ref{fig:dominant_frequency_distribution} and Table~\ref{tab:density_label}, demonstrate that the dominant frequencies are predominantly concentrated in the low-frequency range (0.4 to 0.8 Hz), with sporadic occurrences of higher frequencies (1.1 to 1.2 Hz). This reflects the method's ability to generate signals with consistent primary structures while introducing controlled variability. Such flexibility is beneficial for applications requiring limited spectral variability while maintaining the predominance of low frequencies.

\noindent Figure \ref{fig:noise_ruido} presents examples of signals from the CoSiBD dataset with increasing levels of added noise, illustrating how amplitude fluctuations progressively obscure the underlying temporal structure.

\begin{figure}[H] \centering \begin{minipage}{0.47\textwidth} \centering \includegraphics[width=\textwidth]{graphs/ruido1.png} \subcaption{Low-noise signal, where amplitude variations are present but minimally distorted.} \label{fig:noise1} \end{minipage} \hspace{0.02\textwidth} \begin{minipage}{0.47\textwidth} \centering \includegraphics[width=\textwidth]{graphs/ruido2.png} \subcaption{Moderate-noise signal, with irregular peaks and troughs beginning to distort the oscillatory pattern.} \label{fig:noise2} \end{minipage}

\vspace{0.15cm}

\begin{minipage}{0.47\textwidth} \centering \includegraphics[width=\textwidth]{graphs/ruido3.png} \subcaption{High-noise signal, where significant distortion leads to unpredictable fluctuations.} \label{fig:noise3} \end{minipage} \hspace{0.02\textwidth} \begin{minipage}{0.47\textwidth} \centering \includegraphics[width=\textwidth]{graphs/ruido4.png} \subcaption{Extreme-noise signal, where the original oscillatory structure is almost entirely masked by chaotic interference.} \label{fig:noise4} \end{minipage}

\caption{Visualization of signals under increasing noise conditions, showing how random fluctuations progressively mask the original temporal patterns. From low (a) to extreme noise levels (d), this degradation highlights the reconstruction challenges faced by robust super-resolution models.} \label{fig:noise_ruido} \end{figure}



\subsection*{Spectral Stability Across Sampling Resolutions}

This analysis aims to investigate the influence of sampling resolution on the robustness of spectral estimates under varying frequency content. At lower resolutions, aliasing can obscure critical frequency peaks, compromising the ability to distinguish closely spaced spectral components \cite{Rabiner1975}. Conversely, higher resolutions improve the granularity of the frequency axis, allowing for better separation of spectral features and reducing the risk of misrepresenting the signal’s underlying structure \cite{Marple1987}.

\noindent Ultimately, this evaluation seeks to determine the sampling resolution that optimizes both spectral fidelity and practical utility. By quantifying the relationship between resolution and spectral stability, this approach provides a framework for selecting appropriate sampling rates in real-world applications, ensuring accurate frequency-domain analysis while managing computational resources efficiently.


\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{graphs/psd.png}
    \caption{Average power spectral density (PSD) for different sampling resolutions based on 50 independent runs.}
    \label{fig:average_psd}
\end{figure}

As shown in Figure~\ref{fig:average_psd}, lower sampling resolutions, specifically the blue curve (150 points) and the orange curve (250 points), exhibit a noticeable reduction in detail within the high-frequency range. These lower-resolution curves display greater fluctuations and noise, particularly beyond 20 Hz, which is consistent with the theoretical effects of subsampling. The blue curve (150 points) is especially affected, showing significant variability and a less stable spectral representation in the higher frequencies.
\\ \\
In contrast, the higher sampling demonstrate a smoother and more stable spectral profile across all frequencies. The red curve (1000 points), in particular, captures finer details and exhibits minimal high-frequency noise, making it the most reliable for precise spectral analysis. 


\subsection*{Impact of Noise on Frequency Characteristics}

Analyzing the impact of noise on frequency characteristics is a critical step in validating the robustness and reliability of spectral analysis methods. Understanding how noise influences the Power Spectral Density (PSD) allows for the assessment of a method's sensitivity and its ability to preserve essential signal features despite the presence of interference.
\\ \\
It is generally expected that higher noise amplitudes will have a more pronounced effect on the high-frequency components of the PSD, as noise tends to introduce rapid fluctuations and random variations that are typically reflected in these regions. Conversely, the low-frequency components are anticipated to remain relatively stable, given that noise often has a lesser impact on slower signal dynamics.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{graphs/noise.png}
    \caption{Power spectral density (PSD) of signals generated with different noise amplitudes. Low frequencies remain stable, while high frequencies increase with noise.}
    \label{fig:noise_psd}
\end{figure}

 \noindent Figure~\ref{fig:noise_psd} illustrates the impact of different noise amplitudes on the Power Spectral Density (PSD), highlighting that noise primarily affects the high-frequency components, while low frequencies remain stable. As the noise amplitude increases — from 0.0 (blue curve) to 0.2 (red curve) — there is a noticeable rise in variability at higher frequencies, particularly beyond 10 Hz. The green (0.1) and red (0.2) curves exhibit more pronounced noise-induced fluctuations, reflecting the direct influence of noise on elevated frequencies. This behavior aligns with theoretical expectations, as noise typically introduces rapid and random oscillations that predominantly affect high-frequency bands.
\\ \\
Despite the increased power in the high-frequency range with higher noise levels, the low-frequency components (below 10 Hz) remain relatively stable across all evaluated conditions. This stability underscores the robustness of the method in preserving essential spectral characteristics even under noisy conditions, which is crucial for applications where critical information resides in the low-frequency range. These findings confirm the method's effectiveness in handling realistic perturbations, enabling clear identification of noise effects and facilitating the implementation of targeted filtering strategies. Moreover, the observed sensitivity in high frequencies offers valuable insights for optimizing models intended to operate in environments with varying noise levels, ensuring a balance between accuracy and resilience to interference.

\subsection*{\addtext{Anti-Aliasing Filter Validation}}

\addtext{To address reviewer concerns regarding proper frequency aliasing prevention during subsampling, we implemented and validated anti-aliasing filtering using Butterworth low-pass filters. The filtering approach applies an 8th-order Butterworth filter with cutoff frequency set at 90\% of the target Nyquist frequency before downsampling to each resolution level.}
\\ \\
\addtext{The Butterworth filter design provides maximally flat frequency response in the passband, making it suitable for preserving signal characteristics below the cutoff while effectively attenuating higher frequencies that would cause aliasing. The filter is applied using zero-phase filtering (scipy.signal.filtfilt), which processes the signal in both forward and reverse directions to eliminate phase distortion. This ensures that temporal relationships in the signal are preserved after filtering.}
\\ \\
\addtext{For each target resolution, the cutoff frequency is calculated as: $f_c = 0.9 \times (f_s^{target} / 2)$, where $f_s^{target}$ is the target sampling frequency. For example, when downsampling from 5,000 samples (fs $\approx$ 398 Hz) to 150 samples (fs $\approx$ 11.9 Hz), the filter cutoff is set at approximately 5.4 Hz, effectively removing frequency components above the target Nyquist limit (5.95 Hz) before resampling.}
\\ \\
\addtext{This anti-aliasing approach follows established signal processing best practices and directly addresses the reviewer requirement for proper frequency aliasing prevention. The dataset provides both filtered and unfiltered subsampled versions, allowing researchers to evaluate the impact of anti-aliasing on their specific super-resolution algorithms. Detailed filter parameters and implementation are documented in the filtering\_info.json metadata file included with the dataset.}
\notetext{New subsection addressing reviewer requirement for anti-aliasing filter documentation and validation.}

\subsection*{Multi-Scale Super-Resolution Benchmark}

To systematically validate the utility of CoSiBD across a wide range of upsampling challenges, we trained a series of convolutional neural network (CNN) models for time series super-resolution at four different scaling factors: 5$\times$, 10$\times$, 20$\times$, and 33$\times$. All models employed the TimeSeriesSRNet architecture—a five-layer encoder-decoder network with 1D convolutional layers (kernel size 5, ReLU activations) and bilinear upsampling. Each model was trained on 2,000 paired signals (low-resolution input to 5,000-sample high-resolution target) and validated on 500 independent signals, using mean squared error (MSE) loss, Adam optimizer (learning rate 0.001, weight decay $10^{-5}$), batch size 16, and early stopping with patience of 3 validation checks (every 10 epochs). Training was conducted on Apple Silicon GPU (MPS backend) to accelerate convergence.

Table~\ref{tab:multiscale_benchmark} summarizes the validation performance, convergence characteristics, and computational requirements for each upsampling factor. All models successfully converged within the 50-epoch budget, with the lowest-resolution inputs (150 samples, 33$\times$ upsampling) requiring the most epochs to achieve stable performance. Validation loss increased systematically with upsampling factor, reflecting the inherent difficulty of reconstructing fine temporal details from severely undersampled inputs. Notably, even the most challenging 33$\times$ upsampling task achieved sub-0.01 MSE validation loss, demonstrating that CoSiBD provides sufficient structural diversity and signal complexity to train robust super-resolution models across a broad spectrum of reconstruction scenarios.

\begin{table}[h]
\centering
\small
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\textbf{Input Size} & \textbf{Factor} & \textbf{Val Loss} & \textbf{Epochs} & \textbf{Early Stop} & \textbf{LSD} & \textbf{SCORR} \\
\hline
1000 samples & 5$\times$ & 0.0845 & 50 & No & 0.51$\pm$0.63 & 0.98$\pm$0.10 \\
500 samples & 10$\times$ & 0.1524 & 50 & No & 0.64$\pm$0.63 & 0.98$\pm$0.10 \\
250 samples & 20$\times$ & 0.4376 & 50 & No & 0.95$\pm$0.67 & 0.98$\pm$0.10 \\
150 samples & 33$\times$ & 1.0326 & 50 & No & 1.21$\pm$0.67 & 0.98$\pm$0.11 \\
\hline
\end{tabular}
\caption{Multi-scale super-resolution benchmark results. Validation loss measured as mean squared error on 500 independent test signals. LSD (Log Spectral Distance) quantifies spectral content deviation (lower is better), while SCORR (Spectral Correlation) measures frequency-domain similarity (higher is better, range [0,1]). Early Stop indicates whether training terminated before maximum epochs. All models completed the full 50-epoch training without early termination, demonstrating stable convergence across all upsampling factors.}
\label{tab:multiscale_benchmark}
\end{table}

To complement amplitude-based validation with frequency-domain assessment, we computed spectral fidelity metrics for all reconstructed signals. Log Spectral Distance (LSD), which quantifies the difference between power spectral densities on a logarithmic scale, increased systematically from 0.51 (5$\times$) to 1.21 (33$\times$), confirming that spectral degradation correlates with upsampling difficulty. However, all LSD values remained below 1.5—a threshold typically considered acceptable for high-fidelity reconstruction in audio processing—indicating that models preserve essential frequency characteristics even under extreme compression. Spectral Correlation (SCORR) remained consistently high across all factors (0.98$\pm$0.10), demonstrating that reconstructed signals maintain strong frequency-domain similarity to ground truth despite increasingly sparse inputs. Figure~\ref{fig:spectral_analysis} presents representative spectrogram comparisons across all upsampling factors, visually confirming the preservation of spectral structure and the gradual emergence of reconstruction artifacts at higher factors. These results establish that CoSiBD enables training models capable of maintaining both temporal and spectral fidelity across diverse super-resolution challenges.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{graphs/multifactor_loss_curves.png}
    \caption{Training and validation loss evolution across all four upsampling factors (5$\times$, 10$\times$, 20$\times$, 33$\times$). Each panel shows loss curves during training, demonstrating consistent convergence patterns and the absence of overfitting across all scaling factors. The systematic increase in final validation loss with upsampling factor reflects the inherent difficulty of reconstructing fine temporal details from severely undersampled inputs.}
    \label{fig:multifactor_loss_curves}
\end{figure}

Figure~\ref{fig:multifactor_loss_curves} illustrates the training and validation loss evolution for all four upsampling factors, revealing consistent convergence patterns and the absence of overfitting across scales. Representative prediction examples (Figure~\ref{fig:multifactor_predictions}) demonstrate qualitative reconstruction fidelity, showing that models trained on CoSiBD can accurately recover high-frequency components, temporal transitions, and amplitude dynamics even from extremely sparse inputs.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{graphs/multifactor_predictions.png}
    \caption{Representative prediction examples across all upsampling factors. Each quadrant shows prediction comparisons for a different scaling factor (5$\times$, 10$\times$, 20$\times$, 33$\times$), displaying low-resolution inputs, ground-truth high-resolution signals, and CNN-reconstructed outputs. Visual inspection confirms that models trained on CoSiBD accurately recover high-frequency components, temporal transitions, and amplitude dynamics even from extremely sparse inputs.}
    \label{fig:multifactor_predictions}
\end{figure}

These multi-scale experiments establish quantitative baseline performance metrics for future benchmarking studies and confirm that CoSiBD supports robust model training across diverse super-resolution challenges. The systematic increase in task difficulty—from moderate 5$\times$ upsampling to extreme 33$\times$ reconstruction—positions this dataset as a comprehensive testbed for evaluating novel architectures, loss functions, and training strategies in the time series super-resolution domain.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{graphs/spectral_analysis_grid.png}
    \caption{Spectrogram comparison across all upsampling factors. Each row represents a different upsampling factor (5$\times$, 10$\times$, 20$\times$, 33$\times$), showing original signal (left), CNN-reconstructed signal (center), and spectral difference (right). Visual analysis confirms preservation of spectral structure across all factors, with reconstruction artifacts gradually increasing at higher upsampling rates. Representative signals selected based on median Log Spectral Distance (LSD) for each factor.}
    \label{fig:spectral_analysis}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{graphs/spectral_metric_trends.png}
    \caption{Spectral quality metrics vs upsampling factor. Left: Log Spectral Distance (LSD) increases systematically with upsampling factor, from 0.51 (5$\times$) to 1.21 (33$\times$), while remaining below the 1.5 threshold for high-fidelity reconstruction. Right: Spectral Correlation (SCORR) maintains consistently high values (>0.97) across all factors, demonstrating robust frequency-domain similarity. Error bars represent standard deviation over 500 validation signals per factor.}
    \label{fig:spectral_metrics}
\end{figure}


\subsection*{\addtext{Preliminary Application Results}}

\addtext{To provide initial evidence of the dataset's utility for training deep learning models, we conducted preliminary experiments using convolutional neural networks (CNNs) for time-series super-resolution~\cite{Kuleshov2017,Kaniraja2024}. A TimeSeriesSRNet model with encoder-decoder architecture (Conv1d layers: 1→64→128→256 followed by upsampling and decoder layers 256→128→64→1) was trained using the CoSiBD dataset and validated on real-world data from two distinct domains: EEG clinical signals~\cite{Luciw2014} (500 training, 690 validation samples) and VCTK speech recordings~\cite{Yamagishi2019} (44 hours from 109 speakers).}
\\ \\
\addtext{Four training strategies were evaluated: (1) Real-only: trained exclusively on domain-specific real data; (2) Synth-only: trained exclusively on CoSiBD synthetic signals; (3) Mixed: trained on combined synthetic and real data; (4) Tunned: pre-trained on synthetic data, then fine-tuned on real data. Performance was measured using Mean Absolute Error (MAE) between predicted and ground-truth high-resolution signals.}
\\ \\
\addtext{Results demonstrate that synthetic data augmentation significantly improves model performance on real-world signals~\cite{Forestier2017}. For EEG validation, the Mixed strategy achieved MAE of $9.73 \times 10^{-2}$, representing a 9.64\% improvement over the Real-only baseline ($10.77 \times 10^{-2}$). For out-of-domain VCTK speech data, the Tunned approach achieved MAE of $4.41 \times 10^{-3}$, a substantial 25.51\% improvement over Real-only ($5.92 \times 10^{-3}$). Notably, models trained exclusively on synthetic data (Synth-only) exhibited higher errors, confirming that synthetic signals complement rather than replace real data~\cite{Forestier2017}. These findings provide quantitative evidence that CoSiBD successfully bridges the gap between synthetic training and real-world application, validating its design objectives. Detailed experimental methodology, complete results, and model comparisons are documented in a separate manuscript currently under preparation.}
\notetext{New subsection addressing reviewer requirements for real-world application validation, CNN/deep learning model demonstration, and quantitative performance metrics.}

\begin{table}[h]
\centering
\small
\begin{tabular}{|l|c|c|}
\hline
\textbf{Training Strategy} & \textbf{EEG MAE ($\times 10^{-2}$)} & \textbf{VCTK MAE ($\times 10^{-3}$)} \\
\hline
Real-only (baseline) & 10.77 & 5.92 \\
Synth-only & 12.11 & 8.79 \\
Mixed (synth + real) & \textbf{9.73} & 5.59 \\
Tunned (pretrain + finetune) & 10.68 & \textbf{4.41} \\
\hline
\end{tabular}
\caption{\addtext{Mean Absolute Error (MAE) for CNN-based super-resolution models trained with different strategies. Bold values indicate best performance for each dataset. Mixed strategy shows 9.64\% improvement on EEG data, while Tunned strategy achieves 25.51\% improvement on VCTK speech data, demonstrating the value of synthetic data augmentation.}}
\label{tab:cnn_results}
\end{table}

\begin{figure}[h]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/eeg_model_comparison_1.pdf}
        \subcaption{EEG clinical signal reconstruction comparison.}
        \label{fig:eeg_comparison}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/vctk_model_comparison_5.pdf}
        \subcaption{VCTK speech signal reconstruction comparison.}
        \label{fig:vctk_comparison}
    \end{minipage}
    \caption{\addtext{Visual comparison of super-resolution model predictions for representative test samples from (a) EEG clinical dataset and (b) VCTK speech dataset. Each panel shows the low-resolution input (downsampled), ground-truth high-resolution signal, and predictions from four training strategies (Real, Synth, Mixed, Tunned). The comparisons demonstrate that synthetic data augmentation (Mixed and Tunned) produces reconstructions that more closely match the ground truth across both domains.}}
    \label{fig:model_comparisons}
\end{figure}


\section*{Usage Notes}

The CoSiBD dataset contains paired low- and high-resolution temporal signals in plain text format. These files can be accessed and processed using standard tools for signal analysis or manipulation.

\subsection*{Reading the Data}

The signals are stored as plain text (\texttt{.txt}) files, with one sample per line. Each file contains multiple time series stacked vertically, where each row corresponds to a single signal. The dataset can be accessed using standard Python tools or with the optional helper function \texttt{read\_data()} available in the accompanying GitHub repository:

\begin{verbatim}
import temana as tm

# Load low-resolution and high-resolution validation signals
x_valid = tm.read_data('SamplesAV_FV2024_07_09/SignalAVFV_Sub_Sample250_5000.txt')
y_valid = tm.read_data('SamplesAV_FV2024_07_09/SignalAVFV_Super_Sample1000_5000Val.txt')
\end{verbatim}

These functions return PyTorch tensors representing the signals.

\subsection*{Visualizing Signal Pairs}

To explore the resolution differences, users can visualize aligned pairs of signals:

\begin{verbatim}
import matplotlib.pyplot as plt

# Visualize the first pair of signals
plt.figure(figsize=(10, 4))
plt.plot(x_valid[0], label='Low-resolution (1000 points)', color='red')
plt.plot(y_valid[0], label='High-resolution (5000 points)', color='blue', alpha=0.7)
plt.xlabel('Time step')
plt.ylabel('Amplitude')
plt.title('Sample Signal Pair')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
\end{verbatim}


\section*{Code availability}

\noindent
\deltext{Custom Python scripts used to load, process, and visualize the CoSiBD dataset are available at:}
\addtext{The complete signal generation pipeline, including modules for frequency profile generation, amplitude envelope construction, spline interpolation, noise application, anti-aliasing filtering, and data export in multiple formats, is available at:}  
\href{https://github.com/DhamarAM/SignalBuilder/tree/main}{CoSiBD scripts on GitHub}.  
\addtext{The repository includes SignalBuilderC, a modular Python package with documented functions for: (1) generating high-resolution signals with configurable parameters, (2) creating subsampled versions via re-evaluation or anti-aliasing filtering, (3) exporting signals in NumPy, text, and JSON formats, and (4) comprehensive metadata generation. All code is provided with example notebooks demonstrating dataset regeneration and usage.}
These scripts are distributed under the MIT License.
\\ \\
\noindent
The custom scripts are open access and provided under the Creative Commons Attribution 4.0 International (CC BY 4.0) license.  
The dataset itself is published separately at:  
\href{https://zenodo.org/records/15138853}{CoSiBD dataset on Zenodo}.
\notetext{Addresses reviewer requirement for comprehensive code documentation and improved repository description.}

% ===== BIBLIOGRAPHY =====
% Using BibTeX with naturemag-doi style for Nature Scientific Data
% References stored in referencias.bib
% Note: \bibliographystyle{naturemag-doi} is defined in wlscirep.cls
\bibliography{referencias}



\section*{Acknowledgments}
This research was supported by Dean's Office of the Polytechnic College of the San Francisco de Quito University  and partially by ProyExcel-0069 project of the Andalusian University, Research and Innovation Department.

\section*{Author Contributions}
J. I. F. handled the methodological design for artificial data creation, probabilistic analysis, spline-based variations, noise distributions, and random node selection. J. A. L. was responsible for the time series methodological design. D. A. M. performed data processing and validation analysis. All of the authors have contributed to writing the manuscript.

\section*{Competing Interests}
The authors declare no competing interests

\end{document}