\documentclass[fleqn,10pt]{wlscirep}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lineno}
 \usepackage{multirow}
\usepackage{array}  % Añade esto en el preámbulo
\renewcommand{\arraystretch}{1.3}  % Espaciado vertical entre filas

\usepackage{subcaption}
\linenumbers
\usepackage{float}

% ===== TRACK CHANGES PACKAGE =====
% Use [draft] to show changes with highlighting
% Use [final] to hide all markup for submission
\usepackage[draft]{changes}
\usepackage{xcolor}

% Define authors for tracked changes
\definechangesauthor[name={Revision}, color=yellow]{REV}

% Custom commands for easier tracking
\newcommand{\addtext}[1]{\added[id=REV]{#1}}
\newcommand{\deltext}[1]{\deleted[id=REV]{#1}}
\newcommand{\replacetext}[2]{\replaced[id=REV]{#2}{#1}}
\newcommand{\notetext}[1]{\comment[id=REV]{#1}}
\newcommand{\highlighttext}[1]{\highlight[id=REV]{#1}}
% ===== END TRACK CHANGES =====  

%\title{CoSiBD: A Versatile Dataset for Benchmarking Signal Processing and Machine Learning Algorithms}
%\title{CoSiBD: A Synthetic Dataset for Super-Resolution Deep Learning Temporal Series Analysis}
%\title{A synthetic dataset for super-resolution of Time Series using Deep Learning}
\title{A synthetic dataset for Time Series Super-Resolution with Deep Learning}
\author[1]{Julio Ibarra-Fiallo}
\author[2]{Juan A. Lara}
\author[1]{D'hamar Agudelo-Moreno}
%\author[2,*]{autor }
\affil[1]{Colegio de Ciencias e Ingenierías, Universidad San Francisco de Quito, Cumbayá, Ecuador}
\affil[2]{Universidad de Córdoba, Córdoba, España}

\affil[*]{corresponding author: Julio Ibarra-Fiallo (jibarra@usfq.edu.ec)}


\begin{abstract}
\deltext{The increasing application of temporal signal analysis in fields like biomedical engineering, telecommunications, and industrial monitoring emphasizes the need for high-quality data to train and evaluate advanced machine learning models.}\addtext{The increasing application of time-series analysis in fields like biomedical engineering, telecommunications, and industrial monitoring emphasizes the need for high-quality data to train and evaluate advanced machine learning models.} Acquiring real-world temporal data at suitable resolutions is often limited by ethical, economic, or practical constraints. To address this, we introduce CoSiBD (Complex Signal Benchmark Dataset for Super-Resolution), a synthetic dataset of complex temporal signals designed for training and assessing AI models, particularly deep learning systems, in tasks like temporal super-resolution and signal processing. \addtext{CoSiBD comprises 2,500 high-resolution signals ($N=5{,}000$ samples each over a reference domain $\tau\in[0,4\pi]$) with corresponding low-resolution versions at four levels (150, 250, 500, and 1,000 samples) obtained via simple uniform decimation (uniform subsampling) of the original sequence.} \replacetext{Each signal is provided in three formats (NumPy arrays, plain text, and JSON) with comprehensive metadata documenting all generation parameters for reproducibility.}{Each signal is provided in three formats (NumPy arrays, plain text, and JSON) with comprehensive metadata documenting all generation parameters, including random seeds for full reproducibility.} CoSiBD includes diverse signals with non-uniform frequency modulations, capturing gradual transitions and abrupt high-frequency events \replacetext{to approximate a range of dynamics observed in practice.}{to mirror real-world dynamics.} \replacetext{The dataset provides both clean and noisy high-resolution signals; additionally, multiple subsampled versions are provided to support SR benchmarking.}{The dataset provides both clean and noisy variants.} \replacetext{Subsampling is performed using two approaches: direct re-evaluation at lower time resolutions and uniform decimation.}{Low-resolution signals are provided at four target resolutions (150, 250, 500, and 1,000 samples).} The dataset is generated by combining distinct frequency bands, non-uniform intervals, and probabilistic frequency assignments to create realistic patterns, with smoothing achieved through spline interpolation.
\replacetext{Validated for spectral consistency across sampling rates and noise, CoSiBD supports training and evaluation.}{We report a technical validation focusing on spectral consistency across sampling rates and noise; CoSiBD supports training and evaluation.}
\end{abstract}


\begin{document}

\flushbottom
\maketitle

\section*{Background \& Summary}
\label{sec:background-summary}

\deltext{The analysis and simulation of temporal signals are fundamental across science and engineering, supporting insights into dynamic processes.}\addtext{The analysis and simulation of temporal signals are fundamental across science and engineering. These techniques provide critical insights into dynamic processes in multiple domains.} In biomedical research \cite{Karacan2024}, electroencephalography (EEG) and electrocardiography (ECG) analyses reveal brain and heart function \cite{Nayak2023,shaffer2017}. Telecommunications rely on signal processing to ensure data fidelity across noisy media \cite{Chen2022}, while finance uses time-series forecasting for risk and trend analysis \cite{Zhang2016}. Industrial monitoring detects equipment faults using temporal patterns \cite{Bhatia2021}, and environmental science applies similar techniques to \replacetext{climate tracking via remote sensing}{climate and environmental monitoring using remote-sensor time series} \cite{Mallat1989}. Developing robust tools for interpreting time-varying data continues to support both scientific discovery and practical applications.
\\ \\
Recent advances in deep learning have contributed significantly to this field by enabling automatic extraction of complex features from raw signals. Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), including Long Short-Term Memory (LSTM) units, and Generative Adversarial Networks (GANs) have demonstrated improved performance over traditional techniques in image, speech, and time-series processing tasks \cite{Lecun2015,Goodfellow2014}. These models support fine-grained signal reconstruction and forecasting, allowing researchers to explore temporal dynamics in new ways.
\\ \\
Despite this progress, deep learning methods for temporal signal processing often require large quantities of labeled, high-quality data. Access to such data is frequently constrained by medical privacy regulations such as the General Data Protection Regulation (GDPR) and the Health Insurance Portability and Accountability Act (HIPAA) \cite{Isasa2024}. In other domains, including \replacetext{remote sensing and industrial monitoring}{environmental monitoring using remote sensors and industrial monitoring}, data availability is limited by practical and economic barriers to sensor deployment and data collection \cite{Zhang2016}. These limitations are particularly relevant in super-resolution (SR) tasks, where models require paired low- and high-resolution signals for effective training.
\\ \\
Temporal SR, which enhances resolution over time, has broad potential. \replacetext{In medicine, for instance, it improves magnetic resonance imaging (MRI) and computed tomography (CT) scans, supporting earlier disease detection \cite{Morales2022}. For EEG analysis, SR may help recover high-frequency components that aid in the study of neural oscillations \cite{Nayak2023} or detect subtle physiological irregularities \cite{shaffer2017}. In remote sensing, SR helps refine satellite imagery \cite{Mallat1989}, while in telecommunications it contributes to enhanced signal reliability. It also has applications in industrial monitoring by increasing sensitivity to system changes.}{In biomedical monitoring and sensing, SR can help reconstruct higher-resolution physiological time series (e.g., ECG/EEG), potentially improving the analysis of neural oscillations \cite{Nayak2023} and subtle physiological irregularities \cite{shaffer2017}. SR also applies to audio/speech enhancement, industrial vibration monitoring, and telecommunications, where higher temporal resolution can increase sensitivity to rapid changes and improve signal quality.}
\\ \\
Traditional SR methods such as polynomial interpolation, frequency-domain transforms, and splines each have limitations. Polynomial models are often insufficient for capturing nonlinear dynamics; frequency-domain methods are susceptible to noise \cite{Mallat1989}; and splines, though flexible, may not generalize well to complex signal variability \cite{Schumaker2007,DeBoor2001}. Many of these methods also assume uniform partitioning, which may not align with the multi-scale, irregular structure of natural temporal phenomena.
\\ \\
Deep learning offers adaptive alternatives to these traditional methods. CNNs are capable of modeling spatio-temporal structure, RNNs and LSTMs capture long-range dependencies in time, and GANs can learn high-resolution representations through adversarial training \cite{Lecun2015,Goodfellow2014}. While GANs have achieved strong results in image SR \cite{Brophy2023}, their application to time-series SR remains relatively new. Preliminary work on synthetic time-series generation indicates potential \cite{Brophy2023,IbarraFiallo2024}, but the lack of accessible, high-quality paired datasets remains a significant barrier to progress.
\\ \\
Synthetic datasets offer one solution to this problem, allowing researchers to design reproducible training environments that reflect the structure and variability of real-world signals. Prior studies have used synthetic data in domains such as fluid dynamics \cite{Yasuda2023}, bioimaging \cite{Priessner2024}, and live-cell imaging \cite{Qiao2025}, demonstrating that synthetic approaches can help simulate complexity while avoiding legal and practical restrictions associated with real-world data.
\\ \\
To support research in super-resolution for time-series data, we present the Complex Signal Benchmark Dataset (CoSiBD). CoSiBD is a synthetic dataset composed of time-series signals with variable resolution, frequency characteristics, and noise levels. The dataset is intended to provide a resource for training and evaluating SR models under controlled, reproducible conditions. It includes non-stationary, piecewise-structured signals (via non-uniform interval partitioning with change-points), multiple levels of resolution and noise, a technical validation suite, and publicly available Python code to facilitate use. CoSiBD has been used in research presented at the International Conference on Signal Processing and Machine Learning~\cite{IbarraFiallo2024} and is made available to support further development in deep learning approaches for temporal super-resolution.

\notetext{Added a short related-work subsection and comparison table to position CoSiBD against representative publicly available synthetic time-series datasets and simulators and explicitly state the practical gap addressed (reviewer request: contextualization vs. existing resources).}

\addtext{To further position CoSiBD with respect to existing public synthetic time-series resources, we summarize representative datasets and simulators and highlight the practical gap addressed by our benchmark.}

\subsection*{Related synthetic time-series resources}

\addtext{Publicly available synthetic resources for temporal signals exist, but they are typically designed for tasks other than time-series super-resolution (SR), or they target a specific domain. In wireless communications, the RadioML family provides large collections of synthetic complex I/Q sequences with varying SNR and channel impairments, mainly to benchmark automatic modulation classification rather than paired SR reconstruction \cite{oshea2016grcon,deepsig_datasets,deepsig_radioml2018}. In biomedical signal processing, physiological simulators such as ECGSYN (ECG) and SEREEGA (EEG) enable controlled generation with tunable morphology, sampling settings, and noise, supporting method development when real data access is constrained \cite{mcsharry2003ecg,ecgsyn_physionet,krol2018sereega}. In power systems, LoadGAN provides multi-resolution generation of load time series across sampling rates and time horizons (from sub-second to long-term scales), but it is not distributed as a standardized paired SR benchmark \cite{pinceti2021loadgan}. Domain-specific paired low-/high-resolution training data can also be produced via physical forward modeling, e.g., low- and high-resolution 1D seismic traces for learning-based resolution enhancement \cite{yuan2024seismic}.}

\replacetext{Table~\ref{tab:related_synthetic_datasets} summarizes these representative resources and highlights a practical gap: while many tools provide synthetic signals, they usually do not jointly offer (i) multi-factor paired LR--HR signals for time-series SR, (ii) a clear pairing protocol for constructing low-resolution observations for SR, and (iii) per-signal metadata (including random seeds) enabling exact sample-level reproducibility. CoSiBD is designed to address this gap by providing multi-resolution paired signals, explicit nuisance modeling (noise and structured interference), and comprehensive metadata for reproducible SR benchmarking across multiple difficulty levels.}{Table~\ref{tab:related_synthetic_datasets} summarizes these representative resources and highlights a practical gap: while many tools provide synthetic signals, they usually do not jointly offer (i) multi-factor paired LR--HR signals for time-series SR, (ii) a clear pairing protocol for low-resolution observations aligned to reconstructing the original HR target (here implemented via simple uniform decimation), and (iii) per-signal metadata enabling deterministic regeneration and principled benchmarking. CoSiBD is designed to address this gap by providing multi-resolution paired signals, explicit nuisance modeling (noise and structured interference), and comprehensive metadata for reproducible SR benchmarking across multiple difficulty levels.}

\begin{table*}[t]
\centering
\begingroup
\small
\setlength{\tabcolsep}{3pt}
\renewcommand{\arraystretch}{1.15}
\begin{tabular}{|p{2.7cm}|p{2.3cm}|p{1.6cm}|p{1.9cm}|p{1.7cm}|p{2.2cm}|p{2.4cm}|}
\hline
                                     \csname textbf\endcsname{Resource} & \textbf{Domain} & \textbf{Form} & \textbf{Paired LR--HR SR} & \textbf{Multi-resolution} & \textbf{Noise / artifacts} & \textbf{Reproducibility granularity} \\
\hline
                                     \csname textbf\endcsname{CoSiBD (this work)} &
Generic time series (complex-structured signals) &
Dataset + generator &
Yes (LR $\rightarrow$ HR targets) &
Yes ($150/\allowbreak250/\allowbreak500/\allowbreak1000 \rightarrow 5000$) &
Gaussian + structured interference; primary benchmark uses direct decimation &
Per-signal metadata; deterministic regeneration (seed-controlled) \\
\hline
RadioML 2016.10A \cite{oshea2016grcon,deepsig_datasets} &
Wireless communications (I/Q) &
Dataset &
No (classification benchmark) &
N/A (not SR) &
Variable SNR + channel impairments &
Dataset-level (labels/\allowbreak SNR); not per-sample ``recipe'' \\
\hline
RadioML 2018.01A \cite{deepsig_radioml2018} &
Wireless communications (I/Q) &
Dataset &
No (classification benchmark) &
N/A (not SR) &
Simulated channel effects + SNR variability &
Dataset-level; not SR-paired \\
\hline
ECGSYN \cite{mcsharry2003ecg,ecgsyn_physionet} &
ECG (physiology) &
Simulator/tool &
Configurable\footnotemark[1] &
Configurable (via sampling settings) &
Model-based; supports controlled variability &
Configurable via simulator parameters (user-defined) \\
\hline
SEREEGA \cite{krol2018sereega} &
EEG (physiology) &
Simulator/\allowbreak toolbox &
Configurable\footnotemark[1] &
Configurable (user-defined) &
Supports noise and event-related components &
Configurable via simulator parameters (user-defined) \\
\hline
LoadGAN \cite{pinceti2021loadgan} &
Power systems load time series &
Generator/tool &
No (generation) &
Yes (variable sampling rates) &
Domain-specific variability (load patterns) &
Tool-based; generation is configurable \\
\hline
Synthetic LR--HR seismic traces (example) \cite{yuan2024seismic} &
Seismic traces (geophysics) &
Paper-specific paired data &
Yes (LR--HR pairs) &
Typically limited (study-specific) &
Study-dependent &
Paired data available for the study; limited generality \\
\hline
\end{tabular}
\endgroup
\caption{Representative publicly available synthetic time-series datasets and simulators related to signal processing and learning. ``Form'' indicates whether the resource is distributed primarily as a fixed dataset or as a simulator/generator. ``Reproducibility granularity'' summarizes whether exact per-sample regeneration is supported via documented parameters and seeds.}
\label{tab:related_synthetic_datasets}
\end{table*}

\footnotetext[1]{``Configurable'' indicates that LR--HR pairs can be constructed by running the simulator at different sampling settings and/or applying controlled downsampling, but a standardized paired SR benchmark (multi-factor LR versions aligned to a fixed HR target) is not typically distributed as part of the resource.}

\section*{Methods}
\label{sec:methods}

The methodology used to generate the synthetic temporal signals that constitute the CoSiBD dataset is illustrated in Figure~\ref{fig:generation_process}. The process was designed to produce signals that reflect general characteristics of real-world temporal data, such as variable frequency content, continuous transitions, and intermittent high-frequency activity. A key aspect of the procedure is the ability to produce signals at different resolution levels, supporting the generation of paired datasets for evaluating super-resolution (SR) algorithms.

\begin{figure}
    \centering
    \deleted{\includegraphics[width=0.35\textwidth]{diagrams/generation_process3.png}}
    \added{\includegraphics[width=0.35\textwidth]{diagrams/generation_process4.png}}
    \caption{Schematic overview of the CoSiBD signal generation process.}
    \label{fig:generation_process}
\end{figure}

\addtext{\noindent\textbf{Design rationale inspired by real signals.} To address the concern that the dataset is ``too artificial'', we derived the simulator degrees of freedom from qualitative observations across representative physiological (EEG/ECG) and speech signals. In particular, real signals exhibit (i) non-stationary regime changes, (ii) coexisting low- and high-frequency components with intermittent transients, (iii) smooth amplitude-envelope evolution, and (iv) slow baseline drift and measurement noise. CoSiBD instantiates these properties via non-uniform interval partitioning with change-points, separate low/high-frequency bands, spline-based envelopes and frequency profiles, and explicit offset/noise terms. Figure~\ref{fig:design_rationale_motivations} provides qualitative examples of these motivating properties; the goal is to capture challenging structure for SR benchmarking rather than match a specific domain distribution.}

\begin{figure}
    \centering
    \includegraphics[width=0.95\textwidth]{graphs/r1_3_design_rationale/r1_3_real_signal_motivations.png}
    \caption{Qualitative real-signal properties motivating the CoSiBD design. The physiological example illustrates non-stationarity in the waveform and structured spectral content; the speech example illustrates amplitude-envelope dynamics and a smoothly varying pitch (F0) trend. These observations motivate CoSiBD mechanisms such as regime partitioning with change-points, low/high-frequency bands, and spline-based envelopes/frequency profiles.}
    \label{fig:design_rationale_motivations}
\end{figure}

\noindent The signal generation pipeline involves the following steps:

\begin{enumerate}
    \item \textbf{Base frequency band definition:} A set of distinct frequency bands is defined to represent the underlying spectral content of the signals. These can be adjusted to reflect application-specific characteristics.

    \item \textbf{Non-uniform interval partitioning:} The total signal duration is divided into multiple intervals of variable length. The interval lengths are determined probabilistically to introduce variability in the signal structure.

    \item \textbf{Frequency assignment:} Each interval is assigned a dominant frequency band, sampled according to a predefined probability distribution. This introduces spectral variation over time.

    \item \textbf{Signal synthesis:} A sinusoidal waveform, or a combination of sinusoids within the assigned frequency band, is generated for each interval. Signal parameters such as amplitude and phase are configurable.

    \item \textbf{Transition smoothing:} To avoid discontinuities at interval boundaries, a smoothing function is applied to overlapping segments. This ensures gradual transitions between intervals with different frequency content.

    \item \textbf{Resolution variation:} All signals are initially synthesized at a high temporal resolution \addtext{(5,000 samples over the domain [0, 4$\pi$])}. Lower-resolution versions are created \replacetext{using two distinct approaches: (1) direct re-evaluation by computing the signal at fewer time points using the original generation parameters, and (2) direct decimation (uniform subsampling).}{using simple decimation (uniform subsampling). This keeps the SR task aligned with reconstructing the original high-resolution target; the low-resolution observation is obtained by subsampling the original sequence without pre-filtering. \addtext{Reconstructing low-pass filtered signals is not an objective of CoSiBD.}}\addtext{ For reproducibility, given a high-resolution sequence $x_{\mathrm{HR}}[n]$ of length $N=5000$ and a target low-resolution length $M\in\{1000,500,250,150\}$, we form $x_{\mathrm{LR}}[i]=x_{\mathrm{HR}}[n_i]$ using the fixed index set $n_i=\left\lfloor \frac{i\,(N-1)}{M-1}+0.5\right\rfloor$ for $i=0,\ldots,M-1$ (applied identically to the time array). This reduces to standard stride decimation when $M$ divides $N$.}

    \item \textbf{Noise injection:} Controlled levels of synthetic noise are added to the signals to emulate different data acquisition scenarios. \replacetext{Two noise types are implemented: Gaussian noise with configurable standard deviation (relative to signal RMS) and structured sinusoidal interference (deterministic narrow-band components). Noise is applied probabilistically with 80\% probability per signal; when noise is present, Gaussian noise is selected with 70\% probability.}{Two noise types are implemented: Gaussian noise with configurable standard deviation (relative to signal amplitude) and structured sinusoidal noise bursts (deterministic sinusoidal components). Noise is applied probabilistically with 50\% probability per signal.} Both the type and intensity of the noise can be configured.
\end{enumerate}

\addtext{\noindent\textbf{Rationale for structured 50/60\,Hz interference and noise.} Real measurement pipelines frequently contain narrow-band interference (e.g., mains hum) superimposed on broadband sensor noise. To reflect this common acquisition artifact, CoSiBD includes an optional structured sinusoidal component in addition to Gaussian noise. CoSiBD signals are generated over a reference domain (by default $\tau\in[0,4\pi]$); interpreting $\tau$ as physical time (and therefore reporting frequencies in Hz) requires an explicit time scaling. Throughout this manuscript we adopt an illustrative convention that maps the reference domain to a duration $T=4\pi$ seconds, under which the structured component can be interpreted as a 50/60\,Hz-like powerline interference term, while the broadband term represents the measurement noise floor. Figure~\ref{fig:r1_4_powerline_noise} illustrates this qualitative motivation; the intent is not to reproduce a specific device transfer function but to include realistic nuisance factors that SR models must handle.} % R1-4

\begin{figure}
    \centering
    \includegraphics[width=0.85\textwidth]{figures/powerline_interference_justification.png}
    \caption{Qualitative motivation for the structured interference term used in CoSiBD. An illustrative example shows how adding a narrow-band sinusoidal component (interpretable as 50/60\,Hz under the illustrative convention $T=4\pi$\,s) produces the characteristic periodic contamination observed in real recordings, while broadband noise captures the measurement floor.} % R1-4
    \label{fig:r1_4_powerline_noise}
\end{figure}

\addtext{\noindent\textbf{Sampling units and frequency interpretation.} CoSiBD signals are provided as discrete sequences $x[n]$ (e.g., $N=5{,}000$ samples) that are directly used as inputs/targets by SR models. The internal generation domain $\tau\in[0,4\pi]$ is a reference parameterization; interpreting it as physical time requires choosing a duration $T$ (in seconds) for the reference interval. Under this convention, the implied sampling rate is $f_s = N/T$ and all frequencies reported in Hz scale linearly with $4\pi/T$. Throughout this manuscript, when reporting example frequencies in Hz we adopt the illustrative convention $T=4\pi$\,s, yielding $f_s \approx 5000/(4\pi) \approx 398\,$Hz; other equally valid mappings exist depending on application. Figure~\ref{fig:r1_5_sampling_units} illustrates that the discrete samples are unchanged under different time scalings and that Hz axes shift with the assumed $f_s$, while the normalized spectrum (cycles/sample) is invariant.} % R1-5

\begin{figure}
    \centering
    \includegraphics[width=0.95\textwidth]{graphs/r1_5_sampling_units/r1_5_time_scaling.png}
    \vspace{0.25cm}
    \includegraphics[width=0.95\textwidth]{graphs/r1_5_sampling_units/r1_5_spectrum_mapping.png}
    \caption{Sampling/unit convention in CoSiBD. Top: the same discrete sequence $x[n]$ can be plotted against the sample index or under different assumed time scalings. Bottom: the intrinsic frequency axis is normalized (cycles/sample); mapping to ``Hz'' depends on the assumed sampling rate $f_s$ (two example mappings shown).} % R1-5
    \label{fig:r1_5_sampling_units}
\end{figure}

\noindent The parameters that govern each step of the generation process—such as interval length distributions, frequency band selection probabilities, smoothing function characteristics, sampling rates, and noise settings—can be configured to produce signal sets tailored to different domains or experimental conditions. \replacetext{All generation parameters are documented in comprehensive metadata (\texttt{signals\_metadata.json}), enabling deterministic reproduction of the official dataset release. In particular, the full dataset can be regenerated by rerunning the generator with a fixed global seed (\texttt{seed=42}). The generation pipeline is implemented in modular Python code available in the SignalBuilderC package, with clear interfaces for customization and extension.}{All generation parameters, including random seeds, are documented in comprehensive metadata (\texttt{signals\_metadata.json}), enabling exact reproduction of individual signals or the complete dataset. The generation pipeline is implemented in modular Python code available in the SignalBuilderC package, with clear interfaces for customization and extension.} These configurations are included in the dataset's accompanying code to support reproducibility and allow users to regenerate the signals under consistent conditions.

\section*{Data Records}
\label{sec:data-records}

The Complex Signal Benchmark Dataset (CoSiBD) is publicly available on Zenodo\cite{cosibd_zenodo_2025} and consists of synthetic temporal signals created to support the development and evaluation of temporal super-resolution (SR) algorithms. This section provides an overview of the dataset structure, content, and storage format.
\\ \\
\deltext{The dataset includes a total of 7,800 signal samples divided into two main categories:}
\addtext{The dataset comprises 2,500 high-resolution signals, each with corresponding subsampled versions at four resolution levels, organized into three main categories:}

\begin{itemize}
    \item \replacetext{\textbf{High-resolution signals}: 2,500 signals with 5,000 samples each, spanning the domain [0, 4$\pi$]. Each signal is stored in three formats: NumPy compressed format (.npz), plain text (.txt), and JSON (.json). Per-signal metadata (frequency profiles with explicit change-points (\texttt{base\_points} and \texttt{high\_freq\_points}) and segment labels (\texttt{variation\_type}), amplitude envelopes, spline parameters, vertical offsets, and noise configurations) is provided in a consolidated JSON file (\texttt{signals\_metadata.json}) with one entry per signal. The official dataset release can be deterministically regenerated using the fixed seed (\texttt{seed=42}).}{\textbf{High-resolution signals}: 2,500 signals with 5,000 samples each, spanning the domain [0, 4$\pi$]. Each signal is stored in three formats: NumPy compressed format (.npz), plain text (.txt), and JSON (.json). Per-signal metadata (frequency profiles with explicit change-points (\texttt{base\_points} and \texttt{high\_freq\_points}) and segment labels (\texttt{variation\_type}), amplitude envelopes, spline parameters, vertical offsets, noise configurations, and random seeds) is provided in a consolidated JSON file (\texttt{signals\_metadata.json}) with one entry per signal, enabling exact regeneration.}
    \item \deltext{\textbf{Low-resolution signals}, obtained through controlled downsampling of the high-resolution versions, available at three distinct resolution levels.}\replacetext{\textbf{Simple subsampled signals}: Re-evaluation of each signal at four target resolutions (150, 250, 500, and 1,000 samples) using the original generation parameters. \addtext{Noise is not re-applied in these re-evaluated versions (clean re-evaluation).} Stored in .npz, .txt, and .json formats.}{\textbf{Simple subsampled signals}: Uniform decimation (uniform subsampling) of each signal to four target resolutions (150, 250, 500, and 1,000 samples). These low-resolution versions serve as inputs for SR benchmarking against the original 5,000-sample target. Stored in .npz, .txt, and .json formats.}
\end{itemize}

\noindent \deltext{Noise is applied to both high- and low-resolution signals at different signal-to-noise ratio (SNR) levels (20 dB, 10 dB, and 5 dB), integrated directly into the signal files.}
\replacetext{Reproducibility is ensured through a fixed global random seed for the official release (\texttt{seed=42}) and comprehensive metadata documenting the generation parameters of each signal. Key parameter ranges include: (1) frequency profile tension values \texttt{tau\_frequency} from 21 discrete values in $[1,2]$ (step 0.05); (2) amplitude-envelope configuration with 50\% probability of a tension spline with \texttt{tau\_amplitude} uniformly sampled in $[0.5,2.5]$ and 50\% probability of a zero-order step envelope, with controlled amplitude magnitudes (1--8); (3) vertical offsets normally distributed $\mathcal{N}(0,3.0)$; and (4) noise applied with 80\% probability per signal, using Gaussian noise (70\% given noise) or structured sinusoidal interference otherwise.}{Reproducibility is ensured through documented random seeds: each high-resolution signal is generated using a unique seed (ranging from 10,000 to 12,499), enabling exact regeneration of individual signals or the entire dataset. All generation parameters are stored in metadata JSON files, including: (1) frequency profile parameters---tau\_frequency values from uniform distribution [1, 2] with 0.05 step; (2) amplitude envelope parameters---tau\_amplitude from \{1, 3, 5, 8, 10, 12, 15, 20\} for tension splines, or zero-order step functions (70\% probability); (3) vertical offsets---normally distributed (mean=0, SD=3.0); and (4) noise configurations---50\% probability of Gaussian or structured noise.}
 
\deltext{A summary table describes the dataset subsets, indicating sample counts and resolution. Naming conventions follow a consistent pattern: `Sub\_Super\_Sample` prefixes denote high-resolution subsets, while `Sub\_Sample` denotes low-resolution ones. Resolution pairings are indicated in the names (e.g., `500\_5000`), and validation subsets are labeled with the suffix `Val`.}
\replacetext{The dataset is provided as consolidated files under \texttt{SignalBuilderC/data/}. High-resolution signals are stored as \texttt{signals\_\allowbreak high\_\allowbreak resolution\_\allowbreak 5000.[npz|txt|json]}. Subsampled signals are stored as \texttt{signals\_\allowbreak subsampled\_\allowbreak simple\_\allowbreak \{150,250,500,1000\}.[npz|txt|json]}. Dataset-level metadata and configuration are stored in \texttt{signals\_\allowbreak metadata.json}, \texttt{signals\_\allowbreak metadata\_\allowbreak consolidated\_\allowbreak 2500.json}, and \texttt{dataset\_\allowbreak summary.json}.}{The dataset is provided as consolidated files under \texttt{SignalBuilderC/data/}. High-resolution signals are stored as \texttt{signals\_\allowbreak high\_\allowbreak resolution\_\allowbreak 5000.[npz|txt|json]}. Simple subsampled (decimated) signals are stored as \texttt{signals\_\allowbreak subsampled\_\allowbreak simple\_\allowbreak \{150,250,500,1000\}.[npz|txt|json]}. Dataset-level metadata and configuration are stored in \texttt{signals\_\allowbreak metadata.json}, \texttt{signals\_\allowbreak metadata\_\allowbreak consolidated\_\allowbreak 2500.json}, and \texttt{dataset\_\allowbreak summary.json}.}

\noindent \deltext{Signals are stored in plain text `.txt` files containing NumPy-formatted arrays. Each file represents a single temporal signal as a one-dimensional sequence of numerical values. The dataset folder structure mirrors the subset naming scheme.}
\addtext{Each signal is stored in three formats: (1) NumPy compressed format (.npz) containing the signal array, time array, and (for high-resolution only) clean signal without noise; (2) consolidated plain text format (.txt) with one signal per row (samples separated by whitespace) for maximum portability; and (3) JSON format (.json) with both time and signal arrays for web-based applications and interoperability. Per-signal metadata is provided in \texttt{signals\_metadata.json} (one entry per signal), and dataset-level configuration is provided in \texttt{dataset\_summary.json}.}

\noindent The following resolution levels are available:

\begin{itemize}
    \item \textbf{High-resolution:} 5000 \deltext{points}\addtext{samples} per signal\addtext{, sampled over the reference domain $\tau\in[0,4\pi]$. Under the illustrative convention $T=4\pi$\,s, this corresponds to $f_s = 5000/(4\pi) \approx 398$\,Hz}.
    \item \deltext{\textbf{Low-resolution:} Created via downsampling from the high-resolution version:}\replacetext{\textbf{Subsampled resolutions:} Available in multiple subsampled versions:}{\textbf{Subsampled resolutions:} Available as simple decimated versions:}
    \begin{itemize}
        \item \deltext{1000 points}\addtext{1000 samples (illustrative $f_s \approx 79.6$\,Hz for $T=4\pi$\,s)}
        \item \deltext{500 points}\addtext{500 samples (illustrative $f_s \approx 39.8$\,Hz for $T=4\pi$\,s)}
        \item \deltext{250 points}\addtext{250 samples (illustrative $f_s \approx 19.9$\,Hz for $T=4\pi$\,s)}
        \item \addtext{150 samples (illustrative $f_s \approx 11.9$\,Hz for $T=4\pi$\,s)}
    \end{itemize}
\end{itemize}

\noindent Table~\ref{tab:Parameter} outlines the main parameters used in signal generation. \replacetext{The official dataset release is deterministically reproducible using a fixed seed (\texttt{seed=42}), with per-signal parameters recorded in the metadata.}{Each high-resolution signal was generated with a unique random seed (10,000--12,499) and randomly sampled parameter values within the defined ranges, supporting diversity while maintaining reproducibility.}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|m{6cm}|}
\hline
\textbf{Parameter} & \textbf{Range} & \textbf{Description} \\ \hline
Low Frequency & \replacetext{1--5 Hz}{1--5 (illustrative Hz for $T=4\pi$\,s)} & Low-frequency component present in signals \\ \hline
High Frequency & \replacetext{20--100 Hz}{20--100 (illustrative Hz for $T=4\pi$\,s)} & Higher-frequency variations for transitions \\ \hline
Change Points & 2--11 & Number of frequency transitions per signal \\ \hline
Change Locations & Random & Time locations where transitions occur \\ \hline
Variation Type & Categorical & Defines nature of frequency change ("low", "high", "no\_change") \\ \hline
Amplitude Range & \replacetext{1--8}{3--16} & \replacetext{Range for amplitude-envelope magnitude values (controlled to avoid extreme peaks)}{Range for amplitude envelope values} \\ \hline
\addtext{Vertical Offset} & \addtext{N(0, 3.0)} & \addtext{Normally distributed offset added to signals} \\ \hline
Spline Type & Mixed & \replacetext{50\% zero-order (step), 50\% tension spline}{70\% zero-order (step), 30\% tension spline} \\ \hline
\addtext{Tension Parameter (freq)} & \addtext{[1, 2]} & \addtext{Tau values for frequency spline interpolation} \\ \hline
Tension Parameter (amp) & \replacetext{[0.5, 2.5]}{\{1,3,5,8,10,12,15,20\}} & \replacetext{Tau values for amplitude tension spline (uniform; used when spline type is tension)}{Tau values for amplitude spline (when tension type)} \\ \hline
Noise Probability & \replacetext{80\%}{50\%} & Probability of adding noise to each signal \\ \hline
Random Seed & \replacetext{42}{10000--12499} & \replacetext{Global seed used to deterministically reproduce the official dataset release}{Unique seed per signal for reproducibility} \\ \hline
\end{tabular}
\caption{Signal generation parameters used to create diverse temporal patterns within the CoSiBD dataset. \replacetext{All parameters are documented in metadata files, enabling deterministic regeneration of the official dataset release.}{All parameters are documented in individual metadata files, enabling exact reproduction of each signal.} These parameters control the frequency composition and temporal structure.}
\label{tab:Parameter}
\end{table}

\addtext{To explicitly characterize dataset diversity and complexity, CoSiBD spans multiple controlled axes of variation (Table~\ref{tab:Parameter}), including the number and location of change points, categorical transition types, low/high frequency bands, and amplitude-envelope configurations. The resulting variability is visible in representative realizations (Figures~\ref{fig:amplitud} and~\ref{fig:simples}) and is quantified in Technical Validation via the distribution of dominant frequencies (Figure~\ref{fig:dominant_frequency_distribution} and Table~\ref{tab:density_label}) and PSD behavior under different resolutions and noise settings (Figures~\ref{fig:average_psd} and~\ref{fig:noise_psd}). While the dataset is synthetic and not fitted to match a single domain-specific distribution, these controlled variations provide reproducible coverage of common real-world time-series phenomena such as non-stationarity, transient high-frequency events, and additive noise.}

\noindent Figure~\ref{fig:amplitud} shows a representative signal from the dataset sampled at different resolution levels, as well as a version with added noise. This illustrates the variety of sampling and noise conditions included in CoSiBD.

\begin{figure}
\centering
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/amplitud1.png}
    \subcaption{\replacetext{High-resolution signal (5000 points).}{High-resolution signal (5000 samples).}}
    \label{fig:amp1}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/amplitud2.png}
    \subcaption{\replacetext{Medium-resolution signal (500 points).}{Medium-resolution signal (500 samples).}}
    \label{fig:amp2}
\end{minipage}

\vspace{0.15cm}

\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/amplitud3.png}
    \subcaption{\replacetext{Low-resolution signal (250 points).}{Low-resolution signal (250 samples).}}
    \label{fig:amp3}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/amplitud4.png}
    \subcaption{Signal with added noise.}
    \label{fig:amp4}
\end{minipage}

\caption{\replacetext{A synthetic signal sampled at different resolutions: (a) high (5000 points), (b) medium (500 points), (c) low (250 points), and (d) with added noise. These examples reflect the multi-resolution and noise conditions present in the dataset.}{A synthetic signal sampled at different resolutions: (a) high (5000 samples), (b) medium (500 samples), (c) low (250 samples), and (d) with added noise. These examples reflect the multi-resolution and noise conditions present in the dataset.}}
\label{fig:amplitud}
\end{figure}

\vspace{0.3cm}

\noindent Figure~\ref{fig:simples} displays four additional synthetic signals generated using different configuration parameters. These examples demonstrate the variability in temporal structure across instances in the dataset.

\begin{figure}
\centering
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/simples1.png}
    \subcaption{Signal with increasing frequency over time.}
    \label{fig:simp1}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/simples2.png}
    \subcaption{Signal with localized frequency variation.}
    \label{fig:simp2}
\end{minipage}

\vspace{0.15cm}

\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/simples3.png}
    \subcaption{Signal with smooth oscillations and broad amplitude cycles.}
    \label{fig:simp3}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.47\textwidth}
    \centering
    \includegraphics[width=\textwidth]{graphs/simples4.png}
    \subcaption{Signal with irregular peak spacing.}
    \label{fig:simp4}
\end{minipage}

\caption{Examples of synthetic signals in the dataset generated with different parameter configurations. Each signal presents a distinct temporal profile.}
\label{fig:simples}
\end{figure}

\noindent The full dataset is hosted in Zenodo\cite{cosibd_zenodo_2025} (DOI: \href{https://doi.org/10.5281/zenodo.15138853}{10.5281/zenodo.15138853}) and includes the signal files and associated metadata in structured folders.


\section*{Technical Validation}
\label{sec:technical-validation}

\replacetext{This section validates the proposed signal generation method by analyzing its spectral properties under different conditions, including the distribution of dominant frequencies, spectral stability across sampling rates, and the effect of noise. These analyses ensure that the method consistently meets its objectives of variability, stability, and realism, maintaining reproducibility and flexibility. Below, the methodologies and results are described in detail.}{This section evaluates the signal generation procedure by analyzing spectral properties under different conditions, including the distribution of dominant frequencies, spectral stability across sampling rates, and the effect of noise. These analyses aim to assess variability and stability under the reported settings, and to document the dataset's behavior for reproducible use. Below, the methodologies and results are described in detail.}

\subsection*{Validation Context}
\deltext{Experimental parameters were carefully selected to ensure reproducibility and
relevance. The number of signals (n=50) was chosen to provide statistically significant
information about the variability and consistency of the generated signals. Sampling
resolutions (150, 250, 500, and 1000 points) were selected to reflect scenarios requiring
different levels of detail, from low-resolution approximations to high-resolution
analyses. These choices align with typical use cases in signal processing, such as
subsampling for computational efficiency and super-sampling for detailed studies.
\\ \\
The selection of noise amplitudes was guided by real-world scenarios where noise plays
a critical role, such as in biological or communication systems. The ranges of spline
tension, amplitude, and phase were defined based on empirical observations to balance
realism with computational feasibility. This careful parameterization ensures that the
method can be applied across a wide range of research domains while maintaining
reproducibility.}\addtext{Experimental parameters were selected to support reproducibility and to illustrate representative behaviors of the generator under the reported settings. The number of signals (n=50) provides a compact but informative sample to summarize variability in spectral characteristics. Sampling resolutions (150, 250, 500, and 1000 samples) reflect scenarios requiring different levels of detail, aligning with typical signal processing use cases. Noise amplitudes and other parameter ranges were motivated by common acquisition artifacts and exploratory checks, with the goal of providing a controllable benchmark rather than an exhaustive model of any specific measurement pipeline.}

\subsection*{Analysis of Dominant Frequency Distribution}

To assess the stability and variability of the primary spectral components, we analyzed the distribution of dominant frequencies across multiple generated signals. A total of fifty independent signals were synthesized using identical input parameters. To examine their spectral characteristics, we computed the power spectral density (PSD) of each signal, which quantifies how signal power is distributed across different frequencies.
\\ \\
The PSD was estimated using Welch’s method, selected for its ability to reduce noise and provide a smoother spectral representation \cite{Welch1967}. \replacetext{This method achieves better spectral estimation by dividing the signal into overlapping segments, computing their individual spectra, and averaging them. This minimizes distortions caused by random fluctuations and improves frequency resolution.}{This method stabilizes spectral estimation by dividing the signal into overlapping segments, computing their individual spectra, and averaging them. This reduces variance from random fluctuations and yields a smoother estimate.} For each signal, the dominant frequency was identified as the frequency at which the PSD reaches its maximum value. This corresponds to the most prominent spectral component, indicating where the signal concentrates most of its energy.
\\ \\
By analyzing the distribution of dominant frequencies across the dataset, we evaluate whether the generated signals exhibit consistent spectral patterns or if there is significant variation. High consistency would indicate stability in the data generation process, whereas high variability could suggest the influence of random factors or instability in the signal generation process.

\begin{figure}
    \centering
    \includegraphics[width=0.56\textwidth]{graphs/analysis_densidad.png}
    \caption{Distribution of dominant frequencies in 50 independently generated signals (reported in Hz under the illustrative convention $T=4\pi$\,s; for other choices of $T$, the Hz axis rescales by $4\pi/T$).}
    \label{fig:dominant_frequency_distribution}
\end{figure}

\begin{table}
\centering
\small
\begin{tabular}{|l|l|}
\hline
Statistic  & Value (Hz; illustrative $T=4\pi$\,s) \\
\hline
Average Dominant Frequency  & 0.508 \\
Standard Deviation  & 0.195 \\
Minimum Dominant Frequency  & 0.390 \\
Maximum Dominant Frequency  & 1.171 \\
\hline
\end{tabular}
\caption{\label{tab:density_label}Summary statistics of dominant frequencies, including average, standard deviation, and extreme values.}
\end{table}

\noindent The results, shown in Figure~\ref{fig:dominant_frequency_distribution} and Table~\ref{tab:density_label}, show that the dominant frequency values (reported in Hz under the illustrative convention $T=4\pi$\,s) are concentrated in a low-frequency range, with occasional higher-frequency occurrences under the same convention. For other choices of $T$, these values rescale linearly by $4\pi/T$. This behavior reflects the method's ability to generate signals with consistent primary structures while introducing controlled variability.

\noindent Figure \ref{fig:noise_ruido} presents examples of signals from the CoSiBD dataset with increasing levels of added noise, illustrating how amplitude fluctuations progressively obscure the underlying temporal structure.

\begin{figure}[H] \centering \begin{minipage}{0.47\textwidth} \centering \includegraphics[width=\textwidth]{graphs/ruido1.png} \subcaption{Low-noise signal, where amplitude variations are present but minimally distorted.} \label{fig:noise1} \end{minipage} \hspace{0.02\textwidth} \begin{minipage}{0.47\textwidth} \centering \includegraphics[width=\textwidth]{graphs/ruido2.png} \subcaption{Moderate-noise signal, with irregular peaks and troughs beginning to distort the oscillatory pattern.} \label{fig:noise2} \end{minipage}

\vspace{0.15cm}

\begin{minipage}{0.47\textwidth} \centering \includegraphics[width=\textwidth]{graphs/ruido3.png} \subcaption{High-noise signal, where significant distortion leads to unpredictable fluctuations.} \label{fig:noise3} \end{minipage} \hspace{0.02\textwidth} \begin{minipage}{0.47\textwidth} \centering \includegraphics[width=\textwidth]{graphs/ruido4.png} \subcaption{Extreme-noise signal, where the original oscillatory structure is almost entirely masked by chaotic interference.} \label{fig:noise4} \end{minipage}

\caption{Visualization of signals under increasing noise conditions, showing how added noise progressively masks the original temporal patterns. From low (a) to extreme noise levels (d), this degradation highlights reconstruction challenges for super-resolution models.} \label{fig:noise_ruido} \end{figure}



\subsection*{Spectral Stability Across Sampling Resolutions}

This analysis aims to investigate the influence of sampling resolution (number of samples) on the robustness of spectral estimates under varying frequency content. When frequency axes are reported in Hz, they follow the illustrative convention $T=4\pi$\,s; for other choices of $T$, the Hz axis rescales by $4\pi/T$. At lower resolutions, reduced sampling density and coarser frequency grids can obscure or merge spectral peaks, compromising the ability to distinguish closely spaced spectral components \cite{Rabiner1975}. Conversely, higher resolutions improve the granularity of the frequency axis, allowing for better separation of spectral features and reducing the risk of misrepresenting the signal’s underlying structure \cite{Marple1987}.

\noindent This evaluation documents how spectral summaries vary with sampling resolution under the reported settings. The intent is to provide descriptive context for using CoSiBD at different resolutions (and computational budgets) in benchmark protocols, rather than to prescribe a universal sampling rate.


\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{graphs/psd.png}
    \caption{\replacetext{Average power spectral density (PSD) for different sampling resolutions based on 50 independent runs.}{Average power spectral density (PSD) for different sampling resolutions based on 50 independent runs (Hz axis under the illustrative convention $T=4\pi$\,s).}}
    \label{fig:average_psd}
\end{figure}

As shown in Figure~\ref{fig:average_psd}, lower sampling resolutions, specifically the blue curve (150 samples) and the orange curve (250 samples), exhibit a noticeable reduction in detail within the higher-frequency range (reported in Hz under the illustrative convention $T=4\pi$\,s). These lower-resolution curves display greater fluctuations, particularly at higher frequencies under this convention, which is consistent with the theoretical effects of subsampling. The blue curve (150 samples) is especially affected, showing significant variability and a less stable spectral representation in the higher frequencies.
\\ \\
In contrast, the higher sampling resolutions demonstrate a smoother and more stable spectral profile across all frequencies. The red curve (1000 samples), in particular, captures finer details and exhibits minimal high-frequency noise, \replacetext{making it the most stable among the tested resolutions for this analysis.}{making it the smoothest estimate among the reported settings.}


\subsection*{Impact of Noise on Frequency Characteristics}

We analyze how varying the noise amplitude affects the power spectral density (PSD), with particular attention to differences between low- and high-frequency regions.

\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{graphs/noise.png}
    \caption{\replacetext{Power spectral density (PSD) of signals generated with different noise amplitudes. Low frequencies remain stable, while high frequencies increase with noise.}{Power spectral density (PSD) of signals generated with different noise amplitudes (Hz axis under the illustrative convention $T=4\pi$\,s).}}
    \label{fig:noise_psd}
\end{figure}

 \noindent \replacetext{Figure~\ref{fig:noise_psd} illustrates the impact of different noise amplitudes on the Power Spectral Density (PSD). As the noise amplitude increases—from 0.0 (blue curve) to 0.2 (red curve)—there is a noticeable rise in variability at higher frequencies, particularly beyond 10 Hz, while the low-frequency region remains comparatively stable.}{Figure~\ref{fig:noise_psd} illustrates the impact of different noise amplitudes on the Power Spectral Density (PSD) under the reported settings (Hz axis under the illustrative convention $T=4\pi$\,s). As the noise amplitude increases—from 0.0 (blue curve) to 0.2 (red curve)—the estimated PSD exhibits increased variability at higher frequencies, while the low-frequency region remains comparatively stable in these plots.}
\\ \\
Across these settings, the low-frequency region changes less than the higher-frequency region in these estimates. This observation provides context for the subsequent super-resolution benchmark, where both time-domain and frequency-domain metrics are reported.

\subsection*{Multi-Scale Super-Resolution Benchmark}
\label{sec:multiscale-super-resolution-benchmark}

To illustrate a baseline use case of CoSiBD and provide reference results across a range of upsampling factors, we trained a series of convolutional neural network (CNN) models for time series super-resolution at four different scaling factors: 5$\times$, 10$\times$, 20$\times$, and 33$\times$. All models employed the TimeSeriesSRNet architecture—a five-layer encoder-decoder network with 1D convolutional layers (kernel size 5, ReLU activations) and bilinear upsampling. For this benchmark, the 2,500 high-resolution signals were partitioned into an experiment-specific split of 2,000 paired signals for training (low-resolution input to 5,000-sample high-resolution target) and 500 held-out signals for validation. This split is used only for the reported protocol and is not distributed as a predefined dataset partition. Each model was trained using mean squared error (MSE) loss, Adam optimizer (learning rate 0.001, weight decay $10^{-5}$), batch size 16, and early stopping with patience of 3 validation checks (every 10 epochs). Training was conducted on Apple Silicon GPU (MPS backend) to accelerate convergence.

Table~\ref{tab:multiscale_benchmark} summarizes the validation performance, convergence characteristics, and computational requirements for each upsampling factor. \replacetext{All models successfully converged within the 50-epoch budget,}{In these runs, all models completed the 50-epoch budget and showed stable validation loss trends,} with the lowest-resolution inputs (150 samples, 33$\times$ upsampling) requiring the most epochs to achieve stable performance. Validation loss increased systematically with upsampling factor, reflecting the inherent difficulty of reconstructing fine temporal details from severely undersampled inputs (Table~\ref{tab:multiscale_benchmark}, Figure~\ref{fig:multifactor_loss_curves}).

\begin{table}[h]
\centering
\small
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\textbf{Input Size} & \textbf{Factor} & \textbf{Val Loss} & \textbf{Epochs} & \textbf{Early Stop} & \addtext{\textbf{LSD}} & \addtext{\textbf{SCORR}} \\
\hline
1000 samples & 5$\times$ & 0.0845 & 50 & No & \addtext{0.51$\pm$0.63} & \addtext{0.98$\pm$0.10} \\
500 samples & 10$\times$ & 0.1524 & 50 & No & \addtext{0.64$\pm$0.63} & \addtext{0.98$\pm$0.10} \\
250 samples & 20$\times$ & 0.4376 & 50 & No & \addtext{0.95$\pm$0.67} & \addtext{0.98$\pm$0.10} \\
150 samples & 33$\times$ & 1.0326 & 50 & No & \addtext{1.21$\pm$0.67} & \addtext{0.98$\pm$0.11} \\
\hline
\end{tabular}
\caption{Multi-scale super-resolution benchmark results. Validation loss measured as mean squared error on 500 independent \deltext{test}\addtext{validation} signals. LSD (Log Spectral Distance) quantifies spectral content deviation (lower is better), while SCORR (Spectral Correlation) measures frequency-domain similarity (higher is better, range [0,1]). Early Stop indicates whether training terminated before maximum epochs. All models completed the full 50-epoch training without early termination, \replacetext{showing consistent convergence in these runs.}{showing stable convergence across all upsampling factors.}}
\label{tab:multiscale_benchmark}
\end{table}

\addtext{To complement amplitude-based validation with frequency-domain assessment, we computed spectral fidelity metrics for all reconstructed signals. Log Spectral Distance (LSD) increased from 0.51 (5$\times$) to 1.21 (33$\times$), while Spectral Correlation (SCORR) remained consistently high (Table~\ref{tab:multiscale_benchmark}, Figure~\ref{fig:spectral_metrics}). Figure~\ref{fig:spectral_analysis} presents representative spectrogram comparisons across all upsampling factors, illustrating how reconstruction artifacts become more visible at higher upsampling factors.}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.95\textwidth]{graphs/multifactor_loss_curves.png}
    \caption{Training and validation loss evolution across all four upsampling factors (5$\times$, 10$\times$, 20$\times$, 33$\times$). Each panel shows loss curves during training; in these runs, training and validation curves follow similar trends without pronounced divergence. The systematic increase in final validation loss with upsampling factor reflects the inherent difficulty of reconstructing fine temporal details from severely undersampled inputs.}
    \label{fig:multifactor_loss_curves}
\end{figure}

Figure~\ref{fig:multifactor_loss_curves} illustrates the training and validation loss evolution for all four upsampling factors. Representative prediction examples (Figure~\ref{fig:multifactor_predictions}) provide qualitative comparisons of reconstructed outputs against ground truth across scaling factors.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{graphs/multifactor_predictions.png}
    \caption{Representative prediction examples across all upsampling factors. Each quadrant shows prediction comparisons for a different scaling factor (5$\times$, 10$\times$, 20$\times$, 33$\times$), displaying low-resolution inputs, ground-truth high-resolution signals, and CNN-reconstructed outputs.}
    \label{fig:multifactor_predictions}
\end{figure}

\replacetext{These multi-scale experiments establish quantitative baseline performance metrics for future benchmarking studies.}{These multi-scale experiments provide quantitative baseline results for future benchmarking studies.} The systematic increase in task difficulty—from moderate 5$\times$ upsampling to extreme 33$\times$ reconstruction—provides a reference protocol for comparing architectures, loss functions, and training strategies in the time series super-resolution domain.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{graphs/spectral_analysis_grid.png}
    \caption{Spectrogram comparison across all upsampling factors. Each row represents a different upsampling factor (5$\times$, 10$\times$, 20$\times$, 33$\times$), showing original signal (left), CNN-reconstructed signal (center), and spectral difference (right). Reconstruction artifacts become more visible at higher upsampling rates. Representative signals selected based on median Log Spectral Distance (LSD) for each factor.}
    \label{fig:spectral_analysis}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{graphs/spectral_metric_trends.png}
    \caption{Spectral quality metrics vs upsampling factor. Left: Log Spectral Distance (LSD) increases systematically with upsampling factor, from 0.51 (5$\times$) to 1.21 (33$\times$). Right: Spectral Correlation (SCORR) maintains consistently high values (>0.97) across all factors. Error bars represent standard deviation over 500 validation signals per factor.}
    \label{fig:spectral_metrics}
\end{figure}


\subsection*{\replacetext{Preliminary Application Results}{Illustrative Transfer Experiments (optional)}}
\label{sec:preliminary-application-results}

\addtext{To provide initial evidence of the dataset's utility for training deep learning models, we conducted preliminary experiments using convolutional neural networks (CNNs) for time-series super-resolution~\cite{Kuleshov2017,Kaniraja2024}. A TimeSeriesSRNet model with encoder-decoder architecture (Conv1d layers: 1→64→128→256 followed by upsampling and decoder layers 256→128→64→1) was trained using the CoSiBD dataset and validated on real-world data from two distinct domains: EEG clinical signals~\cite{Luciw2014} (500 training, 690 validation samples) and VCTK speech recordings~\cite{Yamagishi2019} (44 hours from 109 speakers).}
\\ \\
\addtext{Four training strategies were evaluated: (1) Real-only: trained exclusively on domain-specific real data; (2) Synth-only: trained exclusively on CoSiBD synthetic signals; (3) Mixed: trained on combined synthetic and real data; (4) Tuned: pre-trained on synthetic data, then fine-tuned on real data. Performance was measured using Mean Absolute Error (MAE) between predicted and ground-truth high-resolution signals.}
\\ \\
\addtext{In these illustrative experiments and under the reported protocol, we report MAE values on both evaluated domains (Table~\ref{tab:cnn_results}, Figure~\ref{fig:model_comparisons})~\cite{Forestier2017}. In these runs, models trained exclusively on synthetic data (Synth-only) exhibited higher errors than Real-only, while the Mixed and Tuned strategies achieved lower MAE values under the same protocol, suggesting that synthetic signals can complement domain-specific real data. These results are provided as an example of how CoSiBD can be used and depend on the chosen datasets, splits, and training details; they should not be interpreted as definitive claims about general performance. Detailed experimental methodology and additional comparisons are available in the accompanying repository (see Section~\ref{sec:code-availability}).}
\\ \\
\addtext{As an additional validation experiment, we \replacetext{explored out-of-domain transfer}{evaluated the generalization capability} of a CNN model trained exclusively on CoSiBD synthetic data by reconstructing complete 2-second audio segments from the VCTK corpus~\cite{Yamagishi2019}. The TimeSeriesSRNet model, trained with 5$\times$ upsampling factor on synthetic signals, was applied to speech recordings (48 kHz, 96,000 samples) without any domain-specific fine-tuning. The reconstruction pipeline processed audio in overlapping chunks of 5,000 samples using Overlap-Add synthesis. In a representative example, the Pearson correlation coefficient between reconstructed and original signals was 0.928, suggesting that \replacetext{some temporal structure can be retained in this example}{temporal structure can be retained} despite the domain mismatch. Reconstructed audio examples and the full reconstruction pipeline are available in the accompanying repository.}

\begin{table}[h]
\centering
\small
\begin{tabular}{|l|c|c|}
\hline
\textbf{Training Strategy} & \textbf{EEG MAE ($\times 10^{-2}$)} & \textbf{VCTK MAE ($\times 10^{-3}$)} \\
\hline
Real-only (baseline) & 10.77 & 5.92 \\
Synth-only & 12.11 & 8.79 \\
Mixed (synth + real) & \textbf{9.73} & 5.59 \\
Tuned (pretrain + finetune) & 10.68 & \textbf{4.41} \\
\hline
\end{tabular}
\caption{\replacetext{Mean Absolute Error (MAE) for CNN-based super-resolution models trained with different strategies. Bold values indicate best performance for each dataset. Mixed strategy shows 9.64\% improvement on EEG data, while Tunned strategy achieves 25.51\% improvement on VCTK speech data, illustrating the effect of synthetic data augmentation under the reported protocol.}{Mean Absolute Error (MAE) for CNN-based super-resolution models trained with different strategies under the reported protocol. Bold values indicate best performance for each dataset.}}
\label{tab:cnn_results}
\end{table}

\begin{figure}[h]
    \centering
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/eeg_model_comparison_1.pdf}
        \subcaption{EEG clinical signal reconstruction comparison.}
        \label{fig:eeg_comparison}
    \end{minipage}
    \hfill
    \begin{minipage}{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/vctk_model_comparison_5.pdf}
        \subcaption{VCTK speech signal reconstruction comparison.}
        \label{fig:vctk_comparison}
    \end{minipage}
    \caption{\replacetext{Visual comparison of super-resolution model predictions for representative test samples from (a) EEG clinical dataset and (b) VCTK speech dataset. Each panel shows the low-resolution input (downsampled), ground-truth high-resolution signal, and predictions from four training strategies (Real, Synth, Mixed, Tunned). The comparisons show how different training strategies affect reconstruction quality across both domains.}{Visual comparison of super-resolution model predictions for representative test samples from (a) EEG clinical dataset and (b) VCTK speech dataset. Each panel shows the low-resolution input (downsampled), ground-truth high-resolution signal, and predictions from four training strategies (Real, Synth, Mixed, Tuned).}}
    \label{fig:model_comparisons}
\end{figure}


\section*{Usage Notes}
\label{sec:usage-notes}

The CoSiBD dataset contains high-resolution signals and corresponding subsampled versions at multiple resolutions. Signals are provided in consolidated \texttt{.txt}, \texttt{.npz}, and \texttt{.json} formats. Pairing between low- and high-resolution versions is performed by row index: row $i$ in a subsampled file corresponds to row $i$ in the high-resolution file, with per-signal parameters available in \texttt{signals\_metadata.json}.
\addtext{The dataset is distributed as a single, unified collection without a predefined train/validation/test split. Users should create partitions appropriate to their objectives (e.g., random splits, stratified splits by noise type/level or signal characteristics, cross-validation, or scenario-specific test sets), using the provided metadata to support principled partitioning.}

\subsection*{Reading the Data}

The signals are stored as consolidated plain text (\texttt{.txt}) files, with one signal per row (samples separated by whitespace). Each file contains multiple time series stacked vertically, where each row corresponds to a single signal. The dataset can be accessed using standard Python tools:

\begin{verbatim}
import numpy as np

# Load subsampled (simple decimation) and high-resolution signals
# Each .txt file is consolidated: one signal per row
x_valid = np.loadtxt('SignalBuilderC/data/signals_subsampled_simple_250.txt')
y_valid = np.loadtxt('SignalBuilderC/data/signals_high_resolution_5000.txt')

# Optional: convert to PyTorch tensors
# import torch
# x_valid = torch.tensor(x_valid, dtype=torch.float32)
# y_valid = torch.tensor(y_valid, dtype=torch.float32)
\end{verbatim}

These commands return NumPy arrays (each row corresponds to one signal). Users can optionally convert them to PyTorch tensors.

\subsection*{Visualizing Signal Pairs}

To explore the resolution differences, users can visualize aligned pairs of signals:

\begin{verbatim}
import matplotlib.pyplot as plt

# Visualize the first pair of signals
plt.figure(figsize=(10, 4))
plt.plot(x_valid[0], label='Low-resolution (250 samples)', color='red')
plt.plot(y_valid[0], label='High-resolution (5000 samples)', color='blue', alpha=0.7)
plt.xlabel('Sample index')
plt.ylabel('Amplitude')
plt.title('Sample Signal Pair')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
\end{verbatim}


\section*{Code availability}
\label{sec:code-availability}

\noindent
\deltext{Custom Python scripts used to load, process, and visualize the CoSiBD dataset are available at:}
\addtext{The complete signal generation pipeline, including modules for frequency profile generation, amplitude envelope construction, spline interpolation, noise application, and data export in multiple formats, is available at:}  
\href{https://github.com/DhamarAM/SignalBuilder/tree/main}{CoSiBD scripts on GitHub}.  
\replacetext{The repository includes SignalBuilderC, a modular Python package with documented functions for: (1) generating high-resolution signals with configurable parameters, (2) creating subsampled versions via re-evaluation or decimation, (3) exporting signals in NumPy, text, and JSON formats, and (4) comprehensive metadata generation. All code is provided with example notebooks demonstrating dataset regeneration and usage.}{The repository includes SignalBuilderC, a modular Python package with documented functions for: (1) generating high-resolution signals with configurable parameters, (2) creating subsampled versions via simple decimation (uniform subsampling), (3) exporting signals in NumPy, text, and JSON formats, and (4) comprehensive metadata generation. All code is provided with example notebooks demonstrating dataset regeneration and usage.}
These scripts are distributed under the MIT License.
\\ \\
\noindent
The dataset itself is published separately at:  
Zenodo\cite{cosibd_zenodo_2025} (DOI: \href{https://doi.org/10.5281/zenodo.15138853}{10.5281/zenodo.15138853}).
The Zenodo record distributes the dataset under the Creative Commons Attribution 4.0 International (CC BY 4.0) license.

% ===== BIBLIOGRAPHY =====
% Using BibTeX with naturemag-doi style for Nature Scientific Data
% References stored in referencias.bib
% Note: \bibliographystyle{naturemag-doi} is defined in wlscirep.cls
\bibliography{referencias}



\section*{Acknowledgments}
This research was supported by Dean's Office of the Polytechnic College of the San Francisco de Quito University  and partially by ProyExcel-0069 project of the Andalusian University, Research and Innovation Department.

\section*{Author Contributions}
J. I. F. handled the methodological design for artificial data creation, probabilistic analysis, spline-based variations, noise distributions, and random node selection. J. A. L. was responsible for the time series methodological design. D. A. M. performed data processing and validation analysis. All of the authors have contributed to writing the manuscript.

\section*{Competing Interests}
The authors declare no competing interests

\end{document}