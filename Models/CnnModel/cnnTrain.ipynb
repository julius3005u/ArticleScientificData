{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Entrenamiento de Red Neuronal CNN para Super-Resoluci√≥n de Se√±ales\n",
    "\n",
    "## üìã Descripci√≥n\n",
    "Este notebook te guiar√° paso a paso para entrenar una red neuronal convolucional (CNN) que convierte se√±ales de **baja resoluci√≥n** a **alta resoluci√≥n**.\n",
    "\n",
    "### ¬øQu√© hace este modelo?\n",
    "- **Entrada**: Se√±al con pocos puntos (ejemplo: 1000 puntos)\n",
    "- **Salida**: Se√±al con muchos puntos (ejemplo: 5000 puntos)\n",
    "- **Aplicaci√≥n**: Reconstrucci√≥n de se√±ales ECG, se√±ales de audio, series temporales, etc.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ 1. Instalaci√≥n de Librer√≠as\n",
    "\n",
    "### Librer√≠as necesarias:\n",
    "- **PyTorch**: Framework de deep learning\n",
    "- **NumPy**: Manejo de arrays y matrices\n",
    "- **Matplotlib**: Visualizaci√≥n de gr√°ficos\n",
    "- **tqdm**: Barras de progreso\n",
    "- **temana**: Librer√≠a personalizada para lectura de datos (debe estar en tu carpeta)\n",
    "\n",
    "### Instalaci√≥n:\n",
    "Si no tienes las librer√≠as instaladas, ejecuta esta celda (descomenta las l√≠neas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomenta y ejecuta si necesitas instalar las librer√≠as\n",
    "# !pip install torch torchvision\n",
    "# !pip install numpy matplotlib tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìö 2. Importar Librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Librer√≠a personalizada (aseg√∫rate de tener temana.py en tu carpeta)\n",
    "import temana as tm\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")\n",
    "print(f\"PyTorch versi√≥n: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèóÔ∏è 3. Definici√≥n del Modelo\n",
    "\n",
    "### ¬øQu√© es TimeSeriesSRNet?\n",
    "Es una red neuronal convolucional con:\n",
    "- **Encoder**: Extrae caracter√≠sticas de la se√±al de entrada\n",
    "- **Upsampler**: Aumenta la resoluci√≥n de la se√±al\n",
    "\n",
    "### Par√°metros:\n",
    "- `upsample_factor`: Factor de aumento (5 = convierte 1000 puntos ‚Üí 5000 puntos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesSRNet(nn.Module):\n",
    "    def __init__(self, upsample_factor=5):\n",
    "        super(TimeSeriesSRNet, self).__init__()\n",
    "        \n",
    "        # Encoder: Extrae caracter√≠sticas de la se√±al\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=9, stride=1, padding=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Upsampler: Aumenta la resoluci√≥n\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=upsample_factor, mode='linear', align_corners=True),\n",
    "            nn.Conv1d(256, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 1, kernel_size=9, stride=1, padding=4)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.upsample(x)\n",
    "        return x\n",
    "\n",
    "print(\"‚úÖ Modelo definido correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìÇ 4. Carga de Datos\n",
    "\n",
    "### Formato de los datos:\n",
    "Los datos deben estar en archivos `.txt` con el siguiente formato:\n",
    "- **Cada fila** = Una se√±al completa\n",
    "- **Cada columna** = Un punto de la se√±al\n",
    "\n",
    "Ejemplo:\n",
    "```\n",
    "0.5  0.6  0.7  ...  (1000 columnas para baja resoluci√≥n)\n",
    "0.3  0.4  0.5  ...  (otra se√±al)\n",
    "```\n",
    "\n",
    "### Archivos necesarios:\n",
    "1. **x_train**: Se√±ales de baja resoluci√≥n (entrada)\n",
    "2. **y_train**: Se√±ales de alta resoluci√≥n (objetivo)\n",
    "\n",
    "### ‚ö†Ô∏è Importante:\n",
    "- Las se√±ales `x_train` y `y_train` deben tener **el mismo n√∫mero de filas** (mismo n√∫mero de muestras)\n",
    "- `x_train` debe tener menos columnas que `y_train` (menor resoluci√≥n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas de tus archivos de datos\n",
    "# CAMBIA ESTAS RUTAS seg√∫n donde tengas tus datos\n",
    "\n",
    "x_train_path = 'Samples/SamplesAV_FV2024_07_09/SignalAVFV_Sub_Sample.txt'\n",
    "y_train_path = 'Samples/SamplesAV_FV2024_07_09/SignalAVFV_Super_Sample.txt'\n",
    "\n",
    "# Cargar datos usando temana\n",
    "x_train = tm.read_data(x_train_path)\n",
    "y_train = tm.read_data(y_train_path)\n",
    "\n",
    "print(f\"‚úÖ Datos cargados correctamente\")\n",
    "print(f\"üìä x_train shape: {x_train.shape} (Muestras, Puntos)\")\n",
    "print(f\"üìä y_train shape: {y_train.shape} (Muestras, Puntos)\")\n",
    "print(f\"üìà Factor de aumento: {y_train.shape[1] // x_train.shape[1]}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üëÄ 5. Visualizaci√≥n de los Datos\n",
    "\n",
    "Veamos c√≥mo se ven las se√±ales de baja y alta resoluci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar una muestra aleatoria\n",
    "sample_idx = np.random.randint(0, x_train.shape[0])\n",
    "\n",
    "# Crear dominio temporal\n",
    "tx_train = np.linspace(0, 4*np.pi, x_train.shape[1])\n",
    "ty_train = np.linspace(0, 4*np.pi, y_train.shape[1])\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(tx_train, x_train[sample_idx, :], 'o-', label='Baja Resoluci√≥n (Entrada)', markersize=4)\n",
    "plt.plot(ty_train, y_train[sample_idx, :], '-', label='Alta Resoluci√≥n (Objetivo)', linewidth=2)\n",
    "plt.title(f'Ejemplo de Se√±al - Muestra #{sample_idx}')\n",
    "plt.xlabel('Tiempo')\n",
    "plt.ylabel('Amplitud')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üí° La se√±al de baja resoluci√≥n tiene {x_train.shape[1]} puntos\")\n",
    "print(f\"üí° La se√±al de alta resoluci√≥n tiene {y_train.shape[1]} puntos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚öôÔ∏è 6. Configuraci√≥n de Hiperpar√°metros\n",
    "\n",
    "### Hiperpar√°metros explicados:\n",
    "- **low_res_points**: N√∫mero de puntos en se√±al de entrada\n",
    "- **high_res_points**: N√∫mero de puntos en se√±al de salida\n",
    "- **upsample_factor**: Factor de aumento (debe ser high_res / low_res)\n",
    "- **epochs**: N√∫mero de veces que el modelo ver√° todos los datos\n",
    "- **batch_size**: N√∫mero de se√±ales procesadas simult√°neamente\n",
    "- **learning_rate**: Velocidad de aprendizaje (t√≠picamente entre 0.0001 y 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraci√≥n autom√°tica basada en los datos\n",
    "low_res_points = x_train.shape[1]\n",
    "high_res_points = y_train.shape[1]\n",
    "upsample_factor = high_res_points // low_res_points\n",
    "\n",
    "# Hiperpar√°metros de entrenamiento\n",
    "epochs = 100           # Puedes aumentar para mejor resultado (pero toma m√°s tiempo)\n",
    "batch_size = 32        # Reduce si tienes poca memoria RAM\n",
    "learning_rate = 1e-3   # 0.001\n",
    "\n",
    "print(\"‚öôÔ∏è Configuraci√≥n:\")\n",
    "print(f\"  - Puntos entrada: {low_res_points}\")\n",
    "print(f\"  - Puntos salida: {high_res_points}\")\n",
    "print(f\"  - Factor de aumento: {upsample_factor}x\")\n",
    "print(f\"  - √âpocas: {epochs}\")\n",
    "print(f\"  - Batch size: {batch_size}\")\n",
    "print(f\"  - Learning rate: {learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ 7. Inicializaci√≥n del Modelo\n",
    "\n",
    "Creamos el modelo, el optimizador y la funci√≥n de p√©rdida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo\n",
    "model = TimeSeriesSRNet(upsample_factor=upsample_factor)\n",
    "\n",
    "# Optimizador (Adam es el m√°s usado)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Funci√≥n de p√©rdida (L1 Loss = Mean Absolute Error)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# Contar par√°metros del modelo\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"‚úÖ Modelo inicializado\")\n",
    "print(f\"üìä Par√°metros totales: {total_params:,}\")\n",
    "print(f\"üéì Par√°metros entrenables: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèãÔ∏è 8. Funci√≥n de Entrenamiento\n",
    "\n",
    "Esta funci√≥n entrena el modelo durante varias √©pocas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, epochs, batch_size, x_train, y_train):\n",
    "    \"\"\"\n",
    "    Entrena el modelo de super-resoluci√≥n.\n",
    "    \n",
    "    Args:\n",
    "        model: Modelo de red neuronal\n",
    "        optimizer: Optimizador (Adam, SGD, etc.)\n",
    "        criterion: Funci√≥n de p√©rdida\n",
    "        epochs: N√∫mero de √©pocas de entrenamiento\n",
    "        batch_size: Tama√±o del batch\n",
    "        x_train: Datos de entrada (baja resoluci√≥n)\n",
    "        y_train: Datos objetivo (alta resoluci√≥n)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    dataset_size = x_train.shape[0]\n",
    "    indices = np.arange(dataset_size)\n",
    "    \n",
    "    # Lista para guardar el historial de p√©rdidas\n",
    "    loss_history = []\n",
    "    \n",
    "    print(\"üöÄ Iniciando entrenamiento...\\n\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Mezclar los datos al inicio de cada √©poca\n",
    "        np.random.shuffle(indices)\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        # Procesar por batches\n",
    "        for start_idx in range(0, dataset_size, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, dataset_size)\n",
    "            batch_idx = indices[start_idx:end_idx]\n",
    "            \n",
    "            # Preparar batch y convertir a tensores\n",
    "            x_batch = torch.tensor(x_train[batch_idx][:, np.newaxis, :], dtype=torch.float32)\n",
    "            y_batch = torch.tensor(y_train[batch_idx][:, np.newaxis, :], dtype=torch.float32)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * x_batch.size(0)\n",
    "        \n",
    "        # Calcular p√©rdida promedio de la √©poca\n",
    "        avg_loss = epoch_loss / dataset_size\n",
    "        loss_history.append(avg_loss)\n",
    "        \n",
    "        # Mostrar progreso cada 10 √©pocas\n",
    "        if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "            print(f\"√âpoca [{epoch+1}/{epochs}] - Loss: {avg_loss:.6f}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Entrenamiento completado\")\n",
    "    return loss_history\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de entrenamiento definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéì 9. Entrenar el Modelo\n",
    "\n",
    "¬°Ahora s√≠! Vamos a entrenar el modelo. **Esto puede tomar varios minutos**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "loss_history = train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    x_train=x_train,\n",
    "    y_train=y_train\n",
    ")\n",
    "\n",
    "print(f\"\\nüéâ Entrenamiento finalizado con √©xito\")\n",
    "print(f\"üìâ Loss final: {loss_history[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìà 10. Visualizar Curva de Aprendizaje\n",
    "\n",
    "Veamos c√≥mo mejor√≥ el modelo durante el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loss_history, linewidth=2)\n",
    "plt.title('Curva de Aprendizaje', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('√âpoca')\n",
    "plt.ylabel('Loss (L1)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üí° El modelo comenz√≥ con loss = {loss_history[0]:.6f}\")\n",
    "print(f\"üí° El modelo termin√≥ con loss = {loss_history[-1]:.6f}\")\n",
    "print(f\"üìä Mejora: {((loss_history[0] - loss_history[-1]) / loss_history[0] * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üíæ 11. Guardar el Modelo\n",
    "\n",
    "Guardamos el modelo entrenado para usarlo despu√©s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear carpeta Models si no existe\n",
    "os.makedirs('Models', exist_ok=True)\n",
    "\n",
    "# Nombre del archivo\n",
    "model_name = f\"timeseries_srnet_{low_res_points}_to_{high_res_points}.pth\"\n",
    "model_path = os.path.join('Models', model_name)\n",
    "\n",
    "# Guardar el modelo\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "print(f\"‚úÖ Modelo guardado en: {model_path}\")\n",
    "print(f\"üì¶ Tama√±o del archivo: {os.path.getsize(model_path) / (1024**2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîç 12. Funciones de Evaluaci√≥n\n",
    "\n",
    "Definimos funciones para evaluar el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_l1_distance(model, x, y_true):\n",
    "    \"\"\"\n",
    "    Calcula la distancia L1 (error absoluto medio) entre la se√±al real y la predicci√≥n.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x_tensor = torch.tensor(x[np.newaxis, np.newaxis, :], dtype=torch.float32)\n",
    "    y_true = np.array(y_true)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred = model(x_tensor).squeeze().numpy()\n",
    "    \n",
    "    l1_distance = np.mean(np.abs(y_true - y_pred))\n",
    "    return l1_distance\n",
    "\n",
    "\n",
    "def mean_l1_loss(model, x_val, y_val):\n",
    "    \"\"\"\n",
    "    Calcula el loss L1 promedio sobre un conjunto de validaci√≥n.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for i in range(x_val.shape[0]):\n",
    "        x = x_val[i]\n",
    "        y_true = y_val[i]\n",
    "        loss = calculate_l1_distance(model, x, y_true)\n",
    "        total_loss += loss\n",
    "    \n",
    "    mean_loss = total_loss / x_val.shape[0]\n",
    "    return mean_loss\n",
    "\n",
    "print(\"‚úÖ Funciones de evaluaci√≥n definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä 13. Visualizar Predicciones\n",
    "\n",
    "Veamos qu√© tan bien funciona el modelo entrenado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(model, x_data, y_data, num_samples=4):\n",
    "    \"\"\"\n",
    "    Grafica predicciones del modelo vs se√±ales reales.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    indices = random.sample(range(x_data.shape[0]), num_samples)\n",
    "    \n",
    "    plt.figure(figsize=(16, 3 * num_samples))\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        x = torch.tensor(x_data[idx][np.newaxis, np.newaxis, :], dtype=torch.float32)\n",
    "        y_true = y_data[idx]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x).squeeze().numpy()\n",
    "        \n",
    "        # Calcular error\n",
    "        l1_error = calculate_l1_distance(model, x_data[idx], y_true)\n",
    "        \n",
    "        # Graficar\n",
    "        plt.subplot(num_samples, 1, i + 1)\n",
    "        plt.plot(y_true, label='Real (Alta Res)', linewidth=2, alpha=0.7)\n",
    "        plt.plot(y_pred, label='Predicci√≥n', linestyle='--', linewidth=2)\n",
    "        plt.scatter(np.linspace(0, len(y_true)-1, len(x_data[idx])), \n",
    "                   np.interp(np.linspace(0, len(y_true)-1, len(x_data[idx])), \n",
    "                            np.arange(len(y_true)), y_true),\n",
    "                   color='red', label='Entrada (Baja Res)', s=20, zorder=5)\n",
    "        plt.title(f'Muestra {idx} - Error L1: {l1_error:.4f}')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualizar predicciones en datos de entrenamiento\n",
    "print(\"üé® Predicciones del modelo en datos de entrenamiento:\\n\")\n",
    "plot_predictions(model, x_train, y_train, num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìà 14. Calcular M√©tricas en Conjunto de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular error promedio en datos de entrenamiento\n",
    "train_loss = mean_l1_loss(model, x_train, y_train)\n",
    "\n",
    "print(\"üìä M√©tricas en Conjunto de Entrenamiento:\")\n",
    "print(f\"  - Loss L1 promedio: {train_loss:.6f}\")\n",
    "print(f\"  - N√∫mero de muestras: {x_train.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîÑ 15. OPCIONAL: Cargar Datos de Validaci√≥n\n",
    "\n",
    "Si tienes un conjunto de validaci√≥n separado, c√°rgalo aqu√≠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descomenta y modifica estas l√≠neas si tienes datos de validaci√≥n\n",
    "\n",
    "# x_val_path = 'Samples/SamplesAV_FV2024_07_09/SignalAVFV_Sub_Sample_Val.txt'\n",
    "# y_val_path = 'Samples/SamplesAV_FV2024_07_09/SignalAVFV_Super_Sample_Val.txt'\n",
    "\n",
    "# x_val = tm.read_data(x_val_path)\n",
    "# y_val = tm.read_data(y_val_path)\n",
    "\n",
    "# print(f\"‚úÖ Datos de validaci√≥n cargados\")\n",
    "# print(f\"üìä x_val shape: {x_val.shape}\")\n",
    "# print(f\"üìä y_val shape: {y_val.shape}\")\n",
    "\n",
    "# # Calcular m√©tricas en validaci√≥n\n",
    "# val_loss = mean_l1_loss(model, x_val, y_val)\n",
    "# print(f\"\\nüìä Loss en validaci√≥n: {val_loss:.6f}\")\n",
    "\n",
    "# # Visualizar predicciones en validaci√≥n\n",
    "# plot_predictions(model, x_val, y_val, num_samples=4)\n",
    "\n",
    "print(\"‚ÑπÔ∏è Secci√≥n de validaci√≥n opcional (descomenta para usar)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîÑ 16. Transfer Learning: Cargar Modelo Pre-entrenado\n",
    "\n",
    "### ¬øQu√© es Transfer Learning?\n",
    "Es cuando cargas un modelo ya entrenado y lo entrenas un poco m√°s con datos nuevos.\n",
    "\n",
    "**√ötil cuando:**\n",
    "- Tienes un modelo entrenado con datos sint√©ticos y quieres mejorarlo con datos reales\n",
    "- Quieres continuar el entrenamiento desde donde lo dejaste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_for_transfer_learning(model_path, upsample_factor):\n",
    "    \"\"\"\n",
    "    Carga un modelo pre-entrenado para transfer learning.\n",
    "    \"\"\"\n",
    "    model = TimeSeriesSRNet(upsample_factor=upsample_factor)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.train()  # Poner en modo entrenamiento\n",
    "    print(f\"‚úÖ Modelo cargado desde: {model_path}\")\n",
    "    return model\n",
    "\n",
    "# Ejemplo de uso (descomenta para usar):\n",
    "# model_pretrained = load_model_for_transfer_learning('Models/timeseries_srnet_1000_to_5000.pth', upsample_factor=5)\n",
    "\n",
    "# # Cargar nuevos datos (por ejemplo, datos reales)\n",
    "# x_real = tm.read_data('RealSamples/ecg_low_5000.txt')\n",
    "# y_real = tm.read_data('RealSamples/ecg_high_5000.txt')\n",
    "\n",
    "# # Escalar datos si es necesario\n",
    "# x_real_scaled = x_real / 40.0\n",
    "# y_real_scaled = y_real / 40.0\n",
    "\n",
    "# # Nuevo optimizador (puedes usar learning rate m√°s bajo)\n",
    "# optimizer_transfer = optim.Adam(model_pretrained.parameters(), lr=1e-4)\n",
    "\n",
    "# # Entrenar con menos √©pocas\n",
    "# loss_history_transfer = train(\n",
    "#     model=model_pretrained,\n",
    "#     optimizer=optimizer_transfer,\n",
    "#     criterion=criterion,\n",
    "#     epochs=20,\n",
    "#     batch_size=32,\n",
    "#     x_train=x_real_scaled,\n",
    "#     y_train=y_real_scaled\n",
    "# )\n",
    "\n",
    "# # Guardar modelo ajustado\n",
    "# torch.save(model_pretrained.state_dict(), 'Models/timeseries_srnet_transfer_learned.pth')\n",
    "\n",
    "print(\"‚ÑπÔ∏è Secci√≥n de transfer learning (descomenta para usar)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîß 17. Troubleshooting Com√∫n\n",
    "\n",
    "### ‚ùå Problema: \"Out of Memory\"\n",
    "**Soluci√≥n:**\n",
    "- Reduce `batch_size` (ejemplo: de 32 a 16 o 8)\n",
    "- Si usas GPU, libera memoria: `torch.cuda.empty_cache()`\n",
    "\n",
    "### ‚ùå Problema: El loss no baja\n",
    "**Posibles causas:**\n",
    "- Learning rate muy alto ‚Üí Prueba con `1e-4` en lugar de `1e-3`\n",
    "- Learning rate muy bajo ‚Üí Prueba con `1e-2`\n",
    "- Datos mal escalados ‚Üí Normaliza tus datos\n",
    "- Necesitas m√°s √©pocas ‚Üí Aumenta `epochs`\n",
    "\n",
    "### ‚ùå Problema: \"FileNotFoundError\"\n",
    "**Soluci√≥n:**\n",
    "- Verifica que las rutas de los archivos sean correctas\n",
    "- Usa rutas absolutas si tienes problemas con rutas relativas\n",
    "\n",
    "### ‚ùå Problema: Las predicciones son malas\n",
    "**Soluciones:**\n",
    "1. Entrena por m√°s √©pocas\n",
    "2. Aumenta el tama√±o del dataset\n",
    "3. Verifica que los datos de entrada y salida est√©n bien alineados\n",
    "4. Prueba con transfer learning si tienes pocos datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù 18. Resumen y Pr√≥ximos Pasos\n",
    "\n",
    "### ‚úÖ Lo que hicimos:\n",
    "1. ‚úÖ Instalamos y cargamos librer√≠as\n",
    "2. ‚úÖ Definimos el modelo CNN para super-resoluci√≥n\n",
    "3. ‚úÖ Cargamos y visualizamos los datos\n",
    "4. ‚úÖ Entrenamos el modelo\n",
    "5. ‚úÖ Evaluamos el rendimiento\n",
    "6. ‚úÖ Guardamos el modelo\n",
    "\n",
    "### üöÄ Pr√≥ximos pasos sugeridos:\n",
    "1. **Experimentar con hiperpar√°metros:**\n",
    "   - Prueba diferentes `learning_rate`\n",
    "   - Aumenta `epochs` para mejor resultado\n",
    "   - Experimenta con diferentes `batch_size`\n",
    "\n",
    "2. **Mejorar el modelo:**\n",
    "   - Usa transfer learning con datos reales\n",
    "   - Prueba con diferentes arquitecturas\n",
    "   - Implementa data augmentation\n",
    "\n",
    "3. **Validaci√≥n:**\n",
    "   - Crea un conjunto de validaci√≥n separado\n",
    "   - Usa cross-validation\n",
    "   - Compara con otros m√©todos (interpolaci√≥n lineal, splines)\n",
    "\n",
    "4. **Aplicaci√≥n:**\n",
    "   - Usa el modelo entrenado en datos nuevos\n",
    "   - Crea una funci√≥n de inferencia\n",
    "   - Exporta el modelo para producci√≥n\n",
    "\n",
    "### üìö Recursos adicionales:\n",
    "- [Documentaci√≥n de PyTorch](https://pytorch.org/docs/stable/index.html)\n",
    "- [Tutorial de CNNs](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html)\n",
    "- [Transfer Learning en PyTorch](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üí° 19. Guardar y Cargar Modelos - Referencia R√°pida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === GUARDAR MODELO ===\n",
    "# torch.save(model.state_dict(), 'ruta/del/modelo.pth')\n",
    "\n",
    "# === CARGAR MODELO PARA INFERENCIA ===\n",
    "# model = TimeSeriesSRNet(upsample_factor=5)\n",
    "# model.load_state_dict(torch.load('ruta/del/modelo.pth'))\n",
    "# model.eval()  # Modo evaluaci√≥n\n",
    "\n",
    "# === CARGAR MODELO PARA CONTINUAR ENTRENAMIENTO ===\n",
    "# model = TimeSeriesSRNet(upsample_factor=5)\n",
    "# model.load_state_dict(torch.load('ruta/del/modelo.pth'))\n",
    "# model.train()  # Modo entrenamiento\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "print(\"üìñ Referencia r√°pida de guardado/carga de modelos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéâ ¬°Felicidades!\n",
    "\n",
    "Has completado el entrenamiento de tu modelo de super-resoluci√≥n de se√±ales.\n",
    "\n",
    "**Creado por:** GitHub Copilot con Claude Sonnet 4.5  \n",
    "**Fecha:** Noviembre 2025"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}