# üöÄ CNN Super-Resoluci√≥n - Experimento CnnModel2

## üìã Descripci√≥n

Este experimento entrena una red neuronal convolucional (CNN) para super-resoluci√≥n de se√±ales temporales usando el dataset **CoSiBD (Correlated Signal Builder Database)**. El modelo aprende a reconstruir se√±ales de alta resoluci√≥n (5,000 muestras) a partir de versiones submuestreadas (1,000 muestras).

**Objetivo:** Validar que el dataset CoSiBD puede ser usado efectivamente para entrenar modelos de super-resoluci√≥n, demostrando su utilidad para la comunidad cient√≠fica.

## üóÇÔ∏è Estructura del Proyecto

```
CnnModel2/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ high_res/          # 2,000 se√±ales √ó 5,000 samples
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ low_res/           # 2,000 se√±ales √ó 1,000 samples
‚îÇ   ‚îî‚îÄ‚îÄ validation/
‚îÇ       ‚îú‚îÄ‚îÄ high_res/          # 500 se√±ales √ó 5,000 samples
‚îÇ       ‚îî‚îÄ‚îÄ low_res/           # 500 se√±ales √ó 1,000 samples
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ best_model.pth         # Mejor checkpoint (generado durante entrenamiento)
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ loss_curves.png        # Curvas de entrenamiento/validaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ prediction_examples.png # Comparaci√≥n visual de predicciones
‚îÇ   ‚îú‚îÄ‚îÄ loss_history.csv       # Historial de p√©rdidas por √©poca
‚îÇ   ‚îî‚îÄ‚îÄ experiment_summary.txt # Resumen del experimento
‚îú‚îÄ‚îÄ temana.py                  # Biblioteca de utilidades para manejo de datos
‚îú‚îÄ‚îÄ cnnTrain2.ipynb            # Notebook principal de entrenamiento
‚îî‚îÄ‚îÄ README.md                  # Este archivo
```

## üèóÔ∏è Arquitectura del Modelo

**TimeSeriesSRNet** - Red encoder-decoder parametrizable:

### Encoder (Extracci√≥n de caracter√≠sticas)
- Conv1D: 1 ‚Üí 64 canales (kernel=9, stride=1, padding=4)
- BatchNorm + ReLU
- Conv1D: 64 ‚Üí 128 canales (kernel=5, stride=1, padding=2)
- BatchNorm + ReLU
- Conv1D: 128 ‚Üí 256 canales (kernel=5, stride=1, padding=2)
- BatchNorm + ReLU

### Upsampler (Reconstrucci√≥n)
- Linear Upsample: Factor 5x (1,000 ‚Üí 5,000 samples)
- Conv1D: 256 ‚Üí 128 canales (kernel=5, padding=2)
- BatchNorm + ReLU
- Conv1D: 128 ‚Üí 64 canales (kernel=5, padding=2)
- BatchNorm + ReLU
- Conv1D: 64 ‚Üí 1 canal (kernel=9, padding=4)

**Par√°metros totales:** ~500K par√°metros

## ‚öôÔ∏è Configuraci√≥n del Experimento

| Par√°metro | Valor |
|-----------|-------|
| **Input Size** | 1,000 samples |
| **Output Size** | 5,000 samples |
| **Upsample Factor** | 5x |
| **Training Samples** | 2,000 se√±ales |
| **Validation Samples** | 500 se√±ales |
| **Batch Size** | 16 |
| **Learning Rate** | 0.001 |
| **Optimizer** | Adam (weight_decay=1e-5) |
| **Loss Function** | MSE (Mean Squared Error) |
| **Epochs** | 50 |
| **Device** | CUDA (si est√° disponible) / CPU |

## üöÄ Uso

### 1. Entrenamiento

Abre y ejecuta el notebook `cnnTrain2.ipynb` en Jupyter:

```bash
cd Models/CnnModel2
jupyter notebook cnnTrain2.ipynb
```

El notebook est√° organizado en secciones:
1. Configuraci√≥n e importaciones
2. Par√°metros del experimento
3. Definici√≥n del modelo TimeSeriesSRNet
4. Carga de datos desde `data/`
5. Creaci√≥n de DataLoaders
6. Configuraci√≥n de entrenamiento (loss + optimizer)
7. Loop de entrenamiento con checkpointing
8. Visualizaci√≥n de curvas de p√©rdida
9. Carga del mejor modelo
10. Predicciones en validaci√≥n
11. Guardado de resultados

**Tiempo estimado de entrenamiento:** 10-30 minutos (dependiendo de GPU/CPU)

### 2. Inferencia en Nuevas Se√±ales

```python
import torch
import numpy as np
from temana import MyDataset

# Cargar modelo entrenado
checkpoint = torch.load('models/best_model.pth')
model = TimeSeriesSRNet(upsample_factor=10)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

# Cargar se√±al de baja resoluci√≥n (1,000 samples)
low_res_signal = np.loadtxt('path/to/signal_sub1000.txt')

# Hacer predicci√≥n
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
with torch.no_grad():
    input_tensor = torch.tensor(low_res_signal, dtype=torch.float32)
    input_tensor = input_tensor.unsqueeze(0).unsqueeze(0).to(device)
    high_res_pred = model(input_tensor).cpu().numpy().flatten()

# high_res_pred contiene 5,000 samples
print(f"Predicci√≥n generada: {high_res_pred.shape}")
```

## üìä Resultados Esperados

Al ejecutar el notebook completo, se generar√°n:

1. **Modelo entrenado:** `models/best_model.pth` (checkpoint con mejor validation loss)
2. **Curvas de p√©rdida:** `results/loss_curves.png` (evoluci√≥n de train/val loss)
3. **Ejemplos visuales:** `results/prediction_examples.png` (5 ejemplos comparando low-res, predicci√≥n, ground-truth)
4. **Historial CSV:** `results/loss_history.csv` (p√©rdidas por √©poca para an√°lisis posterior)
5. **Resumen:** `results/experiment_summary.txt` (configuraci√≥n y resultados del experimento)

### M√©tricas de Evaluaci√≥n

- **MSE (Mean Squared Error):** Funci√≥n de p√©rdida principal
- **Comparaci√≥n visual:** Superposici√≥n de se√±ales predichas vs. ground truth
- **Best validation loss:** Se reporta al final del entrenamiento

## üî¨ Detalles del Dataset

Las se√±ales provienen de **SignalBuilderC**, un generador de se√±ales correlacionadas del proyecto CoSiBD:

- **Se√±ales de alta resoluci√≥n:** Archivos `.txt` con 5,000 muestras cada uno
- **Se√±ales submuestreadas:** Versiones simplificadas con 1,000 muestras (factor 5x)
- **Formato:** Archivos de texto plano con un valor por l√≠nea
- **Nomenclatura:** 
  - Alta resoluci√≥n: `signal_XXXX.txt`
  - Baja resoluci√≥n: `signal_XXXX_sub1000.txt`

**Divisi√≥n train/val:**
- Train: Se√±ales 0000-1999 (2,000 pares)
- Validation: Se√±ales 2000-2499 (500 pares)

## üìö Dependencias

```python
torch>=2.0.0
numpy>=1.24.0
matplotlib>=3.7.0
tqdm>=4.65.0
```

Instalar con:
```bash
pip install torch numpy matplotlib tqdm
```

## üéØ Pr√≥ximos Pasos

1. **Evaluaci√≥n cuantitativa adicional:**
   - Calcular PSNR (Peak Signal-to-Noise Ratio)
   - Calcular SNR (Signal-to-Noise Ratio)
   - Comparar con m√©todos baseline (interpolaci√≥n lineal, spline)

2. **Ablation studies:**
   - Probar diferentes arquitecturas (m√°s/menos capas)
   - Experimentar con kernel sizes
   - Probar diferentes factores de upsampling

3. **Generalizaci√≥n:**
   - Validar con datos reales (EEG, VCTK) del manuscrito
   - Transfer learning a otros dominios

4. **Optimizaci√≥n:**
   - Learning rate scheduling
   - Data augmentation (ruido, desplazamientos)
   - Regularizaci√≥n adicional

## üìÑ Relaci√≥n con el Manuscrito

Este experimento apoya las siguientes secciones del manuscrito:

- **Preliminary Application Results:** Demuestra uso efectivo del dataset CoSiBD
- **Technical Validation:** Valida la calidad de las se√±ales generadas
- **Usage Notes:** Proporciona ejemplo concreto de aplicaci√≥n ML

**Reviewer Requirements Addressed:**
- R1-3: Validaci√≥n con datos reales (preparaci√≥n para EEG/VCTK)
- R2-2: Resultados cuantitativos para demostrar utilidad del dataset
- R3-1: Experimentos CNN adicionales m√°s all√° de los preliminares

## üë• Autores

Creado como parte del proyecto **CoSiBD (Correlated Signal Builder Database)** para el manuscrito en Scientific Data.

## üìù Notas

- El modelo es completamente parametrizable: ajustar `INPUT_SIZE` y `OUTPUT_SIZE` en el notebook
- Los checkpoints se guardan autom√°ticamente cuando mejora la validation loss
- El notebook est√° dise√±ado para ser ejecutado de principio a fin sin interacci√≥n manual
- Todos los paths son relativos al directorio `CnnModel2/`

---

**√öltima actualizaci√≥n:** 22 de noviembre de 2024
