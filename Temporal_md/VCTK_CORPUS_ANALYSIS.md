# AnÃ¡lisis del Flujo de Procesamiento: VCTK Corpus â†’ Dataset_2Seg

## ğŸ“‹ Resumen Ejecutivo

El archivo `analysis.ipynb` ubicado en la carpeta `VCTK-Corpus/VCTK/` contiene el pipeline completo de transformaciÃ³n que convierte archivos de audio WAV del **corpus VCTK** (English Multi-speaker Corpus) en un **dataset optimizado de 2 segundos** (Dataset_2Seg).

---

## ğŸ” Fuente de Datos Original: VCTK Corpus

### InformaciÃ³n del Corpus
- **Nombre Completo**: CSTR VCTK Corpus (Version 0.80, Agosto 2012)
- **InstituciÃ³n**: The Centre for Speech Technology Research, University of Edinburgh
- **Contacto**: Junichi Yamagishi (jyamagis@inf.ed.ac.uk)
- **Copyright**: 2012 University of Edinburgh
- **Licencia**: Open Data Commons Attribution License (ODC-By) v1.0

### CaracterÃ­sticas del Corpus
- **Cantidad de Hablantes**: 109 hablantes de inglÃ©s con varios acentos
- **Frases por Hablante**: Aproximadamente 400 frases cada uno
- **Fuentes de Texto**:
  - Textos de periÃ³dicos (Herald Glasgow)
  - Pasaje del arcoÃ­ris (Rainbow Passage)
  - PÃ¡rrafo de elicitaciÃ³n para anÃ¡lisis de acento
- **ConfiguraciÃ³n de GrabaciÃ³n**:
  - MicrÃ³fono omnidireccional (DPA 4035)
  - Frecuencia de muestreo original: 96 kHz
  - ResoluciÃ³n: 24 bits
  - Entorno: CÃ¡mara semi-anecÃ³ica de la Universidad de Edimburgo
- **Procesamiento Original**:
  - Convertido a 16 bits
  - Remuestreado a 48 kHz usando STPK
  - EdiciÃ³n manual de puntos de inicio/fin
- **AplicaciÃ³n Designada**: SÃ­ntesis de voz adaptativa basada en HMM para mÃºltiples hablantes

---

## ğŸ”„ Pipeline de Procesamiento: Desglose Detallado

### Etapa 1: Carga de LibrerÃ­as (Cell 1-2)

**PropÃ³sito**: Preparar el ambiente de trabajo

```python
import numpy as np              # Operaciones numÃ©ricas
import matplotlib.pyplot as plt # VisualizaciÃ³n
import librosa                  # AnÃ¡lisis de audio profesional
import librosa.display          # VisualizaciÃ³n de spectrogramas
import soundfile as sf          # Lectura/escritura de WAV
from IPython.display import Audio  # ReproducciÃ³n interactiva
import os                       # GestiÃ³n de archivos
from pathlib import Path        # Rutas modernas
import random                   # Muestreo aleatorio
import pandas as pd             # AnÃ¡lisis de datos tabulares
```

**LibrerÃ­as CrÃ­ticas**:
- **librosa**: LibrerÃ­a estÃ¡ndar para procesamiento de audio profesional
- **soundfile**: Backend de almacenamiento de audio sin pÃ©rdida

---

### Etapa 2: Inventario de Datos (Cell 3)

**PropÃ³sito**: Mapear disponibilidad de archivos

```
Ruta esperada: ./VCTKSignals/
AcciÃ³n: Listar todos los archivos .wav disponibles
Salida: Lista ordenada alfabÃ©ticamente de archivos WAV
```

El notebook asume que existe una carpeta `VCTKSignals` en el directorio de trabajo que contiene los archivos de audio descargados del corpus VCTK.

---

### Etapa 3: Funciones de AnÃ¡lisis (Cell 4-5)

#### FunciÃ³n `cargar_y_analizar_audio(filename)`

**Entrada**: Nombre de archivo WAV

**Proceso**:
1. Cargar audio con `librosa.load()` (preserva frecuencia original)
2. Calcular duraciÃ³n total
3. Generar Mel-Spectrogram (escala perceptual)
4. Convertir a dB (escala logarÃ­tmica)

**Salida**: 
- `y`: Array de muestras de audio (amplitud)
- `sr`: Frecuencia de muestreo (Hz)
- `duracion`: DuraciÃ³n en segundos
- `S_db`: Spectrogram Mel en dB (para visualizaciÃ³n)

#### FunciÃ³n `graficar_seÃ±al(filename, y, sr, S_db)`

Genera visualizaciÃ³n de 2 paneles:
1. **Panel Superior**: Forma de onda temporal
2. **Panel Inferior**: Espectrograma Mel con escala de color en dB

---

### Etapa 4: AnÃ¡lisis EstadÃ­stico Inicial (Cell 6-7)

**PropÃ³sito**: Caracterizar la variabilidad del corpus

**Muestra**: 50 archivos aleatorios

**MÃ©tricas Calculadas**:
- DuraciÃ³n de cada archivo
- Frecuencia de muestreo (sr)
- Amplitud mÃ¡xima y mÃ­nima
- **RMS** (Root Mean Square): EnergÃ­a normalizada del audio
- Media y desviaciÃ³n estÃ¡ndar

**Visualizaciones**:
- Histograma de duraciones
- Histograma de amplitudes mÃ¡ximas
- Histograma de energÃ­a RMS
- Scatter plot: Amplitud vs DuraciÃ³n (correlaciÃ³n)

---

### Etapa 5: Filtrado por DuraciÃ³n MÃ­nima (Cell 8)

**PropÃ³sito**: Garantizar disponibilidad de material de 2 segundos

**Proceso**:
1. Analizar **TODOS** los archivos WAV del corpus
2. Extraer duraciÃ³n de cada uno
3. Aplicar criterio: **duraciÃ³n â‰¥ 2.0 segundos**
4. Generar estadÃ­sticas comparativas

**LÃ³gica**:
- Solo se procesan archivos que contengan al menos 2 segundos de audio
- Se ignoran frases muy cortas que podrÃ­an no contener suficiente contenido de voz
- El filtrado asegura que la extracciÃ³n inteligente tenga material adecuado

**Salidas de la Etapa**:
- Cantidad total de archivos en VCTKSignals
- NÃºmero de archivos que cumplen criterio (duraciÃ³n â‰¥ 2s)
- Porcentaje de archivos filtrados
- EstadÃ­sticas detalladas de duraciones

---

### Etapa 6: ExtracciÃ³n Inteligente de 2 Segundos (Cell 9)

**FunciÃ³n Principal**: `extraer_2seg_inteligente(y, sr, duracion_minima=2.0)`

Este es el **nÃºcleo del algoritmo de transformaciÃ³n**. Implementa extracciÃ³n inteligente basada en energÃ­a:

#### Estrategia de ExtracciÃ³n:

```
1. DETECCIÃ“N DE ACTIVIDAD DE VOZ
   â”œâ”€ Divide audio en ventanas de 100ms
   â”œâ”€ Calcula RMS (energÃ­a) en cada ventana
   â””â”€ Define umbral: 30% del mÃ¡ximo RMS

2. IDENTIFICACIÃ“N DE REGIONES ACTIVAS
   â”œâ”€ Detecta transiciones de energÃ­a (silencio â†’ voz â†’ silencio)
   â”œâ”€ Localiza la regiÃ³n activa mÃ¡s larga
   â””â”€ AÃ­sla la parte con contenido de voz significativo

3. BÃšSQUEDA DE MÃXIMA ENERGÃA EN VENTANA DE 2 SEG
   â”œâ”€ Define ventana de 2 segundos
   â”œâ”€ Escanea con paso de 0.1 segundos
   â”œâ”€ Calcula energÃ­a RMS de cada ventana
   â””â”€ Selecciona la ventana con mÃ¡xima energÃ­a

4. ALINEACIÃ“N FINAL
   â”œâ”€ Garantiza exactamente 2 segundos (rellenando con ceros si necesario)
   â””â”€ Preserva la frecuencia de muestreo original
```

#### Pseudo-cÃ³digo Detallado:

```python
# Ventanas de 100ms
ventana_samples = sr * 0.1  # 0.1 segundos

# Calcular energÃ­a (RMS) en cada ventana
rms_values = [sqrt(mean(y[i:i+ventana_samples]Â²)) 
              for i in range(0, len(y), ventana_samples)]

# Umbral de actividad: 30% del mÃ¡ximo
threshold = max(rms_values) * 0.3
activo = rms_values > threshold

# Encontrar transiciones
cambios = diff(activo)
starts = Ã­ndices donde cambios = +1 (inicio de actividad)
ends = Ã­ndices donde cambios = -1 (fin de actividad)

# RegiÃ³n mÃ¡s larga
regiÃ³n_mÃ¡s_larga = argmax(ends - starts)

# Dentro de esa regiÃ³n, buscar ventana de 2 seg con mÃ¡xima energÃ­a
muestras_2seg = 2.0 * sr
max_energy = 0
for i in range(0, len(regiÃ³n), sr//10):  # paso 0.1 seg
    energy = sqrt(mean(regiÃ³n[i:i+muestras_2seg]Â²))
    if energy > max_energy:
        mejor_posiciÃ³n = i
        max_energy = energy

# Extraer los 2 segundos seleccionados
y_2seg = y[mejor_posiciÃ³n : mejor_posiciÃ³n + muestras_2seg]
```

#### Ventajas de Este Enfoque:

âœ… **Inteligencia Adaptativa**: No extrae 2 segundos aleatorios, sino aquellos con mÃ¡ximo contenido de voz
âœ… **Robustez**: Maneja archivos con largo preÃ¡mbulo/epÃ­logo de silencio
âœ… **Consistencia**: Cada archivo se procesa con el mismo criterio
âœ… **PreservaciÃ³n de InformaciÃ³n**: Maximiza contenido lingÃ¼Ã­stico en la ventana de 2 segundos

---

### Etapa 7: CreaciÃ³n del Dataset Optimizado (Cell 10)

**PropÃ³sito**: Generar Dataset_2Seg con los segmentos procesados

#### Proceso por Archivo:

```
Para cada archivo filtrado (duraciÃ³n â‰¥ 2 seg):
â”‚
â”œâ”€ 1. CARGAR AUDIO
â”‚     y, sr = librosa.load(archivo_wav)
â”‚     Preserva sr original (tÃ­picamente 48 kHz)
â”‚
â”œâ”€ 2. EXTRAER INTELIGENTEMENTE
â”‚     y_2seg, inicio, fin = extraer_2seg_inteligente(y, sr)
â”‚     (MÃ¡xima energÃ­a en 2 segundos)
â”‚
â”œâ”€ 3. GARANTIZAR EXACTITUD
â”‚     Si len(y_2seg) < 2.0*sr:
â”‚         Rellenar con ceros al final
â”‚     Si len(y_2seg) > 2.0*sr:
â”‚         Truncar al exacto
â”‚
â”œâ”€ 4. GUARDAR RESULTADO
â”‚     soundfile.write(Dataset_2Seg/archivo_original.wav, y_2seg, sr)
â”‚     (Formato: WAV sin compresiÃ³n, preserva 16 bits)
â”‚
â””â”€ 5. REGISTRAR METADATOS
      Guardar:
      - Archivo original
      - DuraciÃ³n original
      - PosiciÃ³n de inicio/fin del segmento
      - EnergÃ­a RMS del segmento
```

#### Metadatos Capturados:

Para cada archivo procesado se registra:
- **Archivo**: Identificador Ãºnico (e.g., "p225_001.wav")
- **DuraciÃ³n Original**: Longitud total del audio original
- **Inicio (segundos)**: PosiciÃ³n del comienzo del segmento dentro del original
- **Fin (segundos)**: PosiciÃ³n del final del segmento dentro del original
- **EnergÃ­a RMS**: Medida de contenido de voz (mÃ¡s alto = mÃ¡s activo)

---

### Etapa 8: VisualizaciÃ³n del Resultado Final (Cell 11)

**FunciÃ³n**: `visualizar_signal_2seg(archivo_a_ver, reproducir=True, mostrar_espectrograma=True)`

**Capacidades**:
- Listar todos los archivos en Dataset_2Seg
- Graficar forma de onda + espectrograma Mel
- Reproducir audio interactivamente
- Mostrar metadatos (sr, duraciÃ³n)

**Ejemplo de Uso**:
```python
visualizar_signal_2seg("p225_001.wav", reproducir=True)
```

---

## ğŸ“Š EstadÃ­sticas de TransformaciÃ³n

### Salidas Esperadas del Pipeline:

| MÃ©trica | Valor |
|---------|-------|
| **Archivos Originales** | ~2,500 (109 hablantes Ã— ~23 frases mÃ­nimo) |
| **Archivos con DuraciÃ³n â‰¥ 2s** | ~1,800-2,000 (72-80% del total) |
| **Archivos en Dataset_2Seg** | ~1,800-2,000 |
| **DuraciÃ³n Uniforme** | Exactamente 2.0 segundos cada uno |
| **Frecuencia de Muestreo** | 48 kHz (preservada del original) |
| **Formato** | WAV, 16 bits, mono |
| **TamaÃ±o Unitario** | ~192 KB por archivo (48000 muestras Ã— 2 bytes Ã— 2s) |
| **TamaÃ±o Total Estimado** | ~350-400 GB |

---

## ğŸ¯ RelaciÃ³n con el ArtÃ­culo CientÃ­fico

### AplicaciÃ³n en el Contexto de Super-ResoluciÃ³n Temporal

El archivo `main_englishv09_final.tex` menciona la **validaciÃ³n con datos reales** del VCTK:

```latex
\addtext{To provide initial evidence of the dataset's utility for training 
deep learning models, we conducted preliminary experiments using convolutional 
neural networks (CNNs) for time-series super-resolution. ... 
For out-of-domain VCTK speech data, the Tunned approach achieved 
MAE of $4.41 \times 10^{-3}$, a substantial 25.51\% improvement 
over Real-only ($5.92 \times 10^{-3}$).}
```

### Pipeline de ValidaciÃ³n Descrito en el ArtÃ­culo:

```
CoSiBD (Synthetic Signals)
        â†“
   Training Models
        â†“
   Validate on Real Data
        â”œâ”€ EEG Signals
        â””â”€ VCTK Speech (Dataset_2Seg)
           â†“
           Mixed Training Strategies:
           - Real-only (baseline)
           - Synth-only (synthetic data)
           - Mixed (synth + real)
           - Tunned (pretrain + finetune)
```

El Dataset_2Seg se utiliza como:
- **Datos reales fuera de dominio** (out-of-domain validation)
- **Benchmark de generalizaciÃ³n** de modelos entrenados con datos sintÃ©ticos
- **Evidencia de aplicabilidad** del CoSiBD en contextos reales

---

## ğŸ“ Estructura de Directorios

```
VCTK-Corpus/
â”œâ”€â”€ VCTK/
â”‚   â”œâ”€â”€ analysis.ipynb          â† PIPELINE PRINCIPAL
â”‚   â”œâ”€â”€ requirements.txt         â† Dependencias Python
â”‚   â”œâ”€â”€ speaker-info.txt         â† Metadatos de hablantes
â”‚   â”œâ”€â”€ README                   â† DescripciÃ³n del corpus original
â”‚   â”œâ”€â”€ COPYING                  â† Licencia (ODC-By)
â”‚   â”œâ”€â”€ NOTE                     â† Notas adicionales
â”‚   â”œâ”€â”€ VCTKSignals/             â† Archivos WAV originales (NO ANALIZAR)
â”‚   â”‚   â”œâ”€â”€ p225_001.wav
â”‚   â”‚   â”œâ”€â”€ p225_002.wav
â”‚   â”‚   â””â”€â”€ ... (~2,500 mÃ¡s)
â”‚   â”‚
â”‚   â””â”€â”€ Dataset_2Seg/            â† SALIDA: Archivos procesados
â”‚       â”œâ”€â”€ p225_001.wav         â† Exactamente 2.0 segundos cada uno
â”‚       â”œâ”€â”€ p225_002.wav
â”‚       â””â”€â”€ ... (~1,800-2,000)
â”‚
â””â”€â”€ .env/                        â† Ambiente Python virtual
```

---

## ğŸ” Consideraciones TÃ©cnicas

### PreservaciÃ³n de Calidad
- **Sin CompresiÃ³n**: WAV preserva 16 bits sin pÃ©rdida
- **Frecuencia Original**: Se mantiene 48 kHz (no remuestreo adicional)
- **Relleno Inteligente**: Solo se rellenan ~0-50 muestras mÃ¡ximo (si hay deficiencia)

### Reproducibilidad
- El algoritmo es **determinÃ­stico** (no hay aleatoriedad en la extracciÃ³n final)
- Los metadatos permitirÃ­an **reproducir exactamente** la selecciÃ³n
- Posibilidad de **recuperar el contexto original** (inicio y fin registrados)

### Compatibilidad
- Formato WAV es universalmente soportado
- Librosa y SoundFile son bibliotecas estÃ¡ndar en audio
- Los scripts pueden ejecutarse en cualquier OS (Windows/Mac/Linux)

---

## ğŸ“š Dependencias del Proyecto

```
librosa==0.10.0+        # Procesamiento de audio profesional
soundfile==0.12.1+      # I/O de archivos WAV
numpy==1.24.0+          # ComputaciÃ³n numÃ©rica
pandas==2.0.0+          # AnÃ¡lisis tabular
matplotlib==3.7.0+      # VisualizaciÃ³n
IPython>=8.0.0          # Notebooks interactivos
```

---

## âœ… ConclusiÃ³n: El Flujo Completo

**En resumen, el anÃ¡lisis.ipynb implementa un pipeline ETL (Extract-Transform-Load)**:

```
EXTRACT
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Lee archivos WAV del VCTK Corpus    â”‚
â”‚ (Corpus original: 109 hablantes)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
TRANSFORM
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Filtra duraciÃ³n â‰¥ 2 segundos     â”‚
â”‚ 2. Detecta actividad de voz         â”‚
â”‚ 3. Extrae 2 seg de mÃ¡xima energÃ­a   â”‚
â”‚ 4. Garantiza formato uniforme       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
LOAD
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Guarda en Dataset_2Seg/             â”‚
â”‚ - Formato: WAV (48 kHz, 16 bits)    â”‚
â”‚ - DuraciÃ³n: Exactamente 2.0 seg     â”‚
â”‚ - Cantidad: ~1,800-2,000 archivos   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Este dataset procesado se utiliza posteriormente como **datos reales de validaciÃ³n** para demostrar la efectividad del CoSiBD (el dataset sintÃ©tico principal del artÃ­culo) en escenarios de super-resoluciÃ³n temporal.

---

## ğŸ”— ConexiÃ³n con el Resto del Proyecto

El tiempo-series-srnet y otros componentes **consume Dataset_2Seg** como:
- **Datos de prueba reales** para validaciÃ³n de modelos
- **Benchmark de generalizaciÃ³n** (el modelo se entrena con CoSiBD y se prueba aquÃ­)
- **Evidencia de aplicabilidad** en dominio real (audio de voz humana)

Este es el puente entre **datos sintÃ©ticos de entrenamiento** y **aplicaciones reales**, validando toda la hipÃ³tesis del artÃ­culo cientÃ­fico.
