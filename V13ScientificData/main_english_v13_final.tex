\documentclass[fleqn,10pt]{wlscirep}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lineno}
 \usepackage{multirow}
\usepackage{array}  % Añade esto en el preámbulo
\renewcommand{\arraystretch}{1.3}  % Espaciado vertical entre filas

\usepackage{subcaption}
\linenumbers
\usepackage{float}

% ===== TRACK CHANGES PACKAGE =====
% Use [draft] to show changes with highlighting
% Use [final] to hide all markup for submission
\usepackage{xcolor}

% ===== END TRACK CHANGES ===== 

%\title{CoSiBD: A Versatile Dataset for Benchmarking Signal Processing and Machine Learning Algorithms}
%\title{CoSiBD: A Synthetic Dataset for Super-Resolution Deep Learning Temporal Series Analysis}
%\title{A synthetic dataset for super-resolution of Time Series using Deep Learning}
\title{A synthetic dataset for Time Series Super-Resolution with Deep Learning}
\author[1]{Julio Ibarra-Fiallo}
\author[2]{Juan A. Lara}
\author[1]{D'hamar Agudelo-Moreno}
%\author[2,*]{autor }
\affil[1]{Colegio de Ciencias e Ingenierías, Universidad San Francisco de Quito, Cumbayá, Ecuador}
\affil[2]{Universidad de Córdoba, Córdoba, España}

\affil[*]{corresponding author: Julio Ibarra-Fiallo (jibarra@usfq.edu.ec)}

\begin{abstract}
The increasing application of time-series analysis in fields such as biomedical engineering, telecommunications, and industrial monitoring emphasizes the need for high-quality datasets to develop, compare, and validate data-driven methods.
Acquiring real-world temporal data at suitable resolutions is often limited by ethical, economic, or practical constraints. To address this, we introduce CoSiBD (Complex Signal Benchmark Dataset for Super-Resolution), a synthetic dataset of complex temporal signals designed to support reproducible research in multi-resolution time-series analysis, including temporal super-resolution and related signal processing tasks.
CoSiBD comprises 2,500 high-resolution signals ($N=5{,}000$ samples each over a reference domain $\tau\in[0,4\pi]$), with corresponding low-resolution versions provided at four target sampling levels (150, 250, 500, and 1,000 samples) obtained via uniform decimation of the original sequences.
CoSiBD includes diverse signals with non-uniform frequency modulations, capturing gradual transitions and abrupt high-frequency events to reflect a broad range of non-stationary temporal behaviors.
The dataset includes clean and noisy variants across all sampling resolutions, enabling systematic benchmarking under controlled variability conditions.
The dataset is generated by combining distinct frequency bands, non-uniform intervals, and probabilistic frequency assignments to create realistic patterns, with smoothing achieved through spline interpolation.
Technical validation focuses on the spectral characteristics of the generated signals across sampling resolutions and noise settings, documenting consistency and controlled variability under the reported generation parameters.
\end{abstract}



\begin{document}

\flushbottom
\maketitle

\section*{Background \& Summary}
\label{sec:background-summary}

The analysis and simulation of temporal signals are fundamental across science and engineering, providing critical insights into dynamic processes across multiple domains.
In biomedical research \cite{Karacan2024}, electroencephalography (EEG) and electrocardiography (ECG) analyses reveal brain and heart function \cite{Nayak2023,shaffer2017}.
Telecommunications rely on signal processing to ensure data fidelity across noisy media \cite{Chen2022}, while finance uses time-series forecasting for risk and trend analysis \cite{Zhang2016}.
Industrial monitoring detects equipment faults using temporal patterns \cite{Bhatia2021}, and environmental science applies similar techniques to climate and environmental monitoring using remote-sensor time series \cite{Mallat1989}.
Developing robust tools for interpreting time-varying data continues to support both scientific discovery and practical applications, while increasingly relying on the availability of reliable and well-characterized temporal signal datasets.
\\ \\
Recent advances in deep learning have contributed significantly to this field by enabling automatic extraction of complex features from raw signals.
Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), including Long Short-Term Memory (LSTM) units, and Generative Adversarial Networks (GANs) have demonstrated improved performance over traditional techniques in image, speech, and time-series processing tasks \cite{Lecun2015,Goodfellow2014}.
These models support fine-grained signal reconstruction and forecasting, allowing researchers to explore temporal dynamics in new ways, but also increasing the demand for well-structured, high-quality temporal signal datasets suitable for training and evaluation.
\\ \\
Despite this progress, deep learning methods for temporal signal processing often require large quantities of labeled, high-quality data.
Access to such data is frequently constrained by medical privacy regulations such as the General Data Protection Regulation (GDPR) and the Health Insurance Portability and Accountability Act (HIPAA) \cite{Isasa2024}.
In other domains, including environmental monitoring using remote sensors and industrial monitoring, data availability is limited by practical and economic barriers to sensor deployment and data collection \cite{Zhang2016}.
These limitations are particularly relevant in super-resolution (SR) tasks, where models require paired low- and high-resolution signals for effective training, which are rarely available in sufficient quantity and with consistent acquisition conditions.
\\ \\
Temporal SR, which enhances resolution over time, has broad potential.
In biomedical monitoring and sensing, temporal SR can help reconstruct higher-resolution physiological time series, such as ECG and EEG signals.
For EEG analysis, SR may help recover high-frequency components that aid in the study of neural oscillations \cite{Nayak2023} or detect subtle physiological irregularities \cite{shaffer2017}.
In domains such as environmental sensing, telecommunications, and industrial monitoring, SR can increase sensitivity to rapid temporal changes.
\\ \\
Traditional SR methods such as polynomial interpolation, frequency-domain transforms, and splines each have limitations.
Polynomial models are often insufficient for capturing nonlinear dynamics; frequency-domain methods are susceptible to noise \cite{Mallat1989}; and splines, though flexible, may not generalize well to complex signal variability \cite{Schumaker2007,DeBoor2001}.
Many of these methods also assume uniform partitioning, which may not align with the multi-scale, irregular structure of natural temporal phenomena.
\\ \\
Deep learning offers adaptive alternatives to these traditional methods.
CNNs are capable of modeling spatio-temporal structure, RNNs and LSTMs capture long-range dependencies in time, and GANs can learn high-resolution representations through adversarial training \cite{Lecun2015,Goodfellow2014}.
While GANs have achieved strong results in image SR \cite{Brophy2023}, their application to time-series SR remains relatively new.
Preliminary work on synthetic time-series generation indicates potential \cite{Brophy2023}, but the lack of accessible, high-quality paired datasets remains a significant barrier to progress.
\\ \\
Synthetic datasets offer one solution to this problem, allowing researchers to design reproducible training environments that reflect the structure and variability of real-world signals.
Prior studies have used synthetic data in domains such as fluid dynamics \cite{Yasuda2023}, bioimaging \cite{Priessner2024}, and live-cell imaging \cite{Qiao2025}, demonstrating that synthetic approaches can help simulate complexity while avoiding legal and practical restrictions associated with real-world data.
\\ \\
To support research in super-resolution for time-series data, we present the Complex Signal Benchmark Dataset (CoSiBD).
CoSiBD is a synthetic dataset composed of time-series signals with variable resolution, frequency characteristics, and noise levels.
The dataset is intended to provide a reusable benchmark resource for the development and comparison of super-resolution methods under controlled and reproducible conditions.
It includes non-stationary, piecewise-structured signals generated via non-uniform interval partitioning with change-points, multiple levels of resolution and noise, a technical validation suite, and publicly available Python code to facilitate use.

\subsection*{Related synthetic time-series resources}

Publicly available synthetic resources for temporal signals exist, but they are typically designed for tasks other than time-series super-resolution (SR), or they target a specific domain.
In wireless communications, the RadioML family provides large collections of synthetic complex I/Q sequences with varying signal-to-noise ratios and channel impairments, mainly to benchmark automatic modulation classification rather than paired SR reconstruction \cite{oshea2016grcon,deepsig_datasets,deepsig_radioml2018}.
In biomedical signal processing, physiological simulators such as ECGSYN (ECG) and SEREEGA (EEG) enable controlled generation with tunable morphology, sampling settings, and noise, supporting method development when access to real data is constrained \cite{mcsharry2003ecg,ecgsyn_physionet,krol2018sereega}.
In power systems, LoadGAN provides multi-resolution generation of load time series across sampling rates and time horizons, but it is not distributed as a standardized paired SR benchmark \cite{pinceti2021loadgan}.
Domain-specific paired low- and high-resolution training data can also be produced via physical forward modeling, for example low- and high-resolution one-dimensional seismic traces for learning-based resolution enhancement \cite{yuan2024seismic}.
\\ \\
\noindent
Table~\ref{tab:related_synthetic_datasets} summarizes these representative resources and highlights a practical gap:
while many tools provide synthetic signals, they usually do not jointly offer
(i) multi-factor paired low- and high-resolution signals suitable for time-series SR,
(ii) a clearly specified and reproducible protocol for constructing low-resolution observations aligned to a fixed high-resolution target, and
(iii) per-signal metadata enabling deterministic regeneration and principled benchmarking.
CoSiBD is designed to address this gap by providing multi-resolution paired signals, explicit nuisance modeling (including noise and structured interference), and comprehensive metadata for reproducible super-resolution benchmarking across multiple difficulty levels.

\begin{table*}[t]
\centering
\begingroup
\small
\setlength{\tabcolsep}{3pt}
\renewcommand{\arraystretch}{1.15}
\begin{tabular}{|p{2.7cm}|p{2.3cm}|p{1.6cm}|p{1.9cm}|p{1.7cm}|p{2.2cm}|p{2.4cm}|}
\hline
\textbf{Resource} & \textbf{Domain} & \textbf{Form} & \textbf{Paired LR--HR SR} & \textbf{Multi-resolution} & \textbf{Noise / artifacts} & \textbf{Reproducibility granularity} \\
\hline
\textbf{CoSiBD (this work)} &
Generic time series (complex-structured signals) &
Dataset + generator &
Yes (LR $\rightarrow$ HR targets) &
Yes ($150/250/500/1000 \rightarrow 5000$) &
Gaussian + structured interference; primary benchmark uses direct decimation &
Per-signal metadata; deterministic regeneration (seed-controlled) \\
\hline
RadioML 2016.10A \cite{oshea2016grcon,deepsig_datasets} &
Wireless communications (I/Q) &
Dataset &
No (classification benchmark) &
N/A (not SR) &
Variable SNR + channel impairments &
Dataset-level (labels/SNR) \\
\hline
RadioML 2018.01A \cite{deepsig_radioml2018} &
Wireless communications (I/Q) &
Dataset &
No (classification benchmark) &
N/A (not SR) &
Simulated channel effects + SNR variability &
Dataset-level \\
\hline
ECGSYN \cite{mcsharry2003ecg,ecgsyn_physionet} &
ECG (physiology) &
Simulator/tool &
Configurable\footnotemark[1] &
Configurable &
Model-based; supports controlled variability &
User-defined simulator parameters \\
\hline
SEREEGA \cite{krol2018sereega} &
EEG (physiology) &
Simulator/tool &
Configurable\footnotemark[1] &
Configurable &
Supports noise and event-related components &
User-defined simulator parameters \\
\hline
LoadGAN \cite{pinceti2021loadgan} &
Power systems load time series &
Generator/tool &
No (generation) &
Yes (variable sampling rates) &
Domain-specific variability &
Configurable generation settings \\
\hline
Synthetic LR--HR seismic traces \cite{yuan2024seismic} &
Seismic traces (geophysics) &
Paper-specific paired data &
Yes (LR--HR pairs) &
Study-specific &
Study-dependent &
Study-specific \\
\hline
\end{tabular}
\endgroup
\caption{Representative publicly available synthetic time-series datasets and simulators related to signal processing and learning.}
\label{tab:related_synthetic_datasets}
\end{table*}

\footnotetext[1]{``Configurable'' indicates that low- and high-resolution signals can be generated or derived by adjusting simulator settings or sampling rates, but a standardized paired super-resolution benchmark is not distributed as part of the resource.}


\section*{Methods}
\label{sec:methods}

The methodology used to generate the synthetic temporal signals that constitute the CoSiBD dataset is illustrated in Figure~\ref{fig:generation_process}. The signal generation process is designed to produce time series exhibiting structural properties commonly observed in real-world temporal data, including variable frequency content, smooth transitions, and intermittent high-frequency activity. A key aspect of the procedure is the generation of signals at multiple temporal resolutions, enabling the construction of paired datasets for super-resolution (SR) benchmarking.
\\ \\
\begin{figure}
    \centering
    \includegraphics[width=0.35\textwidth]{diagrams/generation_process4.png}
    \caption{Schematic overview of the CoSiBD signal generation process.}
    \label{fig:generation_process}
\end{figure}

\noindent\textbf{Signal design principles.}
The CoSiBD signal generator incorporates structural properties commonly observed in physiological and speech time series, including (i) non-stationary regime changes, (ii) coexisting low- and high-frequency components with intermittent transients, (iii) smooth amplitude-envelope evolution, and (iv) baseline drift and measurement noise. These properties are implemented through non-uniform interval partitioning with change-points, separate low- and high-frequency bands, spline-based amplitude envelopes and frequency profiles, and explicit offset and noise terms. Figure~\ref{fig:design_rationale_motivations} illustrates representative examples of these signal characteristics and the corresponding design mechanisms used in CoSiBD.
\\ \\
\begin{figure}
    \centering
    \includegraphics[width=0.95\textwidth]{graphs/r1_3_design_rationale/r1_3_real_signal_motivations.png}
    \caption{Representative examples of non-stationary temporal properties in physiological and speech signals that informed the CoSiBD design. The figure shows regime changes, structured spectral content, amplitude-envelope dynamics, and smoothly varying frequency trends, which are reflected in the corresponding signal generation mechanisms.}
    \label{fig:design_rationale_motivations}
\end{figure}

\noindent The signal generation pipeline involves the following steps:

\begin{enumerate}
    \item \textbf{Base frequency band definition:}
    A set of distinct frequency bands is defined to represent the underlying spectral content of the signals. These can be adjusted to reflect application-specific characteristics.

    \item \textbf{Non-uniform interval partitioning:}
    The total signal duration is divided into multiple intervals of variable length. The interval lengths are determined probabilistically to introduce variability in the signal structure and non-stationarity through change-points.

    \item \textbf{Frequency assignment:}
    Each interval is assigned a dominant frequency band, sampled according to a predefined probability distribution. This introduces spectral variation over time.

    \item \textbf{Signal synthesis:}
    A sinusoidal waveform, or a combination of sinusoids within the assigned frequency band, is generated for each interval. Signal parameters such as amplitude and phase are configurable.

    \item \textbf{Transition smoothing:}
    To avoid discontinuities at interval boundaries, a smoothing function is applied to overlapping segments. This ensures gradual transitions between intervals with different frequency content.
    
    \item \textbf{Resolution variation:}
    All signals are initially synthesized at a high temporal resolution. Lower-resolution versions are created by applying controlled downsampling to the high-resolution signals, forming paired datasets. In CoSiBD, paired low-resolution sequences are obtained via simple uniform decimation (uniform subsampling) of the high-resolution signals. The low-resolution observation is formed by subsampling the original sequence without pre-filtering.

    \item \textbf{Noise injection:}
    Controlled levels of synthetic noise are added to the signals to emulate different data acquisition scenarios. Both the type and intensity of the noise can be configured. Two noise types are implemented: additive Gaussian noise with configurable amplitude and structured sinusoidal interference. Noise is applied probabilistically on a per-signal basis. All noise parameters are recorded in per-signal metadata.
\end{enumerate}

\noindent\textbf{Rationale for structured 50/60\,Hz interference and noise.}
Real measurement pipelines frequently contain narrow-band interference (e.g., mains hum) superimposed on broadband sensor noise. To reflect this common acquisition artifact, CoSiBD includes an optional structured sinusoidal component in addition to Gaussian noise. CoSiBD signals are generated over a reference domain (by default $\tau\in[0,4\pi]$); interpreting $\tau$ as physical time (and therefore reporting frequencies in Hz) requires an explicit time scaling. Throughout this manuscript we adopt an illustrative convention that maps the reference domain to a duration $T=4\pi$ seconds, under which the structured component can be interpreted as a 50/60\,Hz-like powerline interference term, while the broadband term represents the measurement noise floor. Figure~\ref{fig:r1_4_powerline_noise} illustrates this qualitative motivation; the intent is not to reproduce a specific device transfer function but to include realistic nuisance factors that SR models must handle.
\\ \\
\begin{figure}
    \centering
    \includegraphics[width=0.85\textwidth]{figures/powerline_interference_justification.png}
    \caption{Qualitative motivation for the structured interference term used in CoSiBD. An illustrative example shows how adding a narrow-band sinusoidal component (interpretable as 50/60\,Hz under the illustrative convention $T=4\pi$\,s) produces the characteristic periodic contamination observed in real recordings, while broadband noise captures the measurement floor.}
    \label{fig:r1_4_powerline_noise}
\end{figure}

\noindent\textbf{Sampling units and frequency interpretation.}
CoSiBD signals are provided as discrete sequences $x[n]$ (e.g., $N=5{,}000$ samples) that are directly used as inputs or targets by SR models. The internal generation domain $\tau\in[0,4\pi]$ is a reference parameterization; interpreting it as physical time requires choosing a duration $T$ (in seconds) for the reference interval. Under this convention, the implied sampling rate is $f_s = N/T$ and all frequencies reported in Hz scale linearly with $4\pi/T$. Throughout this manuscript, when reporting example frequencies in Hz we adopt the illustrative convention $T=4\pi$\,s, yielding $f_s \approx 5000/(4\pi) \approx 398$\,Hz; other equally valid mappings exist depending on application. Consequently, any band-specific interpretation in Hz should be understood under the chosen $T$. Changing $T$ rescales all reported Hz values while preserving the underlying discrete sequences, which is a key feature of CoSiBD's reference-domain design. Figure~\ref{fig:r1_5_sampling_units} illustrates that the discrete samples are unchanged under different time scalings and that Hz axes shift with the assumed $f_s$, while the normalized spectrum (cycles per sample) is invariant.
\\ \\
\begin{figure}
    \centering
    \includegraphics[width=0.95\textwidth]{graphs/r1_5_sampling_units/r1_5_time_scaling.png}
    \vspace{0.25cm}
    \includegraphics[width=0.95\textwidth]{graphs/r1_5_sampling_units/r1_5_spectrum_mapping.png}
    \caption{Sampling and unit convention in CoSiBD. Top: the same discrete sequence $x[n]$ plotted against the sample index or under different assumed time scalings. Bottom: the intrinsic frequency axis is normalized (cycles per sample); mapping to physical frequency units depends on the assumed sampling rate $f_s$.}
    \label{fig:r1_5_sampling_units}
\end{figure}

\noindent
The parameters that govern each step of the generation process—such as interval length distributions, frequency band selection probabilities, smoothing function characteristics, sampling rates, and noise settings—can be configured to produce signal sets tailored to different domains or experimental conditions. All generation parameters, including random seeds, are documented in comprehensive metadata (\texttt{signals\_metadata.json}), enabling exact reproduction of individual signals or the complete dataset. The generation pipeline is implemented in modular Python code available in the SignalBuilderC package, with clear interfaces for customization and extension. These configurations are included in the dataset's accompanying code to support reproducibility and allow users to regenerate the signals under consistent conditions.


\section*{Data Records}
\label{sec:data-records}

The Complex Signal Benchmark Dataset (CoSiBD) is publicly available on Zenodo and consists of synthetic temporal signals created to support the development and evaluation of temporal super-resolution (SR) algorithms. The dataset is released under an open license to facilitate reuse and reproducibility. This section provides an overview of the dataset structure, content, and storage format.
\\ \\
\noindent
The dataset comprises 2,500 high-resolution signals, each with corresponding subsampled versions at four resolution levels, organized into multiple categories:

\begin{itemize}
    \item \textbf{High-resolution signals}: 2,500 signals generated at full sampling rate, each consisting of 5,000 samples spanning the reference domain $[0,4\pi]$. Each signal is provided in three formats: NumPy compressed archives (.npz), plain-text files (.txt), and JSON representations (.json). Per-signal generative metadata—including frequency profiles with explicit change-points (\texttt{base\_points}, \texttt{high\_freq\_points}), segment labels (\texttt{variation\_type}), amplitude envelopes, spline parameters, vertical offsets, noise configurations, and random seeds—is stored in a consolidated metadata file (\texttt{signals\_metadata.json}), enabling exact regeneration of individual signals.

    \item \textbf{Simple subsampled signals}: low-resolution versions obtained via uniform decimation of the high-resolution signals at four target resolutions (150, 250, 500, and 1,000 samples). These paired low-resolution sequences are intended as inputs for temporal super-resolution benchmarking against the original 5,000-sample targets and are provided in .npz, .txt, and .json formats.
\end{itemize}

Reproducibility is ensured through documented random seeds: each high-resolution signal is generated using a unique seed (ranging from 10,000 to 12,499), enabling exact regeneration of individual signals or the entire dataset. All generation parameters are stored in metadata JSON files, allowing users to reproduce signals deterministically without relying on a fixed global seed.
\\ \\
\noindent
The dataset is provided as consolidated files organized by resolution level and processing method. High-resolution signals are stored as \texttt{signals\_\allowbreak high\_\allowbreak resolution\_\allowbreak 5000.[npz|txt|json]}. Simple subsampled (uniformly decimated) signals are stored as \texttt{signals\_\allowbreak subsampled\_\allowbreak simple\_\allowbreak \{150,250,500,1000\}.[npz|txt|json]}. Dataset-level metadata and configuration files are provided separately, including \texttt{signals\_\allowbreak metadata.json} and \texttt{dataset\_\allowbreak summary.json}.
\\ \\
\noindent
Each signal is provided in three formats: (1) NumPy compressed format (.npz) containing the signal array, the corresponding time grid, and (for high-resolution records only) the clean signal without noise; (2) plain-text format (.txt), where signals are stored as numerical arrays with samples separated by whitespace, for maximum portability; and (3) JSON format (.json) containing both time and signal arrays to support web-based applications and interoperability. Per-signal generative metadata is stored separately in \texttt{signals\_metadata.json} (one entry per signal), while dataset-level configuration and summary information is provided in \texttt{dataset\_summary.json}.

\subsection*{Metadata schema and example}

CoSiBD provides per-signal metadata to support (i) deterministic regeneration, (ii) principled partitioning (e.g., by noise type or segment labels), and (iii) analysis of the piecewise structure induced by change-points. Table~\ref{tab:metadata_schema} summarizes representative fields contained in \texttt{signals\_metadata.json}. A minimal example entry is shown below (one signal; values truncated for brevity).

\begin{table}[H]
\centering
\small
\begin{tabular}{|p{3.2cm}|p{3.2cm}|p{7.2cm}|}
\hline
\textbf{Field} & \textbf{Type / example} & \textbf{Meaning} \\ \hline
\texttt{signal\_id}, \texttt{index} & \texttt{"signal\_0000"}, 0 & Unique identifier and row index used to align LR--HR pairs across consolidated files. \\ \hline
\texttt{seed} & 10000--12499 & Per-signal random seed enabling deterministic regeneration. \\ \hline
\texttt{t\_start}, \texttt{t\_end} & 0.0, 12.566... & Reference-domain interval (\(\tau\in[0,4\pi]\)) used by the generator. \\ \hline
\texttt{fs\_high} & 397.887... & Illustrative sampling rate under the manuscript convention \(T=4\pi\) s. \\ \hline
\texttt{tau\_frequency} & 1.15 & Frequency-profile spline tension parameter. \\ \hline
\texttt{amplitude\_spline\_type}, \texttt{tau\_amplitude} &
\texttt{"zero\_order"}, \texttt{"N/A"} &
Envelope model type and, when applicable, its tension parameter. \\ \hline
\texttt{base\_points} & \(K\times 2\) array & Change-points and base-band frequencies defining the piecewise frequency profile. \\ \hline
\texttt{high\_freq\_points} & \(K\times 2\) array & Change-points and high-frequency component levels (intermittent transients). \\ \hline
\texttt{variation\_type} & \texttt{["low", ...]} & Segment labels aligned to change-points. \\ \hline
\texttt{amp\_knots}, \texttt{amp\_values} & arrays & Envelope control knots and values. \\ \hline
\texttt{vertical\_offset} & 0.069... & Additive baseline drift term. \\ \hline
\texttt{noise\_profile} & JSON object & Noise flags and parameters (e.g., Gaussian vs structured interference). \\ \hline
\end{tabular}
\caption{Representative per-signal metadata fields in \texttt{signals\_metadata.json}.}
\label{tab:metadata_schema}
\end{table}

\begin{verbatim}
{
    "t_start": 0.0,
    "t_end": 12.566370614359172,
    "fs_high": 397.88735772973837,
    "tau_frequency": 1.15,
    "amplitude_spline_type": "zero_order",
    "vertical_offset": 0.06905161748158965,
    "base_points": [[0.0, 2.0764], [1.9229, 2.0764], ...],
    "high_freq_points": [[0.0, 0.0], [1.9229, 0.0], ...],
    "variation_type": ["low", "low", "low", "low"],
    "amp_knots": [0.0, 6.2819, 12.5639],
    "amp_values": [0.7238, 1.2267, 0.9661],
    "noise_profile": {"has_noise": true, "noise_type": "gaussian", ...},
    "seed": 10000,
    "signal_id": "signal_0000",
    "index": 0
}
\end{verbatim}

\noindent The following resolution levels are available:

\begin{itemize}
    \item \textbf{High-resolution:} 5,000 samples per signal, sampled over the reference domain $\tau\in[0,4\pi]$.

    \item \textbf{Subsampled resolutions:} simple decimated versions of the high-resolution signals:
    \begin{itemize}
        \item 1,000 samples
        \item 500 samples
        \item 250 samples
        \item 150 samples
    \end{itemize}
\end{itemize}

\noindent Table~\ref{tab:Parameter} outlines the main parameters used in signal generation. Each high-resolution signal was generated using a unique random seed (ranging from 10,000 to 12,499), with parameter values randomly sampled within the defined ranges.

\begin{table}[H]
\centering
\begin{tabular}{|c|c|m{6cm}|}
\hline
\textbf{Parameter} & \textbf{Range} & \textbf{Description} \\ \hline
Low Frequency & 1--5 (illustrative Hz for $T=4\pi$\,s) & Low-frequency component present in signals \\ \hline
High Frequency & 20--100 (illustrative Hz for $T=4\pi$\,s) & Higher-frequency variations for transitions \\ \hline
Change Points & 2--11 & Number of frequency transitions per signal \\ \hline
Change Locations & Random & Time locations where transitions occur \\ \hline
Variation Type & Categorical & Defines nature of frequency change \\ \hline
Amplitude Range & 3--16 & Range for amplitude envelope values \\ \hline
Vertical Offset & $\mathcal{N}(0,3.0)$ & Normally distributed offset added to signals \\ \hline
Spline Type & Mixed & 70\% zero-order (step), 30\% tension spline \\ \hline
Tension Parameter (freq) & [1,2] & Tau values for frequency spline interpolation \\ \hline
Tension Parameter (amp) & Configurable & Tau values for amplitude spline when applicable \\ \hline
Noise Probability & 50\% & Probability of adding noise to each signal \\ \hline
Random Seed & 10000--12499 & Unique seed per signal for reproducibility \\ \hline
\end{tabular}
\caption{Signal generation parameters used to create diverse temporal patterns within the CoSiBD dataset.}
\label{tab:Parameter}
\end{table}

\noindent
Figure~\ref{fig:amplitud} shows a representative signal from the dataset sampled at different resolution levels, illustrating the multi-resolution structure of CoSiBD and the alignment between high- and low-resolution representations.

\begin{figure}
\centering
\includegraphics[width=0.47\textwidth]{graphs/amplitude_high.png}
\includegraphics[width=0.47\textwidth]{graphs/amplitude_medium.png}

\vspace{0.15cm}

\includegraphics[width=0.6\textwidth]{graphs/amplitude_low.png}

\caption{A synthetic signal sampled at different resolutions: (a) high (5,000 samples), (b) medium (1,000 samples), and (c) low (150 samples).}
\label{fig:amplitud}
\end{figure}

\vspace{0.3cm}

\noindent
Figure~\ref{fig:simples} displays additional synthetic signals generated using different configuration parameters, demonstrating variability in temporal structure across instances in the dataset.

\begin{figure}
\centering
\includegraphics[width=0.47\textwidth]{graphs/simples_high_low.png}
\includegraphics[width=0.47\textwidth]{graphs/simples_localized.png}

\vspace{0.15cm}

\includegraphics[width=0.47\textwidth]{graphs/simples_smooth.png}
\includegraphics[width=0.47\textwidth]{graphs/simples_irregular.png}

\caption{Examples of synthetic signals in the dataset generated with different parameter configurations.}
\label{fig:simples}
\end{figure}

\noindent
The full dataset is publicly available on Zenodo \cite{cosibd_zenodo_2025} and includes the signal files and associated metadata organized in structured folders.


\section*{Technical Validation}
\label{sec:technical-validation}

This section characterizes the spectral properties of the generated signals under different conditions, including the distribution of dominant frequencies, spectral behavior across sampling rates, and the effect of noise. These analyses document how the dataset behaves under the reported generation settings, providing transparency for reproducibility and informed reuse. The applied procedures and observed outcomes are described in detail below.

\subsection*{Validation Context}

Experimental parameters were selected to support reproducibility and to document representative behaviors of the signal generator under the reported settings. Validation analyses were performed on a representative subset of signals to summarize common spectral trends, rather than to establish statistical significance. The provided scripts allow the same analyses to be replicated on any subset of the dataset.
\\ \\
Sampling resolutions (150, 250, 500, and 1000 samples) reflect scenarios requiring different levels of detail commonly encountered in signal processing workflows. Noise amplitudes and other parameter ranges were motivated by typical acquisition artifacts and exploratory checks, with the goal of providing a controllable benchmark for comparative evaluation rather than an exhaustive model of any specific measurement pipeline.

\subsection*{Analysis of Dominant Frequency Distribution}

To characterize the primary spectral components of the generated signals, we analyzed the distribution of dominant frequencies across multiple independent realizations. A total of fifty signals were synthesized using identical generation settings. To examine their spectral characteristics, we computed the power spectral density (PSD) of each signal, which quantifies how signal power is distributed across frequencies.
\\ \\
\noindent
The PSD was estimated using Welch’s method \cite{Welch1967}, which stabilizes spectral estimation by dividing the signal into overlapping segments, computing their individual spectra, and averaging them. This procedure reduces variance from random fluctuations and yields a smoother spectral estimate.
For each signal, the dominant frequency was identified as the frequency at which the PSD reaches its maximum value. This corresponds to the most prominent spectral component, indicating where the signal concentrates most of its energy.
\\ \\
\noindent
By analyzing the distribution of dominant frequencies across the dataset, we characterize the range and spread of the primary spectral components produced by the generator. This analysis documents how dominant frequencies are distributed under fixed generation settings, capturing both repeated structural patterns and the controlled variability introduced by randomized parameters, without implying optimality or domain-specific realism.
\\ \\

\begin{figure}
    \centering
    \includegraphics[width=0.56\textwidth]{graphs/analysis_densidad.png}
    \caption{Distribution of dominant frequencies in 50 independently generated signals (reported in Hz under the illustrative convention $T=4\pi$\,s; for other choices of $T$, the Hz axis rescales by $4\pi/T$).}
    \label{fig:dominant_frequency_distribution}
\end{figure}

\begin{table}
\centering
\small
\begin{tabular}{|l|l|}
\hline
Statistic  & Value (Hz; illustrative $T=4\pi$\,s) \\
\hline
Average Dominant Frequency  & 0.508 \\
Standard Deviation  & 0.195 \\
Minimum Dominant Frequency  & 0.390 \\
Maximum Dominant Frequency  & 1.171 \\
\hline
\end{tabular}
\caption{\label{tab:density_label}Summary statistics of dominant frequencies, including average, standard deviation, and extreme values.}
\end{table}

\noindent
The results, shown in Figure~\ref{fig:dominant_frequency_distribution} and Table~\ref{tab:density_label}, show that dominant frequency values are concentrated within a low normalized-frequency range, with occasional higher-frequency occurrences under the same generation settings. These values are reported in normalized frequency units; conversion to physical units depends on the chosen temporal scaling convention.
\\ \\
\noindent
Figure~\ref{fig:noise_ruido} presents examples of signals from the CoSiBD dataset under increasing noise levels, illustrating how added noise progressively obscures the underlying temporal structure.

\begin{figure}[H]
\centering
\begin{minipage}{0.47\textwidth}
\centering
\includegraphics[width=\textwidth]{graphs/ruido1.png}
\label{fig:noise1}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.47\textwidth}
\centering
\includegraphics[width=\textwidth]{graphs/ruido2.png}
\label{fig:noise2}
\end{minipage}

\vspace{0.15cm}

\begin{minipage}{0.47\textwidth}
\centering
\includegraphics[width=\textwidth]{graphs/ruido3.png}
\label{fig:noise3}
\end{minipage}
\hspace{0.02\textwidth}
\begin{minipage}{0.47\textwidth}
\centering
\includegraphics[width=\textwidth]{graphs/ruido4.png}
\label{fig:noise4}
\end{minipage}

\caption{Visualization of signals under increasing noise conditions, illustrating how added noise progressively masks the underlying temporal patterns present in the dataset. From low (a) to extreme noise levels (d), these examples document the effect of the reported noise settings on the signal structure.}
\label{fig:noise_ruido}
\end{figure}

\subsection*{Spectral Stability Across Sampling Resolutions}

This analysis examines how spectral summaries vary as a function of sampling resolution (number of samples) under the reported generation settings. At lower resolutions, reduced sampling density and coarser frequency grids can obscure or merge spectral peaks, complicating the separation of closely spaced spectral components. Higher resolutions provide finer frequency grids, allowing spectral features to be represented with greater detail.
\\ \\
\noindent
This evaluation documents how spectral characteristics change with sampling resolution, providing descriptive context for using the dataset at different resolutions and computational budgets, rather than prescribing a universal sampling rate.
\\ \\
\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{graphs/psd.png}
    \caption{Average power spectral density (PSD) for different sampling resolutions based on 50 independent runs (Hz axis under the illustrative convention $T=4\pi$\,s).}
    \label{fig:average_psd}
\end{figure}

\noindent
As shown in Figure~\ref{fig:average_psd}, lower sampling resolutions, such as the blue curve (150 samples) and the orange curve (250 samples), exhibit a coarser spectral representation with increased fluctuations in higher normalized-frequency regions. These patterns are consistent with the expected effects of subsampling and reduced frequency resolution. The 150-sample curve shows greater variability across the upper portion of the spectrum under the same scaling.
\\ \\
\noindent
In contrast, higher sampling resolutions demonstrate smoother spectral profiles across the frequency range. The red curve (1000 samples), in particular, captures finer spectral structure and exhibits reduced high-frequency fluctuations, making it the smoothest spectral estimate among the reported settings.

\subsection*{Impact of Noise on Frequency Characteristics}

The effect of varying noise amplitude on the power spectral density (PSD) is analyzed, with particular attention to differences between low- and high-frequency regions.
\\
\begin{figure}
    \centering
    \includegraphics[width=0.7\textwidth]{graphs/noise.png}
    \caption{Power spectral density (PSD) of signals generated with different noise amplitudes (Hz axis under the illustrative convention $T=4\pi$\,s).}
    \label{fig:noise_psd}
\end{figure}

\noindent
Figure~\ref{fig:noise_psd} illustrates the impact of different noise amplitudes on the Power Spectral Density (PSD) under the reported settings (Hz axis under the illustrative convention $T=4\pi$\,s). As the noise amplitude increases—from 0.0 (blue curve) to 0.2 (red curve)—the estimated PSD exhibits increased variability at higher frequencies, while the low-frequency region remains comparatively stable in these plots.
\\ \\
\noindent
Across these settings, the low-frequency region changes less than the higher-frequency region in these estimates. This observation provides context for the subsequent super-resolution benchmark, where both time-domain and frequency-domain metrics are reported.

\section*{Usage Notes}
\label{sec:usage-notes}

The CoSiBD dataset contains high-resolution signals and corresponding subsampled versions at multiple resolutions. Signals are provided in consolidated \texttt{.txt}, \texttt{.npz}, and \texttt{.json} formats. Pairing between low- and high-resolution versions is performed by row index: row $i$ in a subsampled file corresponds to row $i$ in the high-resolution file, with per-signal parameters available in \texttt{signals\_metadata.json}.
The dataset is distributed as a single, unified collection without a predefined train/validation/test split. Users can create partitions appropriate to their objectives (e.g., random splits, stratified splits by noise type or signal characteristics, cross-validation, or scenario-specific test sets), using the provided metadata to support principled partitioning.
\\ \\
\subsection*{Reading the Data}

CoSiBD is distributed as consolidated plain-text (\texttt{.txt}) files in which each row corresponds to a single temporal signal (samples separated by whitespace). Low- and high-resolution signals are aligned by row index: row $i$ in a subsampled file corresponds to row $i$ in the high-resolution file. Per-signal generation parameters are provided in the accompanying metadata file (\texttt{signals\_metadata.json}) using the same indexing scheme.
\\ \\
The following example illustrates how to load paired low- and high-resolution signals using standard Python tools:

\begin{verbatim}
import numpy as np

# Load subsampled (simple decimation) and high-resolution signals
# Each .txt file is consolidated: one signal per row
x_lr = np.loadtxt('SignalBuilderC/data/signals_subsampled_simple_250.txt')
x_hr = np.loadtxt('SignalBuilderC/data/signals_high_resolution_5000.txt')

# Access a paired signal by row index
i = 0
low_res_signal  = x_lr[i]
high_res_signal = x_hr[i]
\end{verbatim}

These commands return NumPy arrays where each row corresponds to one signal. Users may optionally convert the arrays to other formats or frameworks depending on their analysis pipeline.

\subsection*{Visualizing Paired Signals}

To inspect the alignment between low- and high-resolution versions, users can visualize paired signals indexed by the same row:

\begin{verbatim}
import matplotlib.pyplot as plt
import numpy as np

# Visualize a paired low- and high-resolution signal
i = 0
plt.figure(figsize=(10, 4))

# High-resolution signal
plt.plot(high_res_signal, label='High-resolution (5000 samples)', alpha=0.8)

# Low-resolution signal (aligned to HR index range for visualization)
lr_x = np.linspace(0, len(high_res_signal), len(low_res_signal))
plt.scatter(lr_x, low_res_signal, color='red', s=12,
            label='Low-resolution (250 samples)')

plt.xlabel('Sample index')
plt.ylabel('Amplitude')
plt.title('Paired Low- and High-Resolution Signal')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
\end{verbatim}

This visualization highlights how the same underlying temporal structure is represented at different resolutions while preserving alignment between paired signals. Additional signal characteristics (e.g., change-points, frequency profiles, or noise configuration) can be retrieved from \texttt{signals\_metadata.json} using the same row index.

\section*{Code availability}
\label{sec:code-availability}

\noindent
The full signal generation pipeline used to create the CoSiBD dataset is openly available in a public GitHub repository:  
\href{https://github.com/DhamarAM/SignalBuilder/tree/main}{SignalBuilderC (CoSiBD scripts)}.
\\ \\
\noindent
The repository provides a modular Python package (\texttt{SignalBuilderC}) implementing all stages of the dataset construction process, including: (i) generation of high-resolution synthetic temporal signals with configurable frequency profiles and amplitude envelopes; (ii) deterministic creation of paired low-resolution signals via uniform subsampling; (iii) optional noise injection; and (iv) export of signals and associated metadata in NumPy (\texttt{.npz}), plain-text (\texttt{.txt}), and JSON (\texttt{.json}) formats. The codebase is documented and includes example scripts and notebooks illustrating dataset generation, regeneration from metadata, and basic data access.
\\ \\
\noindent
All source code is released under the MIT License, allowing reuse and extension of the generation framework for research and benchmarking purposes.

\vspace{0.3cm}
\noindent
The CoSiBD dataset itself is published separately on Zenodo and is cited in the Data Records section~\cite{cosibd_zenodo_2025}.  
The Zenodo record distributes the dataset under the Creative Commons Attribution 4.0 International (CC BY 4.0) license.

\bibliography{referencias}

\section*{Acknowledgments}
This research was supported by Dean's Office of the Polytechnic College of the San Francisco de Quito University  and partially by ProyExcel-0069 project of the Andalusian University, Research and Innovation Department.

\section*{Author Contributions}
J. I. F. handled the methodological design for artificial data creation, probabilistic analysis, spline-based variations, noise distributions, and random node selection. J. A. L. was responsible for the time series methodological design. D. A. M. performed data processing and validation analysis. All of the authors have contributed to writing the manuscript.

\section*{Competing Interests}
The authors declare no competing interests.

\end{document}